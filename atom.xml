<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Lancelot&#39;s Desert</title>
  <subtitle>细水长流，温润如玉</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-06-09T03:07:56.633Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>懒死骆驼</name>
    <email>494852624@qq.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>剑指offer阅读笔记</title>
    <link href="http://yoursite.com/2017/06/09/offer/"/>
    <id>http://yoursite.com/2017/06/09/offer/</id>
    <published>2017-06-09T02:33:40.000Z</published>
    <updated>2017-06-09T03:07:56.633Z</updated>
    
    <content type="html"><![CDATA[<p><em>本文主要是个人针对《剑指offer》一书的一些笔记，并不涉及具体的题目或者方法，只是作为一个整体的知识点框架梳理，便于查缺补漏。</em></p>
<h2 id="辅助网站"><a href="#辅助网站" class="headerlink" title="辅助网站"></a>辅助网站</h2><ul>
<li><a href="https://github.com/zhedahht/CodingInterviewChinese2" target="_blank" rel="external">剑指offer第二版作者源代码（C++实现）</a></li>
<li><a href="http://blog.csdn.net/derrantcm/article/details/46887821" target="_blank" rel="external">第一版面试题Java实现</a></li>
<li><a href="https://www.nowcoder.com/ta/coding-interviews?page=1" target="_blank" rel="external">牛客网上配套练习</a><a id="more"></a>
<h2 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h2><h3 id="面试形式-amp-流程"><a href="#面试形式-amp-流程" class="headerlink" title="面试形式&amp;流程"></a>面试形式&amp;流程</h3></li>
<li>电面 ——&gt; 远程 ——&gt; 现场</li>
<li>尽可能用形象化的语言把细节描述清楚</li>
<li>不确定问题时，主动提问</li>
</ul>
<h3 id="编程习惯-amp-调试能力"><a href="#编程习惯-amp-调试能力" class="headerlink" title="编程习惯&amp;调试能力"></a>编程习惯&amp;调试能力</h3><ul>
<li>编程前理清思路</li>
<li>命名、缩进习惯</li>
<li>测试在前、开发在后(编程前尽可能考虑多个测试用例)</li>
</ul>
<h3 id="项目介绍"><a href="#项目介绍" class="headerlink" title="项目介绍"></a>项目介绍</h3><ul>
<li>STAR模型 —— 简短项目背景，突出自己所做的工作和成绩</li>
</ul>
<h3 id="技术面"><a href="#技术面" class="headerlink" title="技术面"></a>技术面</h3><h4 id="5种素质"><a href="#5种素质" class="headerlink" title="5种素质"></a>5种素质</h4><ul>
<li>扎实的基础知识</li>
<li>高质量代码</li>
<li>分析问题时思路清晰</li>
<li>能优化时间、空间效率</li>
<li>学习、沟通能力</li>
</ul>
<h4 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h4><ul>
<li>编程语言——熟悉程度</li>
<li>数据结构：<strong>链表、树</strong>、栈、队列、哈希表</li>
<li>算法：<ul>
<li>查找、排序：<strong>二分查找、归并排序、快排</strong></li>
<li>动态规划、贪心</li>
</ul>
</li>
</ul>
<h4 id="高质量代码"><a href="#高质量代码" class="headerlink" title="高质量代码"></a>高质量代码</h4><ul>
<li>鲁棒性——<strong>检查空指针</strong></li>
<li>特殊输入</li>
<li>边界条件</li>
<li>异常处理</li>
</ul>
<p><em>Note:</em></p>
<ul>
<li>考虑本身结构的取值范围</li>
<li>输入变量的可能取值</li>
<li>开发之前多想一些测试用例</li>
</ul>
<h4 id="分析-amp-思路——针对复杂问题"><a href="#分析-amp-思路——针对复杂问题" class="headerlink" title="分析&amp;思路——针对复杂问题"></a>分析&amp;思路——针对复杂问题</h4><ul>
<li>画图使抽象问题形象化</li>
<li>举例使抽象问题具体化</li>
<li>分解使复杂问题简单化</li>
</ul>
<h4 id="效率"><a href="#效率" class="headerlink" title="效率"></a>效率</h4><ul>
<li>首先要知道如何分析效率</li>
<li>数值各种数据结构的优缺点、并能选择合适的数据结构解决问题</li>
<li>熟练掌握常用的算法</li>
</ul>
<h4 id="软技能"><a href="#软技能" class="headerlink" title="软技能"></a>软技能</h4><ul>
<li>沟通能力——思路、逻辑、合作</li>
<li>学习能力：读书、新概念</li>
<li>知识迁移能力</li>
<li>抽象建模能力</li>
<li>发散思维能力</li>
</ul>
<h4 id="关于提问（技术面）"><a href="#关于提问（技术面）" class="headerlink" title="关于提问（技术面）"></a>关于提问（技术面）</h4><ul>
<li>忌<ul>
<li>不要问与自己职位无关的问题</li>
<li>不要问薪水（HR面再详谈）</li>
<li>不要打听面试结果</li>
</ul>
</li>
<li>荐<ul>
<li>问与应聘职位或项目相关的问题</li>
<li>事先搜集应聘职位、项目背景相关信息</li>
<li>面试中留心面试官说过的话</li>
</ul>
</li>
</ul>
<h2 id="第二章-——-基础知识"><a href="#第二章-——-基础知识" class="headerlink" title="第二章 —— 基础知识"></a>第二章 —— 基础知识</h2><h3 id="编程语言"><a href="#编程语言" class="headerlink" title="编程语言"></a>编程语言</h3><p>语言面试的3种类型</p>
<ul>
<li>概念的理解：eg:关键字（特点及使用场合）</li>
<li>分析代码运行结果</li>
<li>写代码</li>
</ul>
<h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><ul>
<li>数组&amp;字符串 —— 基本</li>
<li><strong>链表&amp;树 —— 常考</strong>，代码鲁棒性</li>
<li>栈 —— 递归</li>
<li>队列 —— 广度优先搜索</li>
</ul>
<h3 id="算法与数据操作"><a href="#算法与数据操作" class="headerlink" title="算法与数据操作"></a>算法与数据操作</h3><ul>
<li>实现方式：循环或递归</li>
<li><strong>排序&amp;查找：重点（重中之重：二分查找、归并排序、快速排序）</strong></li>
<li>回溯法 —— 递归、栈、二维数组（矩阵）、迷宫问题</li>
<li>动态规划<ul>
<li>分析：自上而下 ——&gt; 递归</li>
<li>实现：自下而上 ——&gt; 循环</li>
<li>涉及动态规划求解问题的四个特点<ul>
<li>问题目标是求其<strong>最优解</strong></li>
<li>整体问题的最优解<strong>依赖</strong>于各个<strong>子问题</strong>的最优解</li>
<li>将大问题分解为若干小问题之后，小问题之间还存在相互重叠的更小的<strong>公共子问题</strong></li>
<li>自上而下分析问题，自下而上求解问题</li>
</ul>
</li>
</ul>
</li>
<li>贪婪<ul>
<li>分解子问题时存在特殊选择</li>
<li>证明是最优解——需要较强的数学功底</li>
</ul>
</li>
<li>位运算：与、或、异或、左移、右移<ul>
<li>重要结论：将一个整数减去1后再与原来的整数做位与运算，得到的结果相当于把原整数的二进制表示中的最右边的1变成0</li>
<li>常考点：涉及统计二进制表示中1的个数</li>
</ul>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;em&gt;本文主要是个人针对《剑指offer》一书的一些笔记，并不涉及具体的题目或者方法，只是作为一个整体的知识点框架梳理，便于查缺补漏。&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&quot;辅助网站&quot;&gt;&lt;a href=&quot;#辅助网站&quot; class=&quot;headerlink&quot; title=&quot;辅助网站&quot;&gt;&lt;/a&gt;辅助网站&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/zhedahht/CodingInterviewChinese2&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;剑指offer第二版作者源代码（C++实现）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/derrantcm/article/details/46887821&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;第一版面试题Java实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.nowcoder.com/ta/coding-interviews?page=1&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;牛客网上配套练习&lt;/a&gt;
    
    </summary>
    
    
      <category term="Coding" scheme="http://yoursite.com/tags/Coding/"/>
    
      <category term="剑指offer" scheme="http://yoursite.com/tags/%E5%89%91%E6%8C%87offer/"/>
    
      <category term="面试" scheme="http://yoursite.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="校招" scheme="http://yoursite.com/tags/%E6%A0%A1%E6%8B%9B/"/>
    
  </entry>
  
  <entry>
    <title>统计学习方法笔记(三) —— K近邻</title>
    <link href="http://yoursite.com/2017/06/06/knn/"/>
    <id>http://yoursite.com/2017/06/06/knn/</id>
    <published>2017-06-06T12:12:28.000Z</published>
    <updated>2017-06-08T08:32:56.996Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<h2 id="k近邻算法"><a href="#k近邻算法" class="headerlink" title="k近邻算法"></a>k近邻算法</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><blockquote>
<p>给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的k个实例，这k个实例的多数属于某个类，就把该输入实例分为这个类<br><a id="more"></a></p>
<h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><ul>
<li>输入：训练数据集$T= \lbrace (x_1, y_1), (x_2, y_2),…,(x_N, y_N) \rbrace $，其中$x_i \in R^n$为实例的<strong>特征向量</strong>,$y_i \in \lbrace c_1, c_2,…, c_K \rbrace$ 为实例的<strong>类别</strong>,$i=1, 2, 3…, N$；<ul>
<li>输出：实例$x$所属的类$y$</li>
<li>根据所给的<strong>距离度量</strong>，在训练集中找到与$x$最近的k个点，涵盖这k个点的$x$的邻域记作$N_k(x)$；</li>
<li>$N_k(x)$中根据<strong>分类决策规则</strong>（常用多数表决）决定$x$的类别$y$</li>
</ul>
</li>
</ul>
<p>$$y = argmax_{c_j} \sum_{x_i \in N_k(x)} I(y_i = c_j), i=1, 2,…, N; j=1, 2,…, K$$</p>
<p> 其中$I$为指示函数，当$y_i = c_j$时$I$为1，否则为0</p>
</blockquote>
<p><em>Note:</em></p>
<ul>
<li>k近邻法实际上利用训练数据集<strong>对特征向量空间进行划分</strong>，并作为其分类的“模型”</li>
<li>k=1时称为最近邻算法</li>
<li>k近邻法没有显式的学习过程</li>
</ul>
<h2 id="k近邻模型——对特征空间的划分"><a href="#k近邻模型——对特征空间的划分" class="headerlink" title="k近邻模型——对特征空间的划分"></a>k近邻模型——对特征空间的划分</h2><blockquote>
<p>k近邻法中，当训练集、<strong>距离度量、k值以及分类决策规则</strong>确定后，对于任何一个新的输入实例，它所属的类唯一地确定，这相当于根据上述要素将特征空间划分为一些子空间，确定子空间里的每个点所属的类。</p>
</blockquote>
<h2 id="k近邻法的三个基本要素"><a href="#k近邻法的三个基本要素" class="headerlink" title="k近邻法的三个基本要素"></a>k近邻法的三个基本要素</h2><h3 id="k值的选择"><a href="#k值的选择" class="headerlink" title="k值的选择"></a>k值的选择</h3><table>
<thead>
<tr>
<th>k值</th>
<th>学习的近似误差</th>
<th>估计误差</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>较小</td>
<td>下降</td>
<td>上升</td>
<td>整体模型变得复杂，对紧邻的实例点变得非常敏感，容易发生过拟合</td>
</tr>
<tr>
<td>较大</td>
<td>上升</td>
<td>下降</td>
<td>模型变得简单，但与输入实例较远的点也会对输入实例点产生影响</td>
</tr>
</tbody>
</table>
<p><em>Note: 实际应用中，k值一般取一个比较小的数值，通常采用交叉验证法来选取最优的k值。</em></p>
<p>另外关于近似误差和估计误差，网上没有找到让我满意的答案，目前的一点理解如下：</p>
<blockquote>
<p>k值越小，学习的近似误差(approximation error)越小，估计误差(estimation error)越大，反之则相反</p>
</blockquote>
<p>个人感觉这里有点像偏差和方差的区别，是否可以理解为近似误差即偏差，在k值较小时，选择的邻域范围较小，所以在空间内切割的“比较细”，但与此同时导致模型更加复杂，对于近邻的实例点非常敏感，而估计误差理解为方差，也就是说划分的邻域范围较大，所以平均下来根据分类决策规则可以减小邻域内的噪音点的影响，但是范围大的同时也会产生较远的点对于实例点也产生影响</p>
<p>搜索到的一些结果比如<a href="http://blog.csdn.net/linian8123654/article/details/53301207" target="_blank" rel="external">linian2763的博客</a></p>
<blockquote>
<p>估计误差（estimation error）:度量预测结果与最优结果的相近程度<br>近似误差（approximation error）:度量与最优误差之间的相近程度</p>
</blockquote>
<p>此外还有<a href="https://stats.stackexchange.com/a/149922/152084" target="_blank" rel="external">stackexchange</a>上的讨论，但是看得更加迷糊。</p>
<h3 id="距离度量——实例点相似程度的反应"><a href="#距离度量——实例点相似程度的反应" class="headerlink" title="距离度量——实例点相似程度的反应"></a>距离度量——实例点相似程度的反应</h3><p>常用距离度量</p>
<ul>
<li>欧氏距离</li>
<li>$L_p$距离</li>
<li>Minkowski距离</li>
</ul>
<p>其中对于$L_p$距离，设特征空间为n维实数向量空间$R^n$，$x_i, x_j \in R^n$，$x_i = (x_i^{(1)}, x_i^{(2)},…, x_i^{(n)})^T, x_j = (x_j^{(1)}, x_j^{(2)},…, x_j^{(n)})^T$，则$x_i, x_j$的$L_p$距离定义为</p>
<p>$$L_p(x_i,x_j)=(\sum_{l=1}^{n}|x_i^{(l)}-x_j^{(l)}|^p)^{\frac{1}{p}}$$</p>
<p>其中$p \geq 1$，且当$p=2$时转化为欧氏距离，$p=1$时转化为曼哈顿距离</p>
<p><em>Note: 不同的距离度量所确定的最近邻点是不同的</em></p>
<h3 id="分类决策规则"><a href="#分类决策规则" class="headerlink" title="分类决策规则"></a>分类决策规则</h3><p>常用多数表决，即由输入实例的k个邻近的训练实例中的多数类决定输入实例的类，<strong>多数表决规则等价于经验风险最小化</strong></p>
<h2 id="实现方法——kd树-k维树"><a href="#实现方法——kd树-k维树" class="headerlink" title="实现方法——kd树(k维树)"></a>实现方法——kd树(k维树)</h2><ul>
<li>特征空间维数大</li>
<li>训练数据容量大<br>如何对训练数据进行快速k近邻搜索</li>
<li><del>线性扫描：耗时，不可行</del></li>
<li>使用特殊的结构存储训练数据，以减少计算距离的次数——kd树</li>
</ul>
<h3 id="构造kd树"><a href="#构造kd树" class="headerlink" title="构造kd树"></a>构造kd树</h3><h4 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h4><blockquote>
<p>kd树是一种对k维空间中的实例点进行存储以便对其进行快速检索的树形数据结构</p>
</blockquote>
<p><em>Note:</em></p>
<ul>
<li>kd树是二叉树</li>
<li>kd树的每个结点对应于一个k维超矩形区域，而各实例点存在于不同的超矩形区域内，即在kd树的不同结点里</li>
<li>一般这个k维就是数据实例点的维度，即特征数，每次选定一个特征，然后根据范围内的实例点（记录）的该特征的值来进行二分，过程有点像快排里的分割</li>
</ul>
<h4 id="算法-1"><a href="#算法-1" class="headerlink" title="算法"></a>算法</h4><blockquote>
<ul>
<li>输入：k维空间数据集$T= \lbrace x_1, x_2,…, x_N \rbrace $，其中$x_i=(x_i^{(1)},x_i^{(2)},…,x_i^{(k)})^T, i=1,2,…,N$；</li>
<li>输出：kd树</li>
<li>（1）开始：构造根结点，根结点对应于包含T的k维空间的超矩形区域。 选择$x^{(1)}$为坐标轴，以T中所有实例的$x^{(1)}$坐标的<strong>中位数</strong>为切分点，将根结点对应的超矩形区域切分为两个子区域。切分由通过切分点并与坐标轴$x^{(1)}$垂直的超平面实现。由根结点生成深度为1的左、右结点，左子结点区域的$x^{(1)}$坐标对应的值小于切分点的子区域；右子结点区域的$x^{(1)}$坐标对应的值大于切分点的子区域。将落在切分超平面上的实例点保存在根结点。</li>
<li>（2）重复：对于深度为j的结点，选择$x^{(1)}$为切分的坐标轴，$l=(j \mod k) + 1$，以该结点区域中所有实例的$x^{(1)}$坐标的中位数为切分点，将根结点对应的超矩形区域切分为两个子区域。切分由通过切分点并与坐标轴$x^{(1)}$垂直的超平面实现。由该结点生成深度为j+1的左、右结点，左子结点区域的$x^{(1)}$坐标对应的值小于切分点的子区域；右子结点区域的$x^{(1)}$坐标对应的值大于切分点的子区域。将落在切分超平面上的实例点保存在该结点。</li>
<li>（3）直到两个区域没有实例存在时停止。</li>
</ul>
</blockquote>
<p><em>Note:</em></p>
<ul>
<li>书中的方法是轮流按每个维度对某结点进行切分，各个维度（特征）可能会被重复利用来进行切分，当然此时的实例点范围不同，切分点也不同（中位数发生变化）</li>
</ul>
<p>对于kd构造的实例，其一书中的例子比较直观，如下<br><img src="/materials/img/kNN/kd_tree.png" alt="kd_tree"><br>此外，在<a href="https://zh.wikipedia.org/wiki/K-d%E6%A0%91" target="_blank" rel="external">wiki</a>里的一幅三维空间的配图也是非常直观<br><img src="/materials/img/kNN/kd_tree2.png" alt="kd_tree2"></p>
<blockquote>
<p>一个三维k-d树。第一次划分（红色）把根节点（白色）划分成两个节点，然后它们分别再次被划分（绿色）为两个子节点。最后这四个子节点的每一个都被划分（蓝色）为两个子节点。因为没有更进一步的划分，最后得到的八个节点称为叶子节点。</p>
</blockquote>
<h3 id="搜索kd树"><a href="#搜索kd树" class="headerlink" title="搜索kd树"></a>搜索kd树</h3><blockquote>
<p>利用kd树可以省去对大部分的数据点的搜索，从而减少搜索的计算量</p>
</blockquote>
<h4 id="算法-2"><a href="#算法-2" class="headerlink" title="算法"></a>算法</h4><blockquote>
<ul>
<li>输入：已构造的kd树；目标点x；</li>
<li>输出：x的最近邻</li>
<li>（1）在kd树中找到包含目标点x的叶结点：思想有点像<strong>二分查找</strong>，从根节点出发，递归地向下访问kd树，若目标点x当前维的坐标小于切分点的坐标，则移动到左子节点，否则移动到右子节点，直到子节点为叶节点为止</li>
<li>（2）以此叶节点为“当前最近点”</li>
<li>（3）递归地向上回退，在每个节点执行以下操作：<ul>
<li>（a）如果该结点保存的实例点比当前最近点距离目标点更近，则以该实例点为“当前最近点”</li>
<li>（b）当前最近点一定存在于该结点一个子结点对应的区域。检查该子结点的父结点的另一子结点对应的区域是否有更近的点。即以目标点为球心，以目标点与当前最近点间的距离为半径的球体是否与另一子结点对应的区域相交。如果相交，可能在另一个子结点对应的区域中存在更近的点。移动到另一个子结点，接着递归地进行最邻近搜索。如果不相交，则向上回退。</li>
</ul>
</li>
<li>（4）当回退到根结点，搜索结束，此时的当前最近结点即为x的最邻近点。</li>
</ul>
</blockquote>
<p><em>Note:</em></p>
<ul>
<li>若实例点随机分布，kd树搜索的平均计算复杂度是<em>O(log N)</em>，<em>N</em>为训练实例数</li>
<li>kd树更适用于训练实例数远大于空间维数时的k近邻搜索</li>
</ul>
<p>关于这个算法的理解最好还是看书上的例子3.3，基本思路是一个重复二分查找和回溯的过程，另外关于kd树的搜索，有一篇很不错的文章，详见<a href="https://zhuanlan.zhihu.com/p/23966698" target="_blank" rel="external">kd树的细致图文讲解</a></p>
<h2 id="实现——机器学习实战"><a href="#实现——机器学习实战" class="headerlink" title="实现——机器学习实战"></a>实现——机器学习实战</h2><p>按照机器学习实战关于k-NN的章节实现了原始的k-NN分类器，并做了几个小实例：</p>
<ul>
<li>首先是一个基础的原理理解，对于二维空间的点按照坐标之间的距离进行分类，意图是理解k-NN的基本原理，即基于实例的学习算法，按照距离分类</li>
<li>在实现了原始分类器的基础上构建小应用，使用约会网站的异性数据，针对三项特征来判断新输入的异性是否有魅力</li>
<li>同样基于原始分类器，针对二进制点阵构成的数字图像文本文件进行识别和分类</li>
<li>上述三个例子都是使用的同一个原始分类器，不同之处仅仅是输入的数据有所改变，此外为了使输入数据能够被原始分类器处理，针对不同数据的特征进行了不同的处理：<ul>
<li>针对约会网站数据由于各项特征的取值范围不同可能对于距离计算产生影响所以进行了归一化操作</li>
<li>对于图像文本文件将其由32*32的二进制点阵转换为1*1024的向量便于分类器处理</li>
<li>此外还有一些基础的文件格式化为矩阵以及可视化操作</li>
</ul>
</li>
</ul>
<p>原始的Jupyter Notebook可以参考我的<a href="https://github.com/LancelotHolmes/MLinAction/blob/master/k-NN.ipynb" target="_blank" rel="external">github</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;script type=&quot;text/javascript&quot; async src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
&lt;/script&gt;

&lt;h2 id=&quot;k近邻算法&quot;&gt;&lt;a href=&quot;#k近邻算法&quot; class=&quot;headerlink&quot; title=&quot;k近邻算法&quot;&gt;&lt;/a&gt;k近邻算法&lt;/h2&gt;&lt;h3 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的k个实例，这k个实例的多数属于某个类，就把该输入实例分为这个类&lt;br&gt;
    
    </summary>
    
    
      <category term="ML" scheme="http://yoursite.com/tags/ML/"/>
    
      <category term="统计学习方法" scheme="http://yoursite.com/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    
      <category term="Note" scheme="http://yoursite.com/tags/Note/"/>
    
      <category term="k-NN" scheme="http://yoursite.com/tags/k-NN/"/>
    
  </entry>
  
  <entry>
    <title>统计学习方法笔记(二) —— 感知机</title>
    <link href="http://yoursite.com/2017/06/03/Perceptron/"/>
    <id>http://yoursite.com/2017/06/03/Perceptron/</id>
    <published>2017-06-03T08:53:02.000Z</published>
    <updated>2017-06-07T08:45:09.062Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><blockquote>
<p>感知机（perceptron）是<strong>二类分类的线性分类模型</strong>，其输入为实例的特征向量，输出为实例的类别，取+1和-1二值。感知机对应于输入空间中将实例划分为正负两类的<strong>分离超平面</strong>，属于<strong>判别模型</strong>。感知机学习旨在求出将训练数据进行线性划分的分离超平面，为此导入了<strong>基于误分类的损失函数</strong>，利用<strong>梯度下降法</strong>对损失函数进行极小化，求得感知机模型。感知机学习算法具有简单而易于实现的优点，分为原始形式和对偶形式。感知机预测是用学习得到的感知基模型对新的输入实例进行分类。<em>感知机是神经网络与支持向量机的基础</em>。<br><a id="more"></a><br><strong>关键字：二分类，线性分类模型，分离超平面，判别模型，基于误分类的损失函数，随机梯度下降法</strong></p>
</blockquote>
<h2 id="感知机模型——分离超平面"><a href="#感知机模型——分离超平面" class="headerlink" title="感知机模型——分离超平面"></a>感知机模型——<strong>分离超平面</strong></h2><h3 id="数学表达"><a href="#数学表达" class="headerlink" title="数学表达"></a>数学表达</h3><p>$$f(x) = sign(w \cdot x + b)$$</p>
<ul>
<li>输入空间：$R^n$</li>
<li>输出空间：$\lbrace+1, -1 \rbrace$</li>
<li>假设空间：${f|f(x) = w \cdot x + b}$，表示定义在特征空间中的所有线性分类模型或线性分类器</li>
<li>$w \in R^n$，其中$w$表示权值向量，几何意义为<em>超平面的法向量</em></li>
<li>$b \in R$，$b$表示偏置，几何意义为超平面的截距</li>
</ul>
<p><em>Note:模型学习的目的在于通过训练集求得模型的参数$w$和$b$</em></p>
<h3 id="几何解释"><a href="#几何解释" class="headerlink" title="几何解释"></a>几何解释</h3><blockquote>
<p>感知机的几何解释：线性方程$w \cdot x + b = 0$ 对应特征空间$R^n$中的一个超平面$S$,其中$w$是超平面的法向量，$b$是超平面的截距，这个超平面将特征空间划分为两个部分，位于两部分的点（特征向量）分别被分为正、负两类，因此，超平面$S$称为分离超平面。</p>
</blockquote>
<h2 id="感知机的学习策略"><a href="#感知机的学习策略" class="headerlink" title="感知机的学习策略"></a>感知机的学习策略</h2><h3 id="数据集的线性可分性"><a href="#数据集的线性可分性" class="headerlink" title="数据集的线性可分性"></a>数据集的线性可分性</h3><p>给定一个数据集$T={(x_1, y_1), (x_2, y_2),…,(x_N, y_N)}$,其中$x_i \in R^n$,$y_i \in \lbrace+1, -1 \rbrace$,$i=1, 2, 3…, N$，若存在超平面$S$设为$w \cdot x + b = 0$将数据集的正实例点和负实例点完全正确地划分到$S$两侧，则称数据集$T$为线性可分数据集</p>
<h3 id="学习策略"><a href="#学习策略" class="headerlink" title="学习策略"></a>学习策略</h3><ul>
<li><p>目标：求得一个能将训练集正实例点和负实例点完全正确分开的分类超平面——&gt;确定$w, b$</p>
</li>
<li><p>转化：经验损失函数最小化——基于误分类</p>
<ul>
<li>直观思路：误分类点总数，非$w, b$的连续可导函数，不易优化</li>
<li>修改：误分类点到超平面$S$的总距离$$L(w, b)=-\sum_{x_i \in M} y_i(w \cdot x_i + b)$$,其中$M$为误分类点的集合，损失函数$L(w, b)$是$w, b$的连续可导函数。</li>
</ul>
</li>
</ul>
<p><em>Note:</em></p>
<ul>
<li>感知机的学习策略是在假设空间中选取是损失函数最小的模型参数$w, b$，即感知机模型。</li>
<li><a href="http://www.cnblogs.com/graphics/archive/2010/07/10/1774809.html" target="_blank" rel="external">点到平面的距离推导</a></li>
<li><a href="https://www.zhihu.com/question/20473040" target="_blank" rel="external">范数的通俗解释</a></li>
<li>另外关于范数、规范化的理解，这篇<a href="http://blog.csdn.net/zouxy09/article/details/24971995/" target="_blank" rel="external">博文</a>写的深入浅出</li>
</ul>
<h2 id="感知机学习算法"><a href="#感知机学习算法" class="headerlink" title="感知机学习算法"></a>感知机学习算法</h2><h3 id="原始形式"><a href="#原始形式" class="headerlink" title="原始形式"></a>原始形式</h3><h4 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h4><blockquote>
<p>输入：训练集$T= \lbrace (x_1, y_1), (x_2, y_2),…,(x_N, y_N) \rbrace $，其中$x_i \in R^n$,$y_i \in \lbrace+1, -1 \rbrace$,$i=1, 2, 3…, N$，学习率$\eta (0&lt; \eta \leq 1)$<br>  输出：$w, b$;感知机模型$f(x) = sign(w \cdot x + b)$<br>  (1) 选取初值$w_0, b_0$<br>  (2) 在训练集中选取数据$(x_i, y_i)$<br>  (3) if $y_i(w \cdot x_i + b) \leq 0$<br>    $w \leftarrow  w + \eta y_i x_i$<br>    $b \leftarrow  b + \eta y_i $<br>  (4) 转至(2)，直至训练集中没有误分类点</p>
</blockquote>
<h4 id="几何解释-1"><a href="#几何解释-1" class="headerlink" title="几何解释"></a>几何解释</h4><p>当一个实例点被误分类，即位于分离超平面的错误的一侧时，则调整$w, b$的值，是分离超平面向该误分类点的一侧移动，以减少该误分类点与超平面间的距离，直至超平面越过该误分类点使其被正确分类。</p>
<h4 id="随机梯度下降法"><a href="#随机梯度下降法" class="headerlink" title="随机梯度下降法"></a>随机梯度下降法</h4><ul>
<li>首先任意选取一个超平面$w_0, b_0$，然后用随机梯度下降法不断地极小化目标函数</li>
</ul>
<p>$$L(w, b)= - \sum_{x_i \in M} y_i(w \cdot x_i + b)$$</p>
<ul>
<li>极小化过程中不是一次使$M$中的所有误分类点的梯度下降，而是一次随机选取一个误分类点使其梯度下降<ul>
<li>若误分类点集合M固定，损失函数的梯度计算<ul>
<li>$$\frac{\partial L(w,b)}{\partial w}=- \sum_{x_i \in M}y_i x_i$$</li>
<li>$$\frac{\partial L(w,b)}{\partial b}=- \sum_{x_i \in M}y_i$$</li>
</ul>
</li>
<li>随机选取一个误分类点$(x_i, y_i)$对$w, b$进行更新：    <ul>
<li>$$w \leftarrow  w + \eta y_i x_i$$</li>
<li>$$b \leftarrow  b + \eta y_i $$</li>
</ul>
</li>
</ul>
</li>
<li>通过迭代可使损失函数$L(w, b)$不断减小，直到为0。</li>
</ul>
<h3 id="算法的收敛性"><a href="#算法的收敛性" class="headerlink" title="算法的收敛性"></a>算法的收敛性</h3><p>证明如下<br><img src="/materials/img/Perceptron/Convergence_1.JPG" alt="convergence_1"><br><img src="/materials/img/Perceptron/Convergence_2.JPG" alt="convergence_2"><br><img src="/materials/img/Perceptron/Convergence_3.JPG" alt="convergence_3"><br><img src="/materials/img/Perceptron/Convergence_4.JPG" alt="convergence_4"></p>
<p>另外可以看看其他人写的<a href="http://www.cs.columbia.edu/~mcollins/courses/6998-2012/notes/perc.converge.pdf" target="_blank" rel="external">证明过程</a></p>
<p><em>Note: 当训练数据集线性可分时，感知机学习算法存在无穷多个解，其解由于不同的初值或不同的迭代顺序而可能有所不同。</em></p>
<h3 id="对偶形式"><a href="#对偶形式" class="headerlink" title="对偶形式"></a>对偶形式</h3><h4 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h4><p>将$w$和$b$表示为实例$x_i$和标记$y_i$的线性组合的形式，通过求解其系数而求得$w, b$。</p>
<ul>
<li>假设初始值$w_0, b_0$均为0，对误分类点$(x_i, y_i)$，通过<ul>
<li>$$w \leftarrow  w + \eta y_i x_i$$</li>
<li>$$b \leftarrow  b + \eta y_i $$</li>
</ul>
</li>
<li>逐步修改$w, b$，假设修改$n$次，则$w, b$可分别表示为：<ul>
<li>$$w= \sum_{i=1}^{N} \alpha_i y_i x_i$$</li>
<li>$$b= \sum_{i=1}^{N} \alpha_i y_i$$</li>
</ul>
</li>
<li>每个实例点对应有一个$\alpha_i$满足$\alpha_i \geq 0$且当$\eta = 1$时，$\alpha_i$就表示第$i$个实例点由于误分类而进行更新的次数。</li>
<li>实例点更新次数越多，意味着它距离分离超平面越接近，也就越难以正确分类，换言之，这种实例对学习结果影响最大（有点支持向量机中的支持向量的意思）。</li>
</ul>
<h4 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h4><blockquote>
<p>输入：线性可分的数据集$T= \lbrace (x_1, y_1), (x_2, y_2),…,(x_N, y_N) \rbrace $，其中$x_i \in R^n$,$y_i \in \lbrace +1, -1 \rbrace$,$i=1, 2, 3…, N$，学习率$\eta (0&lt; \eta \leq 1)$</p>
<p>输出：$\alpha, b$；感知机模型$f(x) = sign(\sum_{j=1}^{N} \alpha_j y_j x_j \cdot x + b)$,其中$\alpha=(alpla_1, alpla_2,…,alpla_N)^T$<br>(1): $\alpha \leftarrow 0$, $b \leftarrow 0$<br>(2): 计算所有样本内积形成的Gram矩阵$G$，</p>
<p>$G=[x_i \cdot x_j ]_{N \times N}$</p>
<p>(3): 在训练集中选取数据$(x_i, y_i)$，若</p>
<p>$y_i (\sum_{j=1}^{N} \alpha_j y_j x_j \cdot x_i + b) \leq 0$</p>
<p>计算过程中可通过查$G$的值来提高效率）则更新：</p>
<p>$$\alpha_i \leftarrow \alpha_i + \eta$$</p>
<p>$$b \leftarrow b + \eta y_i$$<br>(4): 转至(3)直至没有误分类数据</p>
</blockquote>
<p><em>Note:为什么要引入对偶形式？</em></p>
<ul>
<li><p>首先原始形式中，书中为何要使用随机梯度下降而非批量梯度下降法，个人搜索到的一篇博文里感觉说的有点道理，<a href="http://www.cnblogs.com/pinard/p/6042320.html" target="_blank" rel="external">引用</a>如下</p>
<blockquote>
<p>用普通的基于所有样本的梯度和的均值的批量梯度下降法（BGD）是行不通的，原因在于我们的损失函数里面有限定，只有误分类的M集合里面的样本才能参与损失函数的优化。所以我们不能用最普通的批量梯度下降,只能采用随机梯度下降（SGD）或者小批量梯度下降（MBGD）。 </p>
</blockquote>
</li>
<li><p>此外，关于对偶形式的优势，<a href="https://www.zhihu.com/question/26526858" target="_blank" rel="external">小结</a>一下：</p>
<ul>
<li>对偶形式将权重向量$w$转化为实例$x_i$和标记$y_i$的线性组合形式，且在原书中也提到，对偶形式中的训练实例仅以内积的形式出现，所以可以预先使用Gram矩阵存储，也就是时间换空间的方法提高计算效率</li>
<li>书中这里应该也有点为后续介绍支持向量机做铺垫，所以这里为核函数的引入埋一个伏笔，毕竟书中提到感知机是神经网络与支持向量机的基础，而且后面书中在支持向量机部分的讲解也多次使用对偶形式的求解</li>
</ul>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;script type=&quot;text/javascript&quot; async src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
&lt;/script&gt;

&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;感知机（perceptron）是&lt;strong&gt;二类分类的线性分类模型&lt;/strong&gt;，其输入为实例的特征向量，输出为实例的类别，取+1和-1二值。感知机对应于输入空间中将实例划分为正负两类的&lt;strong&gt;分离超平面&lt;/strong&gt;，属于&lt;strong&gt;判别模型&lt;/strong&gt;。感知机学习旨在求出将训练数据进行线性划分的分离超平面，为此导入了&lt;strong&gt;基于误分类的损失函数&lt;/strong&gt;，利用&lt;strong&gt;梯度下降法&lt;/strong&gt;对损失函数进行极小化，求得感知机模型。感知机学习算法具有简单而易于实现的优点，分为原始形式和对偶形式。感知机预测是用学习得到的感知基模型对新的输入实例进行分类。&lt;em&gt;感知机是神经网络与支持向量机的基础&lt;/em&gt;。&lt;br&gt;
    
    </summary>
    
    
      <category term="ML" scheme="http://yoursite.com/tags/ML/"/>
    
      <category term="Perceptron" scheme="http://yoursite.com/tags/Perceptron/"/>
    
      <category term="统计学习方法" scheme="http://yoursite.com/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    
      <category term="Note" scheme="http://yoursite.com/tags/Note/"/>
    
  </entry>
  
  <entry>
    <title>统计学习方法笔记(一)</title>
    <link href="http://yoursite.com/2017/06/02/Note-StatisticalML/"/>
    <id>http://yoursite.com/2017/06/02/Note-StatisticalML/</id>
    <published>2017-06-02T06:42:52.000Z</published>
    <updated>2017-06-02T13:43:42.567Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><em>本系列文章是个人根据阅读李航博士的《统计学习方法》一书，辅以《机器学习实战》、<a href="http://scikit-learn.org/" target="_blank" rel="external">scikit-learn官方文档</a>等材料整理出来的笔记。</em></p>
<h2 id="统计学习相关概念"><a href="#统计学习相关概念" class="headerlink" title="统计学习相关概念"></a>统计学习相关概念</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><blockquote>
<p>统计学习(statistical learning)是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测和分析的一门学科</p>
</blockquote>
<a id="more"></a>
<h3 id="研究对象"><a href="#研究对象" class="headerlink" title="研究对象"></a>研究对象</h3><p>数据</p>
<h3 id="研究目的"><a href="#研究目的" class="headerlink" title="研究目的"></a>研究目的</h3><p>对数据进行预测和分析：学习什么样的模型和如何学习模型（准确、效率）</p>
<h3 id="研究方法"><a href="#研究方法" class="headerlink" title="研究方法"></a>研究方法</h3><p>构建模型并应用模型进行预测和分析（统计学习方法三要素）</p>
<ul>
<li>模型：模型的假设空间，即学习模型的集合</li>
<li>策略：模型选择的准则</li>
<li>算法：模型学习的算法，求解最优模型的算法</li>
</ul>
<h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><ul>
<li>监督学习</li>
<li>非监督学习</li>
<li>半监督学习</li>
<li>强化学习</li>
</ul>
<h2 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h2><h3 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h3><p><img src="/materials/img/Note_StatisticalML_1/overview.jpg" alt="overview"></p>
<ul>
<li>输入空间：输入所有可能取值的集合</li>
<li>输出空间：输出所有可能取值的集合</li>
<li>特征空间：<ul>
<li>每个具体的输入是一个实例，通常由特征向量表示，所有特征向量存在的空间称为特征空间</li>
<li>有时输入空间与特征空间为相同的空间，不予区分，有时为不同的空间，需要将实例从输入空间映射到特征空间，<strong>模型实际上都是定义在特征空间上</strong></li>
</ul>
</li>
<li>假设空间：学习模型的集合（假设要学习的模型属于某个函数集合），模型属于由输入空间到输出空间的映射的集合，这个集合即假设空间，假设空间的确定意味着学习范围的确定。<ul>
<li>监督学习的模型<ul>
<li>概率模型：条件概率分布$P(Y|X)$</li>
<li>非概率模型：决策函数$Y=f(X)$</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="联合概率分布"><a href="#联合概率分布" class="headerlink" title="联合概率分布"></a>联合概率分布</h3><p>监督学习假设输入与输出的随机变量X和Y遵循联合概率分布$P(X, Y)$(<strong>监督学习关于数据的基本假设</strong>)</p>
<h3 id="监督学习分类"><a href="#监督学习分类" class="headerlink" title="监督学习分类"></a>监督学习分类</h3><ul>
<li>回归问题：输入变量与输出变量均为连续变量的预测问题。</li>
<li>分类问题：输出变量为有限个离散变量的预测问题。</li>
<li>标注问题：输入变量和输出变量均为变量序列的预测问题。</li>
</ul>
<h3 id="问题形式化"><a href="#问题形式化" class="headerlink" title="问题形式化"></a>问题形式化</h3><p>学习与预测——训练与测试</p>
<ul>
<li>学习：利用给定的训练数据集，通过学习（训练）得到一个模型；</li>
<li>预测：对于给定的测试样本中的输入，由所得到的模型给出相应的输出。</li>
</ul>
<h2 id="统计学习方法三要素-针对监督学习"><a href="#统计学习方法三要素-针对监督学习" class="headerlink" title="统计学习方法三要素(针对监督学习)"></a>统计学习方法三要素(针对监督学习)</h2><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>学习什么样的模型，在监督学习过程中，模型指的就是所要学习的条件概率分布或决策函数。</p>
<h3 id="策略（评价标准）"><a href="#策略（评价标准）" class="headerlink" title="策略（评价标准）"></a>策略（评价标准）</h3><p>模型选择的准则：按照什么样的准则学习或选择最优的模型</p>
<ul>
<li>损失函数（代价函数）：一次预测的好坏的度量，常用的包括0-1损失函数、平方损失函数、绝对损失函数、对数(似然)损失函数</li>
<li>风险函数（期望损失）：度量平均意义下模型预测的好坏<ul>
<li>经验风险</li>
<li>结构风险</li>
</ul>
</li>
</ul>
<p><strong>将监督学习的问题转化为经验风险或结构风险函数的最优化问题（结构风险最小的模型即最优模型）</strong></p>
<p><em>Note:在模型选择中，理论上应该使用<code>期望风险</code>函数作为标准，但是由于输入，输出的基本假设$P(X, Y)$联合分布未知（若已知则可直接求解P(Y|X)，不用学习），所以试图使用<code>经验风险</code>（平均损失）来替代，但又由于现实中限于样本容量不会很大，所以要对<code>经验风险</code>进行矫正，于是有了<code>结构风险</code>，在<code>经验风险</code>的基础上添加<code>正则化项</code>来防止过拟合。</em></p>
<h3 id="算法（求解-amp-优化）"><a href="#算法（求解-amp-优化）" class="headerlink" title="算法（求解&amp;优化）"></a>算法（求解&amp;优化）</h3><p>模型学习的算法，即学习模型的具体计算方法</p>
<ul>
<li>用什么样的计算方法求解最优模型（寻找全局最优解）</li>
<li>如何高效实现</li>
</ul>
<h2 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h2><h3 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h3><h4 id="训练误差-测试误差"><a href="#训练误差-测试误差" class="headerlink" title="训练误差*测试误差"></a>训练误差*测试误差</h4><ul>
<li>训练误差：对判断给定的问题是不是一个容易学习的问题是有意义的，但若一味追求减小训练误差，会出现过拟合的情况（所选模型的复杂度比真模型高）</li>
<li>测试误差：反映了学习方法对未知的测试数据集的预测能力，<strong>测试误差小的方法具有更好的预测能力</strong><br><img src="/materials/img/Note_StatisticalML_1/loss.jpg" alt="loss"><br>所以需要选择复杂度适当的模型，而模型选择常用的两种方法分别是<strong>正则化</strong>和<strong>交叉验证</strong>。</li>
</ul>
<h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><p>结构风险最小化策略的实现，在经验风险的基础上加一个正则化项/罚项</p>
<p>$$ R_{srm}(f)=\frac{1}{N}\sum L(y_i,f(x_i))+\lambda J(f) $$</p>
<p>作用是为了选择经验风险和模型复杂度同时较小的模型(在所有可能选择的模型中，能够很好地解释已知数据并且十分简单的，才是最好的模型)</p>
<h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><p>重复的使用数据</p>
<h4 id="数据集划分"><a href="#数据集划分" class="headerlink" title="数据集划分"></a>数据集划分</h4><ul>
<li>训练集：训练模型，通过输入数据学习函数中的参数值，得到拟合了数据的“分类器/回归器”等</li>
<li>验证集：模型选择，从不同的模型中选择最佳模型<ul>
<li>从不同类的模型中选择（比如从SVM,GBM,决策树里选择模型）</li>
<li>从同类模型不同超参数(hyperparameter)组合里选择最优超参数组合。</li>
</ul>
</li>
<li>测试集：最终对学习方法的评估<h4 id="常用方法"><a href="#常用方法" class="headerlink" title="常用方法"></a>常用方法</h4></li>
<li>简单交叉验证</li>
<li>S折交叉验证</li>
<li>留一交叉验证</li>
</ul>
<p><em>Note:关于数据集划分的一点理解理解可以参看<a href="/2017/06/01/cv/" title="交叉验证">交叉验证</a>，而关于模型选择可以进一步了解<a href="/2017/06/01/parameter-hyperparameter/" title="参数与超参数">参数与超参数</a></em></p>
<h3 id="学习的泛化能力"><a href="#学习的泛化能力" class="headerlink" title="学习的泛化能力"></a>学习的泛化能力</h3><h4 id="定义：学习方法的泛化能力-generalization-ability-是指由该方法学习到的模型对未知数据的预测能力。"><a href="#定义：学习方法的泛化能力-generalization-ability-是指由该方法学习到的模型对未知数据的预测能力。" class="headerlink" title="定义：学习方法的泛化能力(generalization ability)是指由该方法学习到的模型对未知数据的预测能力。"></a>定义：学习方法的泛化能力(generalization ability)是指由该方法学习到的模型对未知数据的预测能力。</h4><h4 id="评价方法"><a href="#评价方法" class="headerlink" title="评价方法"></a>评价方法</h4><ul>
<li>理论上：泛化误差即期望风险<br>$$ R_{exp}(f)=E_p[L(Y, f(X))]=\int L(y,f(x))P(x,y)dxdy $$</li>
<li>实际应用中：常常用测试误差衡量</li>
</ul>
<h4 id="泛化误差上界"><a href="#泛化误差上界" class="headerlink" title="泛化误差上界"></a>泛化误差上界</h4><p>通过比较两种学习方法的泛化误差上界来比较其优劣（越小越好）</p>
<ul>
<li>样本容量越大，泛化误差上界越小</li>
<li>假设空间越大，泛化误差上界越大</li>
</ul>
<p><strong>训练误差小的模型，其泛化误差也会小</strong></p>
<h2 id="生成模型与判别模型"><a href="#生成模型与判别模型" class="headerlink" title="生成模型与判别模型"></a>生成模型与判别模型</h2><h3 id="监督学习模型的一般形式"><a href="#监督学习模型的一般形式" class="headerlink" title="监督学习模型的一般形式"></a>监督学习模型的一般形式</h3><ul>
<li>概率模型：条件概率分布$P(Y|X)$</li>
<li>非概率模型：决策函数$Y=f(X)$</li>
</ul>
<h3 id="监督学习方法"><a href="#监督学习方法" class="headerlink" title="监督学习方法"></a>监督学习方法</h3><table>
<thead>
<tr>
<th>-</th>
<th>生成方法</th>
<th>判别方法</th>
</tr>
</thead>
<tbody>
<tr>
<td>定义</td>
<td>由数据学习联合概率分布$P(X, Y)$,然后求出$P(Y&#124;X)$作为预测的模型,$P(Y&#124;X)=\frac{P(X,Y)}{P(X)}$</td>
<td>由数据直接学习决策函数$f(x)$或条件概率分布$P(Y&#124;X)$作为预测模型</td>
</tr>
<tr>
<td>特点</td>
<td>1.可还原出$P(X, Y)$；<br>2.学习收敛速度更快；<br>3.存在隐变量时仍可用</td>
<td>1.直接面对预测，准确率更高；<br>2.便于数据抽象，特征定义和使用，可简化学习问题</td>
</tr>
<tr>
<td>典型模型</td>
<td>朴素贝叶斯法、隐马尔可夫模型</td>
<td>k-近邻、感知机、决策树、逻辑斯谛回归模型、最大熵模型、SVM、提升方法、条件随机场等</td>
</tr>
<tr>
<td>Note</td>
<td>模型表示了给定输入X产生输出Y的生成关系</td>
<td>判别方法关心的是对给定的输入X，应该预测什么样的输出Y</td>
</tr>
</tbody>
</table>
<h2 id="监督学习方法的应用"><a href="#监督学习方法的应用" class="headerlink" title="监督学习方法的应用"></a>监督学习方法的应用</h2><h3 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h3><p>在监督学习中，当输入变量Y取有限个离散值时，预测问题便成为分类问题</p>
<ul>
<li>多类分类问题，包括二分类</li>
<li>评价指标<ul>
<li>分类准确率</li>
<li>精确率&amp;召回率（二分类）——正类、负类、F1值</li>
</ul>
</li>
</ul>
<h3 id="标注问题"><a href="#标注问题" class="headerlink" title="标注问题"></a>标注问题</h3><p>可以认为是分类问题的一种推广，输入观测序列，输出标记序列(状态序列)</p>
<ul>
<li>学习&amp;标注——条件概率分布</li>
<li>评价指标<ul>
<li>标注准确率</li>
<li>精确率、召回率</li>
</ul>
</li>
<li>常用统计学习方法<ul>
<li>隐马尔可夫模型</li>
<li>条件随机场</li>
</ul>
</li>
<li>应用领域<ul>
<li>信息抽取</li>
<li>自然语言处理</li>
</ul>
</li>
</ul>
<h3 id="回归问题"><a href="#回归问题" class="headerlink" title="回归问题"></a>回归问题</h3><p>回归用于预测输入变量（自变量）和输出变量（因变量）之间的关系——函数拟合</p>
<ul>
<li>学习&amp;预测<ul>
<li>一元回归 vs 多元回归</li>
<li>线性回归 vs 非线性回归</li>
<li>损失函数：常用平方损失函数—— <a href="https://zh.wikipedia.org/wiki/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95" target="_blank" rel="external">最小二乘法</a></li>
</ul>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;script type=&quot;text/javascript&quot; async src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
&lt;/script&gt;

&lt;p&gt;&lt;em&gt;本系列文章是个人根据阅读李航博士的《统计学习方法》一书，辅以《机器学习实战》、&lt;a href=&quot;http://scikit-learn.org/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;scikit-learn官方文档&lt;/a&gt;等材料整理出来的笔记。&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&quot;统计学习相关概念&quot;&gt;&lt;a href=&quot;#统计学习相关概念&quot; class=&quot;headerlink&quot; title=&quot;统计学习相关概念&quot;&gt;&lt;/a&gt;统计学习相关概念&lt;/h2&gt;&lt;h3 id=&quot;定义&quot;&gt;&lt;a href=&quot;#定义&quot; class=&quot;headerlink&quot; title=&quot;定义&quot;&gt;&lt;/a&gt;定义&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;统计学习(statistical learning)是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测和分析的一门学科&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="ML" scheme="http://yoursite.com/tags/ML/"/>
    
      <category term="统计学习方法" scheme="http://yoursite.com/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    
      <category term="Note" scheme="http://yoursite.com/tags/Note/"/>
    
  </entry>
  
  <entry>
    <title>关于交叉验证和模型选择的一点思考</title>
    <link href="http://yoursite.com/2017/06/01/cv/"/>
    <id>http://yoursite.com/2017/06/01/cv/</id>
    <published>2017-06-01T12:28:36.000Z</published>
    <updated>2017-06-01T12:36:16.424Z</updated>
    
    <content type="html"><![CDATA[<p> 首先按照《统计学习方法》第一章的内容，常用的模型选择方法有两种，按照结构风险最小化思想的具体实现即<strong>正则化</strong>以及数据驱动的<strong>交叉验证方法</strong>。</p>
<ul>
<li>CV是用于模型的(评估)挑选和<strong>超参数</strong>(关于超参数和参数的区别请见另一篇<a href="/2017/06/01/parameter-hyperparameter/" title="memo">memo</a>)调整的，首先明确一点，所谓模型，指的是我们用来描述输入数据与最终需要预测的输出数据之间的关联的方法，而不是不同数据拟合的模型得到的实例，比如我们可以说一个<strong>线性回归模型</strong>，但是不会说用不同数据拟合的<strong>线性回归器</strong>为不同的模型；<a id="more"></a></li>
<li>为什么要用CV，这涉及到数据划分的问题，首先我们训练好一个模型后需要评估这个模型的效果，但是如果把全部数据都投入训练就没有数据来进行验证了，常规而言，可以将数据集划分为训练集和验证集比如80%训练、20%验证，但是这样会有一些问题，首先有可能你很不巧的将一些特殊数据划分到这20%的验证集里了(要么效果很好、要么效果很糟糕)，这样的话仅仅这么一组验证集的评估效果就很不稳定也不确切；此外我们划分训练集和验证集就减少了训练数据，而一般而言数据越多训练出的模型方差是越小的，从这个角度来看数据越多一般我们训练的效果更好；</li>
<li>那么有没有方法既可以用上所有数据进行验证和评估、最后又可以用所有数据进行训练呢？所以我们就需要交叉验证，比如五折交叉验证，假设我们仍将数据集8-2划分（80%-20%），对于五折交叉验证，我们就是针对模型进行了五次训练，每次取80%训练数据、20%验证数据，并最终保证每个数据都曾在这五次训练验证中作为20%的验证集对模型进行过评估，这样我们就可以确保我们使用了所有数据对我们的模型进行评估</li>
<li>为什么不用CV中得到的预测器进行预测？一般而言，在做交叉验证时确实可能出现某一组交叉验证的得分较高，我们会试图用这一组数据进行模型的拟合和最终预测，但是这种得分高只是一种表面现象，首先数据量少了，其次这一组验证集并非独立的，是在整个交叉验证中随机生成的，所以这个预测器的结果到底好不好还需要在对额外的数据进行测试，如果数据重组也许你可以用<a href="https://stats.stackexchange.com/a/52312/152084" target="_blank" rel="external">嵌套式的交叉验证</a>进行实验，即第一步用常规内层交叉验证确定最佳模型，然后采用数据驱动的方式(外层交叉验证)拟合最佳的一组预测器</li>
<li>所以CV的作用是用来对不同模型（SVM和生成树等），不同参数的模型中评估各个模型的效果，而得到最佳参数组合的模型；接下来将所有训练集投入进去拟合预测得到拟合好的预测器最后对测试集进行预测</li>
<li>那么把所有训练集放到模型中会不会导致过拟合呢？答案是不会，过拟合产生的原因是模型过于复杂（模型的参数），而不是数据增加导致，（而不是传入参数的值），增加数据一般而言更有利于训练集的训练</li>
<li><p>补充：关于生成树模型中的early_stopping，按照《统计学习方法》一书的第12章总结部分P213所述</p>
<blockquote>
<p>提升方法没有现实的正则化项，通常通过早停止(early stopping)的方法达到正则化的效果</p>
</blockquote>
<p>所以early_stopping属于正则化的范畴，是另一种模型选择的具体方法。</p>
<p>参考资料<br><a href="https://stats.stackexchange.com/a/52277/152084" target="_blank" rel="external">https://stats.stackexchange.com/a/52277/152084</a><br><a href="http://scikit-learn.org/stable/modules/cross_validation.html" target="_blank" rel="external">http://scikit-learn.org/stable/modules/cross_validation.html</a><br><a href="https://stats.stackexchange.com/a/52312/152084" target="_blank" rel="external">https://stats.stackexchange.com/a/52312/152084</a></p>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt; 首先按照《统计学习方法》第一章的内容，常用的模型选择方法有两种，按照结构风险最小化思想的具体实现即&lt;strong&gt;正则化&lt;/strong&gt;以及数据驱动的&lt;strong&gt;交叉验证方法&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CV是用于模型的(评估)挑选和&lt;strong&gt;超参数&lt;/strong&gt;(关于超参数和参数的区别请见另一篇&lt;a href=&quot;/2017/06/01/parameter-hyperparameter/&quot; title=&quot;memo&quot;&gt;memo&lt;/a&gt;)调整的，首先明确一点，所谓模型，指的是我们用来描述输入数据与最终需要预测的输出数据之间的关联的方法，而不是不同数据拟合的模型得到的实例，比如我们可以说一个&lt;strong&gt;线性回归模型&lt;/strong&gt;，但是不会说用不同数据拟合的&lt;strong&gt;线性回归器&lt;/strong&gt;为不同的模型；
    
    </summary>
    
    
      <category term="ML" scheme="http://yoursite.com/tags/ML/"/>
    
      <category term="CV" scheme="http://yoursite.com/tags/CV/"/>
    
      <category term="model selection" scheme="http://yoursite.com/tags/model-selection/"/>
    
  </entry>
  
  <entry>
    <title>机器学习中模型的参数和超参数</title>
    <link href="http://yoursite.com/2017/06/01/parameter-hyperparameter/"/>
    <id>http://yoursite.com/2017/06/01/parameter-hyperparameter/</id>
    <published>2017-06-01T12:24:11.000Z</published>
    <updated>2017-06-01T12:27:02.876Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p>一直以来对于机器学习中的模型训练和模型选择存在一个误区，首先机器学习力的模型通俗来说就是一个函数关系，表明输入数据到输出数据的映射，基本的假设前提是输入数据和输出数据符合某种联合概率分布，而模型训练的过程其实就是在确定函数式的具体参数值的过程，比如假设你要做一个多项式回归分析的模型，比如$f(x)=w_1x_1+w_2x_2+w_3x_3$，那么模型训练的过程中其实就是在学习对应的<code>w</code>的值，那么问题来了，实战中所谓的模型调参来选择模型又指的是什么呢？<a id="more"></a>既然训练已经把参数都确定下来了，那我们调整的参数又是什么？原来这里有个误区在于模型中的<code>parameter</code>和<code>hyperparameter</code>的区别，按照搜集到的资料来看，其实模型中可以分为两种参数，一种是在<strong>训练过程中学习到的参数，即<code>parameter</code></strong>也就是上面公式里的<code>w</code>，而另一种参数则是<code>hyperparameter</code>，这种参数是模型中学习不到的，是我们预先定义的，而模型的调参其实指的是调整<code>hyperparameter</code>，而且不同类型的模型的<code>hyperparameter</code>也不尽相同，比如SVM中的C,树模型中的深度、叶子数以及比较常规的学习率等等，这种参数是在模型训练之前预先定义的，所以关于模型的选择其实更多的指的是选择最佳的<code>hyperparameter</code>组合。</p>
<p>参考资料<br><a href="https://datascience.stackexchange.com/a/14234/31117" target="_blank" rel="external">https://datascience.stackexchange.com/a/14234/31117</a><br><a href="https://www.quora.com/What-are-hyperparameters-in-machine-learning" target="_blank" rel="external">https://www.quora.com/What-are-hyperparameters-in-machine-learning</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;script type=&quot;text/javascript&quot; async src=&quot;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
&lt;/script&gt;

&lt;p&gt;一直以来对于机器学习中的模型训练和模型选择存在一个误区，首先机器学习力的模型通俗来说就是一个函数关系，表明输入数据到输出数据的映射，基本的假设前提是输入数据和输出数据符合某种联合概率分布，而模型训练的过程其实就是在确定函数式的具体参数值的过程，比如假设你要做一个多项式回归分析的模型，比如$f(x)=w_1x_1+w_2x_2+w_3x_3$，那么模型训练的过程中其实就是在学习对应的&lt;code&gt;w&lt;/code&gt;的值，那么问题来了，实战中所谓的模型调参来选择模型又指的是什么呢？
    
    </summary>
    
    
      <category term="ML" scheme="http://yoursite.com/tags/ML/"/>
    
      <category term="memo" scheme="http://yoursite.com/tags/memo/"/>
    
      <category term="parameter" scheme="http://yoursite.com/tags/parameter/"/>
    
      <category term="hyperparameter" scheme="http://yoursite.com/tags/hyperparameter/"/>
    
  </entry>
  
  <entry>
    <title>计算机与生活</title>
    <link href="http://yoursite.com/2017/05/30/computer-life/"/>
    <id>http://yoursite.com/2017/05/30/computer-life/</id>
    <published>2017-05-30T11:57:01.000Z</published>
    <updated>2017-05-30T12:05:27.424Z</updated>
    
    <content type="html"><![CDATA[<p>阅读完吴军的《浪潮之巅》，给人的感觉颇有点当初看纪录片《互联网时代》的感觉，简单而言就是你透过作者的眼睛快速浏览了一遍计算机这个行业的发展历程；手头的这本是第二版，看出版时间也是2012年了，到现在算算有点老了，不过对于12年以前发生的一些事情还是能有一个大致的梳理；<br>    这本书上册主要讲述了一些在历史中唱过主角的公司，关于这些公司的兴衰以及作者自己的一些分析判断，下册则更宽泛一点，除了谈谈部分公司，还科普了一些计算机工业界以及商业方面的概念，比如谈信息产业的一些规律，一些公司的商业模式甚至风险投资，金融风暴等等；<br>    下面我想简单谈一谈自己读过这本书的一点点体会，关于计算机和人类的生活。<br><a id="more"></a><br>    我粗略的将计算机的发展历程划分为四个大的阶段，分别是计算时代—自动化时代—互联网时代—数据时代；计算时代比较有代表性的是计算机ENIAC，那个时候还主要用作军事用途，用来计算导弹轨迹之类的，离走进我们的生活还比较远，第二阶段自动化时代比较有代表性的就是微机了（当然这里跳过了面向企业的工作站，主要谈与个人生活相关的），按照作者的说法，这一阶段最有代表性的是三个公司，苹果的个人电脑（一体化）和微软与Intel的联盟（WinTel体系），这一阶段计算机真正开始走入普通人的家庭生活，主要是用于协助处理一些日常的办公工作，属于单机阶段；然后是大家比较熟悉的互联网时代，这一阶段的强大之处在于将计算机连接起来，于是每个用户都不再是孤立的，随着因特网的出现，有一部分人将本地的内容放到了网上，这个时候网上的内容不多，但是比较杂乱无序，所以随之诞生了门户网站比如雅虎等等，他们将互联网上的内容分门别类从而使用户便于查看和获取信息；而随着建立网站的门槛降低，互联网上的内容越来越多，单纯靠人工分类的的门户网站已经满足不了人们的需求了，于是搜索引擎（代表是Google）应运而生，帮助用户在浩瀚的互联网中快速找到自己所需的信息；<br>    如果说互联网时代的关键词是‘内容’；那么数据时代的关键词就是平台了。这个时候，人们已经不满足于只是从互联网上获取信息了，就像不满足于只是从电视接受固定的节目一样，用户开始有‘发出自己的声音’的诉求，也就是创作；于是各个平台相继出现，最有代表性的，早期的Blog可以允许用户自己在网上发布自己的文章，然后是Facebook、Twitter不仅为用户构建了虚拟的社交圈，而且让用户可以在这个圈子里随时随地发出自己的声音并与其他人互动，还有YouTube把平台交给用户，让用户自己去发布自己的视频和收看其他用户的视频；这一阶段的特点是‘平台’ ，比较有代表性的公司并不提供内容，而是让用户自己来做内容的创造者。<br>    而随之而来的是数据的爆发，互联网上的信息变得更加庞杂，在不断炒来炒去的概念‘云计算’，‘大数据’的驱动下，计算机的同学们纷纷投身到数据分析/数据挖掘的工作中，希望能够从庞杂的数据中挖掘出与实际业务相关的有价值的信息；那么，下一步人们的需求在哪呢？是通过数据挖掘对一个人建立画像从而实现对每个人的私人定制服务？还是现在炙手可热的基于VR/AR的虚拟社交？按照前段时间看到的一个关于区块链的演讲，在未来每个人都可以被“数字化”，真实世界的你可以投影到虚拟世界成为一个数字化的、独一无二的你，这大概是一种趋势吧。<br>    最后还是推荐下这本书，作为科普类的读物挺不错的。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;阅读完吴军的《浪潮之巅》，给人的感觉颇有点当初看纪录片《互联网时代》的感觉，简单而言就是你透过作者的眼睛快速浏览了一遍计算机这个行业的发展历程；手头的这本是第二版，看出版时间也是2012年了，到现在算算有点老了，不过对于12年以前发生的一些事情还是能有一个大致的梳理；&lt;br&gt;    这本书上册主要讲述了一些在历史中唱过主角的公司，关于这些公司的兴衰以及作者自己的一些分析判断，下册则更宽泛一点，除了谈谈部分公司，还科普了一些计算机工业界以及商业方面的概念，比如谈信息产业的一些规律，一些公司的商业模式甚至风险投资，金融风暴等等；&lt;br&gt;    下面我想简单谈一谈自己读过这本书的一点点体会，关于计算机和人类的生活。&lt;br&gt;
    
    </summary>
    
    
      <category term="Reading" scheme="http://yoursite.com/tags/Reading/"/>
    
      <category term="IT" scheme="http://yoursite.com/tags/IT/"/>
    
  </entry>
  
  <entry>
    <title>来来来，我教你搭个博客好不好哇</title>
    <link href="http://yoursite.com/2017/05/30/my-blog/"/>
    <id>http://yoursite.com/2017/05/30/my-blog/</id>
    <published>2017-05-30T10:40:58.000Z</published>
    <updated>2017-05-31T01:21:37.987Z</updated>
    
    <content type="html"><![CDATA[<p>先把我的博客贴一下<a href="izhaoyi.top">Lancelot’s Desert</a></p>
<p>端午节两天时间宅实验室把自己搭建一个博客这么个‘历史遗留问题’解决了下，其实之前也用Hugo搭建过，最后给弄崩了，这次尝试下<a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="external">Hexo</a>，发现倒是异常的顺利，一方面Hexo的整体生态比较完备，另一方面网上找到的教程也很靠谱，下面就把我搭建过程中的一些步骤和踩过的坑记录下。<br><a id="more"></a></p>
<h2 id="基础博客搭建"><a href="#基础博客搭建" class="headerlink" title="基础博客搭建"></a>基础博客搭建</h2><p>首先声明下，基础博客搭建基本上和我所参照的<a href="https://zhuanlan.zhihu.com/p/25471760" target="_blank" rel="external">崔斯特</a>的教程是一致的，只是在顺序和语言上重新组织了一下，因为原博主写的教程已经很简明扼要了。</p>
<h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><ul>
<li><a href="https://github.com/waylau/git-for-win" target="_blank" rel="external">git下载</a></li>
<li><a href="https://github.com/" target="_blank" rel="external">github账号</a></li>
<li><a href="https://nodejs.org/en/" target="_blank" rel="external">node.js</a></li>
</ul>
<p>另外的话写博客最好熟悉一点<a href="https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#lists" target="_blank" rel="external">markdown</a>的基本语法，常用的指令不多而且很简单，用的熟练是非常不错的工具，这里也推荐一个markdown的不错的在线编辑器<a href="https://www.zybuluo.com/mdeditor#323984" target="_blank" rel="external">Cmd markdown</a>即时预览的，此外，类似简书、SegmentFault这些网站也是支持MarkDown编辑的，所以如果熟悉这个语法的话还是很方便的。</p>
<h4 id="下载和注册"><a href="#下载和注册" class="headerlink" title="下载和注册"></a>下载和注册</h4><p>基础搭建的话首先需要下载git和node.js(npm)来进行控制台命令的一些输入，以及需要一个github账号，因为我们的博客是挂载在github上的。</p>
<p>在下载好<code>git</code>和<code>node.js</code>并注册好一个<code>github账号</code>后，首先新建一个repository，名称和你的账户名一致，后面添加<code>.github.io</code>域名，比如我的用户名是<code>LancelotHolmes</code>,那么我的repository命名就是<code>LancelotHolmes.github.io</code></p>
<p><img src="/materials/img/my_blog/github.jpg" alt="github"></p>
<h4 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h4><p>在完成上述操作并安装好<code>git</code>和<code>node.js</code>之后，我们选择一个路径新建一个文件夹比如我是在D盘的MyBlog，然后执行<code>git bash</code>，可以在开始里搜索，也可以右键然后选择<code>git bash here</code>,在出现的<code>git</code>控制台中输入之前注册的github账号相对应信息，比如<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git config --<span class="keyword">global</span> user.name <span class="string">"你的账户名"</span></div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git config --<span class="keyword">global</span> user.email <span class="string">"注册github账号时的邮箱"</span></div></pre></td></tr></table></figure>
<p>如图</p>
<p><img src="/materials/img/my_blog/git.jpg" alt="git"></p>
<p>然后是安装Hexo,直接输入</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">npm install -g hexo-cli</div></pre></td></tr></table></figure>
<h4 id="开始搭建"><a href="#开始搭建" class="headerlink" title="开始搭建"></a>开始搭建</h4><p>同样在MyBlog(或者你命名的目录下)，仍然是刚刚的控制台界面，输入<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo init blog</div></pre></td></tr></table></figure></p>
<p>成功的时候会显示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">INFO  Start blogging <span class="keyword">with</span> Hexo!</div></pre></td></tr></table></figure>
<p>接下来进入blog目录下，输入<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">hexo clean</div><div class="line">hexo g</div><div class="line">hexo s</div></pre></td></tr></table></figure></p>
<p>或者你也可以新建一个<code>generate.sh</code>脚本文件将上面三条语句写入,因为后面线下测试会多次用到，可以直接在控制台输入<code>./generate.sh</code>，然后在浏览器里输入<a href="http://localhost:4000/" target="_blank" rel="external">http://localhost:4000/</a>,这个时候你就可以看到一个网页的基本雏形，这是由于你的<code>\blog\source\_posts</code>路径下已经有一个基本的markdown文件了，而且本身下载的Hexo带了一个<code>landscape</code>的主题文件，在路径<code>\blog\themes</code>下可以看到</p>
<p><img src="/materials/img/my_blog/hello.jpg" alt="hello"></p>
<h2 id="配置github"><a href="#配置github" class="headerlink" title="配置github"></a>配置github</h2><h3 id="SSH"><a href="#SSH" class="headerlink" title="SSH"></a>SSH</h3><p>回到控制台，现在我们需要生成SSH，仍然是在<code>git</code>控制台里，输入</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ssh-keygen -t rsa -C <span class="string">"Github的注册邮箱地址"</span></div></pre></td></tr></table></figure>
<p>基本是一直回车，到出现信息<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Your public key has been saved <span class="keyword">in</span> /c/Users/user/.ssh/id_rsa.pub.</div></pre></td></tr></table></figure></p>
<p>在信息对应的路径下找到这个文件，打开它(我是用sublime text打开的)，在你的github界面，右上角头像里选择<code>Settings</code>,左侧选择<code>SSH and GPG keys</code>然后新建一个<code>SSH key</code>,名称随你定，比如我是设置的blog,内容的话把刚刚<code>id_rsa.pub</code>里的内容全选复制进去就好了。</p>
<p><img src="/materials/img/my_blog/ssh.jpg" alt="ssh"></p>
<h3 id="站点配置"><a href="#站点配置" class="headerlink" title="站点配置"></a>站点配置</h3><p>在blog目录下，用sublime或者其他编辑器打开<code>_config.yml</code>文件，找到对应的字段修改下面的基本参数信息，这里需要注意一下存在多个<code>_config.yml</code>文件，一个是在blog目录下，作为站点配置文件，一般用来做一些常规的配置，另外在各个主题的目录下还有一个<code>_config.yml</code>文件用来进行特定主体的一些个性化设置，后面会经常用到这两个文件，另外就是下面的配置<strong>注意:之后的空格</strong></p>
<p>博客基本信息<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">title: 博客名称</div><div class="line">subtitle: 副标题</div><div class="line">description: 网页描述</div><div class="line">author: 作者名</div></pre></td></tr></table></figure></p>
<p>推送设置（这里的repo注意修改为自己的github的对应格式）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">deploy:</div><div class="line">  type: git</div><div class="line">  repo: https://github.com/LancelotHolmes/LancelotHolmes.github.io.git</div><div class="line">  branch: master</div></pre></td></tr></table></figure></p>
<h3 id="新建文章"><a href="#新建文章" class="headerlink" title="新建文章"></a>新建文章</h3><p>在控制台输入</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo n <span class="string">"文章名称"</span></div></pre></td></tr></table></figure>
<p><img src="/materials/img/my_blog/new.jpg" alt="new"></p>
<p>这样会在<code>\blog\source\_posts</code>目录下生成对应的markdown文件，你可以通过编辑器打开它并书写你的文章，比如<br><img src="/materials/img/my_blog/computer.jpg" alt="computer"><br>保存后同样的执行<code>./generate.sh</code>然后打开<a href="http://localhost:4000/" target="_blank" rel="external">http://localhost:4000/</a>就可以看到你刚刚写好的的文章了。</p>
<p><img src="/materials/img/my_blog/show.jpg" alt="show"></p>
<p>当然我这里展示的界面略有不同，因为我这里设置主题，后面会具体介绍。</p>
<h3 id="推送到github"><a href="#推送到github" class="headerlink" title="推送到github"></a>推送到github</h3><p>线下测试发现没有什么问题我们就可以推送到github了，输入如下命令，或者保存为脚本文件<code>deploy.sh</code>然后执行<code>./deploy.sh</code><br>第一次部署到github时可能会出错<code>error deployer not found:github</code>，可以在控制台输入,注意<code>--save</code>必不可少<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">npm install hexo-deployer-git --save</div></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hexo clean</div><div class="line">hexo d -g</div></pre></td></tr></table></figure>
<p>过程中会让你输入你的github账号和密码，推送成功后，你就可以通过在浏览器输入你的静态站点名称访问你的博客了，比如<code>LancelotHolmes.github.io</code>,至此一个基本的博客就搭好了，接下来你每次需要写文章只需要经过如下步骤</p>
<ul>
<li>在blog路径下打开<code>git bash</code>控制台然后输入<code>hexo n &quot;文章名&quot;</code></li>
<li>在路径<code>\blog\source\_posts</code>中编辑对应的markdown，编辑好后保存</li>
<li>执行generate.sh进行线下预览（可选）</li>
<li>执行deploy.sh推送到github就可以通过你的站点访问啦</li>
</ul>
<hr>
<h2 id="配置yilia主题"><a href="#配置yilia主题" class="headerlink" title="配置yilia主题"></a>配置yilia主题</h2><p>前面也给大家看到了我的博客的截图，这里我使用的是<a href="https://github.com/litten/hexo-theme-yilia" target="_blank" rel="external">yilia</a>主题，目前Hexo主题里面比较热门的两大主题是<a href="https://github.com/iissnan/hexo-theme-next" target="_blank" rel="external">Next</a>和<a href="https://github.com/litten/hexo-theme-yilia" target="_blank" rel="external">yilia</a>,这里我就我所配置的一些功能和踩过的坑记录一下。主要包括一些基本的配置以及优化</p>
<h3 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置</h3><p>基本的主题下载和安装可以直接参照yilia的github对应的<a href="https://github.com/litten/hexo-theme-yilia#配置" target="_blank" rel="external">教程</a>，同样在blog目录下执行<code>git bash</code>控制台，输入<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/litten/hexo-theme-yilia.git themes/yilia</div></pre></td></tr></table></figure></p>
<p>然后修改站点配置文件，Hexo根目录下(即blog目录的)的 <code>_config.yml</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">theme: yilia</div></pre></td></tr></table></figure></p>
<p>然后再该文件末尾添加如下语句<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">jsonContent:</div><div class="line">  meta: false</div><div class="line">  pages: false</div><div class="line">  posts:</div><div class="line">    title: true</div><div class="line">    date: true</div><div class="line">    path: true</div><div class="line">    text: true</div><div class="line">    raw: false</div><div class="line">    content: false</div><div class="line">    slug: false</div><div class="line">    updated: false</div><div class="line">    comments: false</div><div class="line">    link: false</div><div class="line">    permalink: false</div><div class="line">    excerpt: false</div><div class="line">    categories: false</div><div class="line">    tags: true</div></pre></td></tr></table></figure></p>
<h3 id="添加disqus评论"><a href="#添加disqus评论" class="headerlink" title="添加disqus评论"></a>添加disqus评论</h3><p>目前使用的评论比较多，我早期Hugo时使用过<a href="https://disqus.com/" target="_blank" rel="external">disqus</a>也就还是用这个了，主要是需要注册一个disque账号，然后修改<strong>主题目录下的<code>_config.yml</code> 文件</strong>，特别注意这里的路径是<code>\blog\themes\yilia</code>,不再是blog下的文件，后面大部分配置都是针对这个文件<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">disqus: LancelotHolmes</div></pre></td></tr></table></figure></p>
<p>这里的修改为你注册的disqus的<code>short-name</code>,yilia主题下的配置会优先覆盖blog下的配置，如果你是使用其他的评论比如多说，顺言之类的应该适时修改相应的字段后面的false为对应的值，效果如下</p>
<p><img src="/materials/img/my_blog/disqus.jpg" alt="disqus"></p>
<h3 id="添加menu"><a href="#添加menu" class="headerlink" title="添加menu"></a>添加menu</h3><p>原始的主题menu是这样的<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">menu:</div><div class="line">  主页: /</div><div class="line">  随笔: /tags/随笔/</div></pre></td></tr></table></figure></p>
<p>，我们可以修改为我们所需要的‘类别’，注意由于yilia作者没有预先设置类别（category）而是把他当作tags使，所以这里配置时链接到对应的tags下的路径，修改如下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">menu:</div><div class="line">  主页: /</div><div class="line">  阅读: /tags/Reading/</div><div class="line">  机器学习: /tags/ML/</div></pre></td></tr></table></figure></p>
<p>可以根据需要在新建文章是设置标签自动生成对应的路径，可以在<code>\blog\public\tags</code>下看到，然后修改<code>menu</code>下的对应字段即可</p>
<h3 id="RSS-amp-Sitemap"><a href="#RSS-amp-Sitemap" class="headerlink" title="RSS &amp; Sitemap"></a>RSS &amp; Sitemap</h3><p>为什么要用RSS,可以看这篇<a href="http://www.ruanyifeng.com/blog/2006/01/rss.html" target="_blank" rel="external">短文</a>，主要是为了方便对你的博客感兴趣的人将你的博客添加到他的订阅列表中，一旦你有更新他可以在第一时间接收到推送。而<code>sitemap</code>则主要是给搜索引擎用的，方便你的站点能够被google收录，当然这里首先需要绑定一个域名，后续我们会具体介绍。<br>这部分主要是参照<a href="http://www.voidking.com/2015/05/31/deve-hexo-theme-optimize/#添加sitemap" target="_blank" rel="external">voidking</a>和<a href="http://blog.magicwang.tech/post/Hexo-Yilia-%E4%B8%BB%E9%A2%98%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/#添加rsssitemap多说头像" target="_blank" rel="external">magicwangs</a>的博客，执行如下语句<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">npm install hexo-generator-feed --save</div><div class="line"></div><div class="line">npm install hexo-generator-sitemap --save</div></pre></td></tr></table></figure></p>
<p>然后照常的执行generate.sh，你可以在路径<code>\blog\public</code>下看到生成的文件<code>atom.xml</code>和<code>sitemap.xml</code>,接下来在<strong>主题目录下的<code>_config.yml</code> 文件</strong>，特别注意这里的路径是<code>\blog\themes\yilia</code>里添加<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># SubNav</span></div><div class="line">subnav:</div><div class="line">  github: <span class="string">"#"</span></div><div class="line">  weibo: <span class="string">"#"</span></div><div class="line">  rss: /atom.xml</div><div class="line">  ...</div></pre></td></tr></table></figure></p>
<p>此外在blog目录下的站点配置文件里(这回是在<code>\blog</code>路径下的_config.yml)添加如下语句<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Sitemap</span></div><div class="line">sitemap:</div><div class="line">    path: sitemap.xml</div><div class="line">baidusitemap:</div><div class="line">    path: baidusitemap.xm</div><div class="line"></div><div class="line"><span class="comment"># RSS</span></div><div class="line">feed:</div><div class="line">    type: atom</div><div class="line">    path: atom.xml</div><div class="line">    limit: <span class="number">100</span></div></pre></td></tr></table></figure></p>
<h3 id="头像设置"><a href="#头像设置" class="headerlink" title="头像设置"></a>头像设置</h3><p>有采用本地图片的，也有将图片传到网上制成外链的，我就是用后面那种方法，这里给大家推荐一个不错的工具<a href="https://sm.ms/" target="_blank" rel="external">sm.ms</a>，方便你把你的本地图片传到网上制成markdown、html、url等格式的外部链接<br><img src="/materials/img/my_blog/smms.jpg" alt="smms"><br>制作好后，修改<strong>主题目录下的<code>_config.yml</code> 文件</strong>，注意这里的路径是<code>\blog\themes\yilia</code>里</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#你的头像url</span></div><div class="line">avatar: https://ooo<span class="number">.0</span>o0.ooo/<span class="number">2017</span>/<span class="number">05</span>/<span class="number">29</span>/<span class="number">592</span>be5c575c4c.jpg</div></pre></td></tr></table></figure>
<p>链接当然是你刚刚生成的url的链接</p>
<h3 id="其他社交外链"><a href="#其他社交外链" class="headerlink" title="其他社交外链"></a>其他社交外链</h3><p>同样是修改<strong>主题目录下的<code>_config.yml</code> 文件</strong>，注意这里的路径是<code>\blog\themes\yilia</code>里，位置与之前的rss的地方差不多，根据你想展示的社交平台设置，注意链接是你的社交平台的主页之类的，比如<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># SubNav</span></div><div class="line">subnav:</div><div class="line">  github: <span class="string">"https://github.com/LancelotHolmes/"</span></div><div class="line">  weibo: <span class="string">"http://weibo.com/2925991784/profile?topnav=1&amp;wvr=6"</span></div></pre></td></tr></table></figure></p>
<h3 id="文章截断"><a href="#文章截断" class="headerlink" title="文章截断"></a>文章截断</h3><p>直接生成的文章在主页会全部显示，如果不处理会占据较大的篇幅，我们可以在文章的特定位置设置文章截断，这样主页展示的就是部分文字，首先仍然是修改<strong>主题目录下的<code>_config.yml</code> 文件</strong>，注意这里的路径是<code>\blog\themes\yilia</code>里</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Content</span></div><div class="line"></div><div class="line"><span class="comment"># 文章太长，截断按钮文字</span></div><div class="line">excerpt_link: more</div></pre></td></tr></table></figure>
<p>然后在你的文章的md文件里你想要阶段的位置插入语句<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;!-- more --&gt;</div></pre></td></tr></table></figure></p>
<p>例如<br><img src="/materials/img/my_blog/cut.jpg" alt="cut"></p>
<p>这样就实现了文章的截断，而需要阅读全文只需要点击相应的按钮或者标题即可</p>
<h3 id="favicon"><a href="#favicon" class="headerlink" title="favicon"></a>favicon</h3><p>这个主要是为了好玩，就是你的网页打开后的在浏览器的上面的一个小图标，比如github和我的博客的favicon</p>
<p><img src="/materials/img/my_blog/fav.jpg" alt="fav"></p>
<p>我是在<a href="https://www.freefavicon.com/freefavicons/" target="_blank" rel="external">freefavicon</a>上直接选的一个，如果你有兴趣可以自己制作16<em>16的图片就行了，将图片复制到路径<code>\blog\public</code>下，然后在<em>*主题目录下的<code>_config.yml</code> 文件</em></em>里修改即可</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">favicon: /favicon.png</div></pre></td></tr></table></figure>
<h3 id="文章目录"><a href="#文章目录" class="headerlink" title="文章目录"></a>文章目录</h3><p>这个是作者目前没有实现的部分，但是有其他的方法，主要参照的是这个<a href="https://github.com/litten/hexo-theme-yilia/pull/120/files" target="_blank" rel="external">post</a>,修改主要涉及这么两个文件</p>
<ul>
<li><p>在<code>/themes/yilia/layout/_partial/article.ejs</code>文件里18行左右的位置插入</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&lt;% if (!index)&#123; %&gt;</div><div class="line">   &lt;% if (toc(post.content))&#123; %&gt;            </div><div class="line">     &lt;div id="toc" class="article-toc"&gt;</div><div class="line">     &lt;h2&gt;目录&lt;/h2&gt;</div><div class="line">      &lt;%- toc(post.content) %&gt;  </div><div class="line">    &lt;/div&gt;</div><div class="line">    &lt;script type="text/javascript"&gt;</div><div class="line">       var _article = document.getElementsByClassName('article')[0];</div><div class="line">       &lt;!-- setTimeout("_article.style.marginRight = '211px'",0);  --&gt;</div><div class="line">       setTimeout("_article.className += ' article2'",0); </div><div class="line">       setTimeout("document.getElementById('toc').style.right = '15px'", 0);                </div><div class="line">     &lt;/script&gt;</div><div class="line">   &lt;% &#125; %&gt;</div><div class="line"> &lt;% &#125; %&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>在<code>\themes\yilia\source-src\css\article.scss</code>文件的末尾添加</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@media (max-width: 1099px)&#123;</span></div><div class="line">   <span class="comment">#toc&#123;</span></div><div class="line">     display: none;</div><div class="line">   &#125;</div><div class="line"> &#125;</div><div class="line"> </div><div class="line"><span class="meta">@media (min-width: 1100px) &#123;</span></div><div class="line"> <span class="comment">#toc&#123;</span></div><div class="line">   z-index: <span class="number">999</span>;</div><div class="line">   background-color: <span class="comment">#fff;</span></div><div class="line">   padding: <span class="number">0</span> <span class="number">1</span>em;</div><div class="line">   border:<span class="number">1</span>px solid <span class="comment">#ddd;</span></div><div class="line">   position: fixed;</div><div class="line">   top: <span class="number">100</span>px;</div><div class="line">   right: <span class="number">-180</span>px;</div><div class="line">   transition: right <span class="number">.5</span>s ease-<span class="keyword">in</span>;</div><div class="line">   width: <span class="number">150</span>px;</div><div class="line">   h2&#123;</div><div class="line">     margin-bottom:<span class="number">10</span>px;</div><div class="line">   &#125;</div><div class="line">   ol&#123;</div><div class="line">     padding-left: <span class="number">0</span>!important;</div><div class="line">   &#125;</div><div class="line">   line-height: <span class="number">1.3</span>em;</div><div class="line">   font-size: <span class="number">0.8</span>em;</div><div class="line">   float: right;</div><div class="line">   .toc&#123;</div><div class="line">     padding: <span class="number">0</span>;</div><div class="line">     li&#123;</div><div class="line">       list-style-type: none;</div><div class="line">       margin: <span class="number">.5</span>em <span class="number">0</span> <span class="number">.5</span>em;</div><div class="line">       ol&#123;</div><div class="line">         margin: <span class="number">.5</span>em <span class="number">0</span> <span class="number">.5</span>em <span class="number">1</span>em;</div><div class="line">       &#125;</div><div class="line">     &#125;</div><div class="line">   &#125;</div><div class="line"> &#125;</div><div class="line"> .article2&#123;</div><div class="line">   margin-right: <span class="number">211</span>px;</div><div class="line">   transition: margin-right <span class="number">.5</span>s ease-<span class="keyword">in</span>;</div><div class="line"> &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">.toc-item span &#123;</div><div class="line">display: table-cell;</div><div class="line">&#125;</div><div class="line">span.toc-text &#123;</div><div class="line">padding-left: <span class="number">3</span>px;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>即可实现，如图<br><img src="/materials/img/my_blog/toc.jpg" alt="toc"><br>如果没有效果，可以尝试在需要目录的文章头部添加如下语句<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">---</div><div class="line">title: 使用机器学习识别出拍卖场中作弊的机器人用户</div><div class="line">date: <span class="number">2017</span><span class="number">-05</span><span class="number">-29</span> <span class="number">19</span>:<span class="number">27</span>:<span class="number">51</span></div><div class="line">tags: [ML, Kaggle, Python]</div><div class="line">toc: true</div><div class="line">---</div></pre></td></tr></table></figure></p>
<p>以上内容基本可以搭建起一个还不错的博客了，当然如果你需要其他的一些好玩的功能比如标签云啊，浏览量、动态特效之类的就多多使用搜索引擎咯，另外，遇到什么问题大部分都能在对应的github的<a href="https://github.com/litten/hexo-theme-yilia/issues?page=2&amp;q=%E5%9F%9F%E5%90%8D&amp;utf8=%E2%9C%93" target="_blank" rel="external">issues</a>找到答案。</p>
<hr>
<h2 id="域名绑定"><a href="#域名绑定" class="headerlink" title="域名绑定"></a>域名绑定</h2><p>最后就介绍下域名的绑定，如果你也不满足使用github的二级域名，而是想使用专属于你自己的域名，那么这部分就是为你而准备的。</p>
<p>这部分也是参照了不少文章，比如<a href="http://www.isetsuna.com/hexo/domain-dns/" target="_blank" rel="external">Setsuna</a>和<a href="http://www.jianshu.com/p/834d7cc0668d" target="_blank" rel="external">水瓶座IOSer</a>，还有<a href="http://zhaozhiming.github.io/blog/2016/08/20/use-gitpage-to-publis-your-site-with-custom-domain/" target="_blank" rel="external">zhaozhiming</a>下面我就简单的叙述一下。</p>
<h3 id="使用工具"><a href="#使用工具" class="headerlink" title="使用工具"></a>使用工具</h3><ul>
<li><a href="https://www.namesilo.com/account_home.php" target="_blank" rel="external">namesilo</a>: 购买域名的地方，经过一番查阅感觉这个相对靠谱</li>
<li><a href="https://www.dnspod.cn/console/dns/izhaoyi.top" target="_blank" rel="external">DNSPod</a>: 国内的免费DNS服务，后面将域名的dns转移到这个上面</li>
</ul>
<p>首先要绑定域名自然需要购买一个域名，国内的话可以试试阿里云、万网，学生的话好像可以试试腾讯云的云服务器，是会送免费的.cn域名，但是国内购买的话需要去公安局备份好象，感觉比较麻烦我就是用了国外的，比如namesilo，其他的介绍可以看看<a href="http://zhaozhiming.github.io/blog/2016/08/20/use-gitpage-to-publis-your-site-with-custom-domain/" target="_blank" rel="external">zhaozhiming</a>的对应观点，当然他和我一样也是在知乎上的一个地方看到的；</p>
<p>在namesilo上注册的教程可以看<a href="https://www.bbsmax.com/A/n2d9ZDYozD/" target="_blank" rel="external">这个</a>,选择好域名并付款后（支持支付宝）的基本设置可以看<a href="https://www.bbsmax.com/A/ZOJPWNxzvV/" target="_blank" rel="external">这个</a>，接下来：</p>
<h3 id="CNAME"><a href="#CNAME" class="headerlink" title="CNAME"></a>CNAME</h3><p>在你的本地站点目录里的source目录下添加一个CNAME文件，<strong>不带后缀</strong>，用编辑器打开并输入你购买的域名，<strong>不要http也不要www</strong>,比如我的域名是<code>izhaoyi.top</code>,我就写入<code>izhaoyi.top</code>然后保存以后执行<code>deploy</code>。</p>
<h3 id="DNS设置"><a href="#DNS设置" class="headerlink" title="DNS设置"></a>DNS设置</h3><h4 id="namesilo"><a href="#namesilo" class="headerlink" title="namesilo"></a>namesilo</h4><p>登陆namesilo之后，右上角的<code>Manage My Domains</code>点击进入后,选择<br><img src="/materials/img/my_blog/namesilo.jpg" alt="namesilo"><br>然后下拉，选择<br><img src="/materials/img/my_blog/namesilo_dns2.png" alt="namesilo2"><br>在上面手动添加两条记录，如图<br><img src="/materials/img/my_blog/namesilo3.jpg" alt="namesilo3"><br>然后回到域名管理界面，选中域名那一栏最前面的勾选框，然后选择上面的<code>Change Namesevers</code>图标<br><img src="/materials/img/my_blog/namesilo4.png" alt="namesilo4"><br>最后在在<code>NameServer1</code>和<code>NameServer2</code>中填写 <code>DNSPod</code> 的 nameserver 地址<code>f1g1ns1.dnspod.net</code>，<code>f1g1ns2.dnspod.net</code><br><img src="/materials/img/my_blog/namesilo5.png" alt="namesilo5"></p>
<h4 id="DNSPod"><a href="#DNSPod" class="headerlink" title="DNSPod"></a>DNSPod</h4><p>同样完成注册后，在<code>域名注册</code>中需要手动添加你购买的域名，并添加一些记录，最终如图<br><img src="/materials/img/my_blog/dnspod.jpg" alt="dnspod"><br>这里的<code>192.30.252.153</code>是github pages的ip地址，固定设置成这个就好，然后稍微等一段时间（也许不用等）应该就可以通过访问你的域名比如<code>izhaoyi.top</code>或者你之前的github站点名比如<code>LancelotHolmes.github.io</code>访问你的博客啦。</p>
<p>最后，欢迎大家来我的<a href="izhaoyi.top">博客</a>踩踩，也欢迎跟我互加友链啊~</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;先把我的博客贴一下&lt;a href=&quot;izhaoyi.top&quot;&gt;Lancelot’s Desert&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;端午节两天时间宅实验室把自己搭建一个博客这么个‘历史遗留问题’解决了下，其实之前也用Hugo搭建过，最后给弄崩了，这次尝试下&lt;a href=&quot;https://hexo.io/zh-cn/docs/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hexo&lt;/a&gt;，发现倒是异常的顺利，一方面Hexo的整体生态比较完备，另一方面网上找到的教程也很靠谱，下面就把我搭建过程中的一些步骤和踩过的坑记录下。&lt;br&gt;
    
    </summary>
    
    
      <category term="blog" scheme="http://yoursite.com/tags/blog/"/>
    
      <category term="hexo" scheme="http://yoursite.com/tags/hexo/"/>
    
      <category term="yilia" scheme="http://yoursite.com/tags/yilia/"/>
    
      <category term="Coding" scheme="http://yoursite.com/tags/Coding/"/>
    
  </entry>
  
  <entry>
    <title>使用机器学习识别出拍卖场中作弊的机器人用户(二)</title>
    <link href="http://yoursite.com/2017/05/29/HumenOrRobot2/"/>
    <id>http://yoursite.com/2017/05/29/HumenOrRobot2/</id>
    <published>2017-05-29T12:52:19.000Z</published>
    <updated>2017-05-30T02:59:47.183Z</updated>
    
    <content type="html"><![CDATA[<!-- 本文承接上一篇文章:[使用机器学习识别出拍卖场中作弊的机器人用户](../HumenOrRobot) -->
<p>本文承接上一篇文章:<a href="/2017/05/29/HumenOrRobot/" title="使用机器学习识别出拍卖场中作弊的机器人用户">使用机器学习识别出拍卖场中作弊的机器人用户</a></p>
<p>本项目为kaggle上Facebook举行的一次比赛，地址见数据来源，完整代码见我的<a href="https://github.com/LancelotHolmes/HumanOrRobot" target="_blank" rel="external">github</a>,欢迎来玩~</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><ul>
<li>数据探索——Data_Exploration.ipynb</li>
<li>数据预处理&amp;特征工程——Feature_Engineering.ipynb &amp; Feature_Engineering2.ipynb</li>
<li>模型设计及评测——Model_Design.ipynb</li>
</ul>
<a id="more"></a>
<h2 id="项目数据来源"><a href="#项目数据来源" class="headerlink" title="项目数据来源"></a>项目数据来源</h2><ul>
<li><a href="https://www.kaggle.com/c/facebook-recruiting-iv-human-or-bot/data" target="_blank" rel="external">kaggle</a><h2 id="项目所需额外工具包"><a href="#项目所需额外工具包" class="headerlink" title="项目所需额外工具包"></a>项目所需额外工具包</h2></li>
<li><a href="http://www.numpy.org/" target="_blank" rel="external">numpy</a></li>
<li><a href="http://pandas.pydata.org/" target="_blank" rel="external">pandas</a></li>
<li><a href="https://matplotlib.org/index.html" target="_blank" rel="external">matplotlib</a></li>
<li><a href="http://scikit-learn.org/stable/" target="_blank" rel="external">sklearn</a></li>
<li><a href="https://xgboost.readthedocs.io/en/latest//parameter.html#parameters-for-tree-booster" target="_blank" rel="external">xgboost</a></li>
<li><a href="https://github.com/Microsoft/LightGBM" target="_blank" rel="external">lightgbm</a></li>
<li><a href="https://github.com/rasbt/mlxtend" target="_blank" rel="external">mlxtend</a>: 含有聚和算法Stacking<br>项目整体运行时间预估为60min左右，在Ubuntu系统，8G内存，运行结果见所提交的jupyter notebook文件</li>
</ul>
<hr>
<p>由于文章内容过长，所以分为两篇文章，总共包含四个部分</p>
<ul>
<li>数据探索</li>
<li>数据预处理及特征工程</li>
<li>模型设计</li>
<li>评估及总结</li>
</ul>
<hr>
<h2 id="特征工程-续"><a href="#特征工程-续" class="headerlink" title="特征工程(续)"></a>特征工程(续)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> pickle</div><div class="line">%matplotlib inline</div><div class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># bids = pd.read_csv('bids.csv')</span></div><div class="line">bids = pickle.load(open(<span class="string">'bids.pkl'</span>))</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> bids.shape</div><div class="line">display(bids.head())</div></pre></td></tr></table></figure>
<pre><code>(7656329, 9)
</code></pre><table>
<thead>
<tr>
<th>bid_id</th>
<th>bidder_id</th>
<th>auction</th>
<th>merchandise</th>
<th>device</th>
<th>time</th>
<th>country</th>
<th>ip</th>
<th>url</th>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>8dac2b259fd1c6d1120e519fb1ac14fbqvax8</td>
<td>ewmzr</td>
<td>jewelry</td>
<td>phone0</td>
<td>9759243157894736</td>
<td>us</td>
<td>69.166.231.58</td>
<td>vasstdc27m7nks3</td>
</tr>
<tr>
<td>1</td>
<td>668d393e858e8126275433046bbd35c6tywop</td>
<td>aeqok</td>
<td>furniture</td>
<td>phone1</td>
<td>9759243157894736</td>
<td>in</td>
<td>50.201.125.84</td>
<td>jmqlhflrzwuay9c</td>
</tr>
<tr>
<td>2</td>
<td>aa5f360084278b35d746fa6af3a7a1a5ra3xe</td>
<td>wa00e</td>
<td>home goods</td>
<td>phone2</td>
<td>9759243157894736</td>
<td>py</td>
<td>112.54.208.157</td>
<td>vasstdc27m7nks3</td>
</tr>
<tr>
<td>3</td>
<td>3939ac3ef7d472a59a9c5f893dd3e39fh9ofi</td>
<td>jefix</td>
<td>jewelry</td>
<td>phone4</td>
<td>9759243157894736</td>
<td>in</td>
<td>18.99.175.133</td>
<td>vasstdc27m7nks3</td>
</tr>
<tr>
<td>4</td>
<td>8393c48eaf4b8fa96886edc7cf27b372dsibi</td>
<td>jefix</td>
<td>jewelry</td>
<td>phone5</td>
<td>9759243157894736</td>
<td>in</td>
<td>145.138.5.37</td>
<td>vasstdc27m7nks3</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bidders = bids.groupby(<span class="string">'bidder_id'</span>)</div></pre></td></tr></table></figure>
<h3 id="针对国家、商品单一特征多类别转换为多个独立特征进行统计"><a href="#针对国家、商品单一特征多类别转换为多个独立特征进行统计" class="headerlink" title="针对国家、商品单一特征多类别转换为多个独立特征进行统计"></a>针对国家、商品单一特征多类别转换为多个独立特征进行统计</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">cates = (bids[<span class="string">'merchandise'</span>].unique()).tolist()</div><div class="line">countries = (bids[<span class="string">'country'</span>].unique()).tolist()</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">dummy_coun_cate</span><span class="params">(group)</span>:</span></div><div class="line">    coun_cate = dict.fromkeys(cates, <span class="number">0</span>)</div><div class="line">    coun_cate.update(dict.fromkeys(countries, <span class="number">0</span>))</div><div class="line">    <span class="keyword">for</span> cat, value <span class="keyword">in</span> group[<span class="string">'merchandise'</span>].value_counts().iteritems():</div><div class="line">        coun_cate[cat] = value</div><div class="line"></div><div class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> group[<span class="string">'country'</span>].unique():</div><div class="line">        coun_cate[c] = <span class="number">1</span></div><div class="line"></div><div class="line">    coun_cate = pd.Series(coun_cate)</div><div class="line">    <span class="keyword">return</span> coun_cate</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bidder_coun_cate = bidders.apply(dummy_coun_cate)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">display(bidder_coun_cate.describe())</div><div class="line">bidder_coun_cate.to_csv(<span class="string">'coun_cate.csv'</span>)</div></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>-</th>
<th>ad</th>
<th>ae</th>
<th>af</th>
<th>ag</th>
<th>al</th>
<th>am</th>
<th>an</th>
<th>ao</th>
<th>ar</th>
<th>at</th>
<th>…</th>
</tr>
</thead>
<tbody>
<tr>
<td>count</td>
<td>6609.0</td>
<td>6609.0</td>
<td>6609.0</td>
<td>6609.0</td>
<td>6609.0</td>
<td>6609.0</td>
<td>6609.0</td>
<td>6609.0</td>
<td>6609.0</td>
<td>6609.0</td>
<td>…</td>
</tr>
<tr>
<td>mean</td>
<td>0.002724</td>
<td>0.205629</td>
<td>0.054774</td>
<td>0.001059</td>
<td>0.048570</td>
<td>0.023907</td>
<td>0.000303</td>
<td>0.036314</td>
<td>0.120442</td>
<td>0.052655</td>
<td>…</td>
</tr>
<tr>
<td>std</td>
<td>0.052121</td>
<td>0.404191</td>
<td>0.227555</td>
<td>0.032530</td>
<td>0.214984</td>
<td>0.152770</td>
<td>0.017395</td>
<td>0.187085</td>
<td>0.325502</td>
<td>0.223362</td>
<td>…</td>
</tr>
<tr>
<td>min</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>…</td>
</tr>
<tr>
<td>25%</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>…</td>
</tr>
<tr>
<td>50%</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>…</td>
</tr>
<tr>
<td>75%</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>…</td>
</tr>
<tr>
<td>max</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>…</td>
</tr>
</tbody>
</table>
<p>同样的，对于每个用户需要统计他对于自己每次竞拍行为的时间间隔情况</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">bidder_interval</span><span class="params">(group)</span>:</span></div><div class="line">    time_diff = np.ediff1d(group[<span class="string">'time'</span>])</div><div class="line">    bidder_interval = &#123;&#125;</div><div class="line">    <span class="keyword">if</span> len(time_diff) == <span class="number">0</span>:</div><div class="line">        diff_mean = <span class="number">0</span></div><div class="line">        diff_std = <span class="number">0</span></div><div class="line">        diff_median = <span class="number">0</span></div><div class="line">        diff_zeros = <span class="number">0</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        diff_mean = np.mean(time_diff)</div><div class="line">        diff_std = np.std(time_diff)</div><div class="line">        diff_median = np.median(time_diff)</div><div class="line">        diff_zeros = time_diff.shape[<span class="number">0</span>] - np.count_nonzero(time_diff)</div><div class="line">    bidder_interval[<span class="string">'tmean'</span>] = diff_mean</div><div class="line">    bidder_interval[<span class="string">'tstd'</span>] = diff_std</div><div class="line">    bidder_interval[<span class="string">'tmedian'</span>] = diff_median</div><div class="line">    bidder_interval[<span class="string">'tzeros'</span>] = diff_zeros</div><div class="line">    bidder_interval = pd.Series(bidder_interval)</div><div class="line">    <span class="keyword">return</span> bidder_interval</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bidder_inv = bidders.apply(bidder_interval)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">display(bidder_inv.describe())</div><div class="line">bidder_inv.to_csv(<span class="string">'bidder_inv.csv'</span>)</div></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>-</th>
<th>tmean</th>
<th>tmedian</th>
<th>tstd</th>
<th>tzeros</th>
</tr>
</thead>
<tbody>
<tr>
<td>count</td>
<td>6.609000e+03</td>
<td>6.609000e+03</td>
<td>6.609000e+03</td>
<td>6609.0</td>
</tr>
<tr>
<td>mean</td>
<td>2.933038e+12</td>
<td>1.860285e+12</td>
<td>3.440901e+12</td>
<td>122.986231</td>
</tr>
<tr>
<td>std</td>
<td>8.552343e+12</td>
<td>7.993497e+12</td>
<td>6.512992e+12</td>
<td>3190.805229</td>
</tr>
<tr>
<td>min</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
<td>0.000000e+00</td>
<td>0.000000</td>
</tr>
<tr>
<td>25%</td>
<td>1.192853e+10</td>
<td>2.578947e+09</td>
<td>1.749995e+09</td>
<td>0.000000</td>
</tr>
<tr>
<td>50%</td>
<td>2.641139e+11</td>
<td>5.726316e+10</td>
<td>5.510107e+11</td>
<td>0.000000</td>
</tr>
<tr>
<td>75%</td>
<td>1.847456e+12</td>
<td>6.339474e+11</td>
<td>2.911282e+12</td>
<td>0.000000</td>
</tr>
<tr>
<td>max</td>
<td>7.610295e+13</td>
<td>7.610295e+13</td>
<td>3.800092e+13</td>
<td>231570.000000</td>
</tr>
</tbody>
</table>
<h3 id="按照用户-拍卖场分组进一步分析"><a href="#按照用户-拍卖场分组进一步分析" class="headerlink" title="按照用户-拍卖场分组进一步分析"></a>按照用户-拍卖场分组进一步分析</h3><p>之前的统计是按照用户进行分组，针对各个用户从整体上针对竞标行为统计其各项特征，下面根据拍卖场来对用户进一步细分，看一看每个用户在不同拍卖场的行为模式,类似上述按照用户分组来统计各个用户的各项特征，针对用户-拍卖场结对分组进行统计以下特征</p>
<ul>
<li>基本计数统计，针对各个用户在各个拍卖场统计设备、国家、ip、url、商品类别、竞标次数等特征的数目作为新的特征</li>
<li>时间间隔统计：统计各个用户在各个拍卖场每次竞拍的时间间隔的 均值、方差、中位数和0值</li>
<li>针对商品类别、国家进一步转化为多类别进行统计</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">auc_features_count</span><span class="params">(group)</span>:</span></div><div class="line">    time_diff = np.ediff1d(group[<span class="string">'time'</span>])</div><div class="line">    </div><div class="line">    <span class="keyword">if</span> len(time_diff) == <span class="number">0</span>:</div><div class="line">        diff_mean = <span class="number">0</span></div><div class="line">        diff_std = <span class="number">0</span></div><div class="line">        diff_median = <span class="number">0</span></div><div class="line">        diff_zeros = <span class="number">0</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        diff_mean = np.mean(time_diff)</div><div class="line">        diff_std = np.std(time_diff)</div><div class="line">        diff_median = np.median(time_diff)</div><div class="line">        diff_zeros = time_diff.shape[<span class="number">0</span>] - np.count_nonzero(time_diff)</div><div class="line"></div><div class="line">    row = dict.fromkeys(cates, <span class="number">0</span>)</div><div class="line">    row.update(dict.fromkeys(countries, <span class="number">0</span>))</div><div class="line"></div><div class="line">    row[<span class="string">'devices_c'</span>] = group[<span class="string">'device'</span>].unique().shape[<span class="number">0</span>]</div><div class="line">    row[<span class="string">'countries_c'</span>] = group[<span class="string">'country'</span>].unique().shape[<span class="number">0</span>]</div><div class="line">    row[<span class="string">'ip_c'</span>] = group[<span class="string">'ip'</span>].unique().shape[<span class="number">0</span>]</div><div class="line">    row[<span class="string">'url_c'</span>] = group[<span class="string">'url'</span>].unique().shape[<span class="number">0</span>]</div><div class="line"><span class="comment">#     row['merch_c'] = group['merchandise'].unique().shape[0]</span></div><div class="line">    row[<span class="string">'bids_c'</span>] = group.shape[<span class="number">0</span>]</div><div class="line">    row[<span class="string">'tmean'</span>] = diff_mean</div><div class="line">    row[<span class="string">'tstd'</span>] = diff_std</div><div class="line">    row[<span class="string">'tmedian'</span>] = diff_median</div><div class="line">    row[<span class="string">'tzeros'</span>] = diff_zeros</div><div class="line"></div><div class="line">    <span class="keyword">for</span> cat, value <span class="keyword">in</span> group[<span class="string">'merchandise'</span>].value_counts().iteritems():</div><div class="line">        row[cat] = value</div><div class="line"></div><div class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> group[<span class="string">'country'</span>].unique():</div><div class="line">        row[c] = <span class="number">1</span></div><div class="line"></div><div class="line">    row = pd.Series(row)</div><div class="line">    <span class="keyword">return</span> row</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bidder_auc = bids.groupby([<span class="string">'bidder_id'</span>, <span class="string">'auction'</span>]).apply(auc_features_count)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bidder_auc.to_csv(<span class="string">'bids_auc.csv'</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> bidder_auc.shape</div></pre></td></tr></table></figure>
<pre><code>(382336, 218)
</code></pre><h2 id="模型设计与参数评估"><a href="#模型设计与参数评估" class="headerlink" title="模型设计与参数评估"></a>模型设计与参数评估</h2><h3 id="合并特征"><a href="#合并特征" class="headerlink" title="合并特征"></a>合并特征</h3><p>对之前生成的各项特征进行合并产生最终的特征空间</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line">%matplotlib inline</div><div class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display</div></pre></td></tr></table></figure>
<p>首先将之前根据用户分组的统计特征合并起来，然后将其与按照用户-拍卖场结对分组的特征合并起来，最后加上时间特征，分别于训练集、测试集连接生成后续进行训练和预测的特征数据文件</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge_data</span><span class="params">()</span>:</span>    </div><div class="line">    train = pd.read_csv(<span class="string">'train.csv'</span>)</div><div class="line">    test = pd.read_csv(<span class="string">'test.csv'</span>)</div><div class="line"></div><div class="line">    time_differences = pd.read_csv(<span class="string">'tdiff.csv'</span>, index_col=<span class="number">0</span>)</div><div class="line">    bids_auc = pd.read_csv(<span class="string">'bids_auc.csv'</span>)</div><div class="line"></div><div class="line">    bids_auc = bids_auc.groupby(<span class="string">'bidder_id'</span>).mean()</div><div class="line">    </div><div class="line">    bidders = pd.read_csv(<span class="string">'cnt_bidder.csv'</span>, index_col=<span class="number">0</span>)</div><div class="line">    country_cate = pd.read_csv(<span class="string">'coun_cate.csv'</span>, index_col=<span class="number">0</span>)</div><div class="line">    bidder_inv = pd.read_csv(<span class="string">'bidder_inv.csv'</span>, index_col=<span class="number">0</span>)</div><div class="line">    bidders = bidders.merge(country_cate, right_index=<span class="keyword">True</span>, left_index=<span class="keyword">True</span>)</div><div class="line">    bidders = bidders.merge(bidder_inv, right_index=<span class="keyword">True</span>, left_index=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">    bidders = bidders.merge(bids_auc, right_index=<span class="keyword">True</span>, left_index=<span class="keyword">True</span>)</div><div class="line">    bidders = bidders.merge(time_differences, right_index=<span class="keyword">True</span>,</div><div class="line">                            left_index=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">    train = train.merge(bidders, left_on=<span class="string">'bidder_id'</span>, right_index=<span class="keyword">True</span>)</div><div class="line">    train.to_csv(<span class="string">'train_full.csv'</span>, index=<span class="keyword">False</span>)</div><div class="line"></div><div class="line">    test = test.merge(bidders, left_on=<span class="string">'bidder_id'</span>, right_index=<span class="keyword">True</span>)</div><div class="line">    test.to_csv(<span class="string">'test_full.csv'</span>, index=<span class="keyword">False</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">merge_data()</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">train_full = pd.read_csv(<span class="string">'train_full.csv'</span>)</div><div class="line">test_full = pd.read_csv(<span class="string">'test_full.csv'</span>)</div><div class="line"><span class="keyword">print</span> train_full.shape</div><div class="line"><span class="keyword">print</span> test_full.shape</div></pre></td></tr></table></figure>
<pre><code>(1983, 445)
(4626, 444)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">train_full[<span class="string">'outcome'</span>] = train_full[<span class="string">'outcome'</span>].astype(int)</div><div class="line">ytrain = train_full[<span class="string">'outcome'</span>]</div><div class="line">train_full.drop(<span class="string">'outcome'</span>, <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">test_ids = test_full[<span class="string">'bidder_id'</span>]</div><div class="line"></div><div class="line">labels = [<span class="string">'payment_account'</span>, <span class="string">'address'</span>, <span class="string">'bidder_id'</span>]</div><div class="line">train_full.drop(labels=labels, axis=<span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line">test_full.drop(labels=labels, axis=<span class="number">1</span>, inplace=<span class="keyword">True</span>)</div></pre></td></tr></table></figure>
<h3 id="设计交叉验证"><a href="#设计交叉验证" class="headerlink" title="设计交叉验证"></a>设计交叉验证</h3><h3 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h3><p>根据之前的分析，由于当前的数据集中存在正负例不均衡的问题，所以考虑选取了RandomForestClassfier, GradientBoostingClassifier, xgboost, lightgbm等四种模型来针对数据及进行训练和预测，确定最终模型的基本思路如下：</p>
<ul>
<li>对四个模型分别使用评价函数roc_auc进行交叉验证并绘制auc曲线，对各个模型的多轮交叉验证得分取平均值并输出</li>
<li>根据得分确定最终选用的一个或多个模型<ul>
<li>若最后发现一个模型的表现大幅度优于其他所有模型，则选择该模型进一步调参</li>
<li>若最后发现多个模型表现都不错，则进行模型的集成，得到聚合模型</li>
<li>使用GridSearchCV来从人为设定的参数列表中选择最佳的参数组合确定最终的模型</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> interp</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> cycle</div><div class="line"></div><div class="line"><span class="comment"># from sklearn.cross_validation import StratifiedKFold</span></div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</div><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score, roc_curve, auc</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">kfold_plot</span><span class="params">(train, ytrain, model)</span>:</span></div><div class="line"><span class="comment">#     kf = StratifiedKFold(y=ytrain, n_folds=5)</span></div><div class="line">    kf = StratifiedKFold(n_splits=<span class="number">5</span>)</div><div class="line">    scores = []</div><div class="line">    mean_tpr = <span class="number">0.0</span></div><div class="line">    mean_fpr = np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</div><div class="line">    exe_time = []</div><div class="line">    </div><div class="line">    colors = cycle([<span class="string">'cyan'</span>, <span class="string">'indigo'</span>, <span class="string">'seagreen'</span>, <span class="string">'yellow'</span>, <span class="string">'blue'</span>])</div><div class="line">    lw = <span class="number">2</span></div><div class="line">    </div><div class="line">    i=<span class="number">0</span></div><div class="line">    <span class="keyword">for</span> (train_index, test_index), color <span class="keyword">in</span> zip(kf.split(train, ytrain), colors):</div><div class="line">        X_train, X_test = train.iloc[train_index], train.iloc[test_index]</div><div class="line">        y_train, y_test = ytrain.iloc[train_index], ytrain.iloc[test_index]</div><div class="line">        begin_t = time.time()</div><div class="line">        predictions = model(X_train, X_test, y_train)</div><div class="line">        end_t = time.time()</div><div class="line">        exe_time.append(round(end_t-begin_t, <span class="number">3</span>))</div><div class="line"><span class="comment">#         model = model</span></div><div class="line"><span class="comment">#         model.fit(X_train, y_train)    </span></div><div class="line"><span class="comment">#         predictions = model.predict_proba(X_test)[:, 1]        </span></div><div class="line">        scores.append(roc_auc_score(y_test.astype(float), predictions))        </div><div class="line">        fpr, tpr, thresholds = roc_curve(y_test, predictions)</div><div class="line">        mean_tpr += interp(mean_fpr, fpr, tpr)</div><div class="line">        mean_tpr[<span class="number">0</span>] = <span class="number">0.0</span></div><div class="line">        roc_auc = auc(fpr, tpr)</div><div class="line">        plt.plot(fpr, tpr, lw=lw, color=color, label=<span class="string">'ROC fold %d (area = %0.2f)'</span> % (i, roc_auc))</div><div class="line">        i += <span class="number">1</span></div><div class="line">    plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], linestyle=<span class="string">'--'</span>, lw=lw, color=<span class="string">'k'</span>, label=<span class="string">'Luck'</span>)</div><div class="line">    </div><div class="line">    mean_tpr /= kf.get_n_splits(train, ytrain)</div><div class="line">    mean_tpr[<span class="number">-1</span>] = <span class="number">1.0</span></div><div class="line">    mean_auc = auc(mean_fpr, mean_tpr)</div><div class="line">    plt.plot(mean_fpr, mean_tpr, color=<span class="string">'g'</span>, linestyle=<span class="string">'--'</span>, label=<span class="string">'Mean ROC (area = %0.2f)'</span> % mean_auc, lw=lw)</div><div class="line">    </div><div class="line">    plt.xlim([<span class="number">-0.05</span>, <span class="number">1.05</span>])</div><div class="line">    plt.ylim([<span class="number">-0.05</span>, <span class="number">1.05</span>])</div><div class="line">    plt.xlabel(<span class="string">'False Positive Rate'</span>)</div><div class="line">    plt.ylabel(<span class="string">'True Positive Rate'</span>)</div><div class="line">    plt.title(<span class="string">'Receiver operating characteristic'</span>)</div><div class="line">    plt.legend(loc=<span class="string">'lower right'</span>)</div><div class="line">    plt.show()</div><div class="line">    </div><div class="line">    <span class="keyword">print</span> <span class="string">'mean scores: '</span>,np.mean(scores)</div><div class="line">    <span class="keyword">print</span> <span class="string">'mean model process time: '</span>,np.mean(exe_time), <span class="string">'s'</span></div></pre></td></tr></table></figure>
<h4 id="RandomForestClassifier"><a href="#RandomForestClassifier" class="headerlink" title="RandomForestClassifier"></a>RandomForestClassifier</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</div><div class="line"><span class="keyword">import</span> time</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">forest_model</span><span class="params">(X_train, X_test, y_train)</span>:</span></div><div class="line">    model = RandomForestClassifier(n_estimators=<span class="number">160</span>, max_features=<span class="number">35</span>, max_depth=<span class="number">8</span>, random_state=<span class="number">7</span>)</div><div class="line">    model.fit(X_train, y_train)    </div><div class="line">    predictions = model.predict_proba(X_test)[:, <span class="number">1</span>]</div><div class="line">    <span class="keyword">return</span> predictions</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">kfold_plot(train_full, ytrain, forest_model)</div><div class="line"><span class="comment"># kfold_plot(train_full, ytrain, model_forest)</span></div></pre></td></tr></table></figure>
<p><img src="/materials/img/HumenOrRobot2/roc_forest.png" alt="forest_auc"></p>
<pre><code>mean scores:  0.909571935157
mean model process time:  0.6372 s
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_model</span><span class="params">(X_train, X_test, y_train)</span>:</span></div><div class="line">    model = GradientBoostingClassifier(n_estimators=<span class="number">200</span>, random_state=<span class="number">7</span>, max_depth=<span class="number">5</span>, learning_rate=<span class="number">0.03</span>)</div><div class="line">    model.fit(X_train, y_train)</div><div class="line">    predictions = model.predict_proba(X_test)[:, <span class="number">1</span>]</div><div class="line">    <span class="keyword">return</span> predictions</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kfold_plot(train_full, ytrain, gradient_model)</div></pre></td></tr></table></figure>
<p><img src="/materials/img/HumenOrRobot2/roc_gbm.png" alt="gbm_auc"></p>
<pre><code>mean scores:  0.911847771023
mean model process time:  4.007 s
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">xgboost_model</span><span class="params">(X_train, X_test, y_train)</span>:</span></div><div class="line">    X_train = xgb.DMatrix(X_train.values, label=y_train.values)</div><div class="line">    X_test = xgb.DMatrix(X_test.values)</div><div class="line">    params = &#123;<span class="string">'objective'</span>: <span class="string">'binary:logistic'</span>, <span class="string">'eval_metric'</span>: <span class="string">'auc'</span>, <span class="string">'silent'</span>: <span class="number">1</span>, <span class="string">'seed'</span>: <span class="number">7</span>,</div><div class="line">              <span class="string">'max_depth'</span>: <span class="number">6</span>, <span class="string">'eta'</span>: <span class="number">0.01</span>&#125;    </div><div class="line">    model = xgb.train(params, X_train, <span class="number">600</span>)</div><div class="line">    predictions = model.predict(X_test)</div><div class="line">    <span class="keyword">return</span> predictions</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kfold_plot(train_full, ytrain, xgboost_model)</div></pre></td></tr></table></figure>
<p><img src="/materials/img/HumenOrRobot2/roc_xgb.png" alt="xgb_auc"></p>
<pre><code>mean scores:  0.915372340426
mean model process time:  4.855 s
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">lightgbm_model</span><span class="params">(X_train, X_test, y_train)</span>:</span></div><div class="line">    X_train = lgb.Dataset(X_train.values, y_train.values)</div><div class="line">    params = &#123;<span class="string">'objective'</span>: <span class="string">'binary'</span>, <span class="string">'metric'</span>: &#123;<span class="string">'auc'</span>&#125;, <span class="string">'learning_rate'</span>: <span class="number">0.01</span>, <span class="string">'max_depth'</span>: <span class="number">6</span>, <span class="string">'seed'</span>: <span class="number">7</span>&#125;</div><div class="line">    model = lgb.train(params, X_train, num_boost_round=<span class="number">600</span>)</div><div class="line">    predictions = model.predict(X_test)</div><div class="line">    <span class="keyword">return</span> predictions</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kfold_plot(train_full, ytrain, lightgbm_model)</div></pre></td></tr></table></figure>
<p><img src="/materials/img/HumenOrRobot2/roc_lgbm.png" alt="lgbm_auc"></p>
<pre><code>mean scores:  0.921512158055
mean model process time:  0.4236 s
</code></pre><h3 id="模型比较"><a href="#模型比较" class="headerlink" title="模型比较"></a>模型比较</h3><p>比较四个模型在交叉验证机上的roc_auc平均得分和模型训练的时间</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">data_source = [<span class="string">'forest'</span>, <span class="string">'gradient boosting'</span>, <span class="string">'xgboost'</span>, <span class="string">'lightgbm'</span>]</div><div class="line">y_pos = np.arange(len(data_source))</div><div class="line">model_auc = [<span class="number">0.910</span>, <span class="number">0.912</span>, <span class="number">0.915</span>, <span class="number">0.922</span>]</div><div class="line">barlist = plt.bar(y_pos, model_auc, align=<span class="string">'center'</span>, alpha=<span class="number">0.5</span>)</div><div class="line">barlist[<span class="number">3</span>].set_color(<span class="string">'r'</span>)</div><div class="line">plt.xticks(y_pos, data_source)</div><div class="line">plt.ylabel(<span class="string">'roc-auc score'</span>)</div><div class="line">plt.title(<span class="string">'Model Performance'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p><img src="/materials/img/HumenOrRobot2/model_performance.png" alt="model_performance"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">data_source = [<span class="string">'forest'</span>, <span class="string">'gradient boosting'</span>, <span class="string">'xgboost'</span>, <span class="string">'lightgbm'</span>]</div><div class="line">y_pos = np.arange(len(data_source))</div><div class="line">model_auc = [<span class="number">0.6372</span>,<span class="number">4.007</span>, <span class="number">4.855</span>, <span class="number">0.4236</span>]</div><div class="line">barlist = plt.bar(y_pos, model_auc, align=<span class="string">'center'</span>, alpha=<span class="number">0.5</span>)</div><div class="line">barlist[<span class="number">3</span>].set_color(<span class="string">'r'</span>)</div><div class="line">plt.xticks(y_pos, data_source)</div><div class="line">plt.ylabel(<span class="string">'time(s)'</span>)</div><div class="line">plt.title(<span class="string">'Time of Building Model'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p><img src="/materials/img/HumenOrRobot2/time.png" alt="model_time"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">auc_forest = [<span class="number">0.87</span>, <span class="number">0.93</span>, <span class="number">0.94</span>, <span class="number">0.86</span>, <span class="number">0.96</span>]</div><div class="line">auc_gb = [<span class="number">0.89</span>, <span class="number">0.91</span>, <span class="number">0.93</span>, <span class="number">0.87</span>, <span class="number">0.95</span>]</div><div class="line">auc_xgb = [<span class="number">0.89</span>,<span class="number">0.92</span>, <span class="number">0.93</span>, <span class="number">0.89</span>, <span class="number">0.95</span>]</div><div class="line">auc_lgb = [<span class="number">0.90</span>, <span class="number">0.93</span>, <span class="number">0.94</span>, <span class="number">0.88</span>, <span class="number">0.96</span>]</div><div class="line"><span class="keyword">print</span> <span class="string">'std of forest auc score: '</span>,np.std(auc_forest)</div><div class="line"><span class="keyword">print</span> <span class="string">'std of gbm auc score: '</span>,np.std(auc_gb)</div><div class="line"><span class="keyword">print</span> <span class="string">'std of xgboost auc score: '</span>,np.std(auc_xgb)</div><div class="line"><span class="keyword">print</span> <span class="string">'std of lightgbm auc score: '</span>,np.std(auc_lgb)</div><div class="line">data_source = [<span class="string">'roc-fold-1'</span>, <span class="string">'roc-fold-2'</span>, <span class="string">'roc-fold-3'</span>, <span class="string">'roc-fold-4'</span>, <span class="string">'roc-fold-5'</span>]</div><div class="line">y_pos = np.arange(len(data_source))</div><div class="line">plt.plot(y_pos, auc_forest, <span class="string">'b-'</span>, label=<span class="string">'forest'</span>)</div><div class="line">plt.plot(y_pos, auc_gb, <span class="string">'r-'</span>, label=<span class="string">'gbm'</span>)</div><div class="line">plt.plot(y_pos, auc_xgb, <span class="string">'y-'</span>, label=<span class="string">'xgboost'</span>)</div><div class="line">plt.plot(y_pos, auc_lgb, <span class="string">'g-'</span>, label=<span class="string">'lightgbm'</span>)</div><div class="line">plt.title(<span class="string">'roc-auc score of each epoch'</span>)</div><div class="line">plt.xlabel(<span class="string">'epoch'</span>)</div><div class="line">plt.ylabel(<span class="string">'roc-auc score'</span>)</div><div class="line">plt.legend()</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<pre><code>std of forest auc score:  0.0396988664826
std of gbm auc score:  0.0282842712475
std of xgboost auc score:  0.0233238075794
std of lightgbm auc score:  0.0285657137142
</code></pre><p><img src="/materials/img/HumenOrRobot2/roc_epoch.png" alt="stability"></p>
<p>单从5次交叉验证的各模型roc-auc得分来看，xgboost的得分相对比较稳定</p>
<h3 id="聚合模型"><a href="#聚合模型" class="headerlink" title="聚合模型"></a>聚合模型</h3><p>由上面的模型比较可以发现，四个模型的经过交叉验证的表现都不错，但是综合而言，xgboost和lightgbm更胜一筹，而且两者的训练时间也相对更短一些，所以接下来考虑进行模型的聚合，思路如下：</p>
<ul>
<li>先通过GridSearchCV分别针对四个模型在整个训练集上进行调参获得最佳的子模型</li>
<li>针对子模型使用<ul>
<li>stacking: 第三方库<a href="https://github.com/rasbt/mlxtend" target="_blank" rel="external">mlxtend</a>里的stacking方法对子模型进行聚合得到聚合模型，并采用之前相同的cv方法对该模型进行打分评价</li>
<li>voting: 使用sklearn内置的VotingClassifier进行四个模型的聚合</li>
</ul>
</li>
<li>最终对聚合模型在一次进行cv验证评分，根据结果确定最终的模型</li>
</ul>
<p>先通过交叉验证针对模型选择参数组合</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">choose_xgb_model</span><span class="params">(X_train, y_train)</span>:</span> </div><div class="line">    tuned_params = [&#123;<span class="string">'objective'</span>: [<span class="string">'binary:logistic'</span>], <span class="string">'learning_rate'</span>: [<span class="number">0.01</span>, <span class="number">0.03</span>, <span class="number">0.05</span>], </div><div class="line">                     <span class="string">'n_estimators'</span>: [<span class="number">100</span>, <span class="number">150</span>, <span class="number">200</span>], <span class="string">'max_depth'</span>:[<span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>]&#125;]</div><div class="line">    begin_t = time.time()</div><div class="line">    clf = GridSearchCV(xgb.XGBClassifier(seed=<span class="number">7</span>), tuned_params, scoring=<span class="string">'roc_auc'</span>)</div><div class="line">    clf.fit(X_train, y_train)</div><div class="line">    end_t = time.time()</div><div class="line">    <span class="keyword">print</span> <span class="string">'train time: '</span>,round(end_t-begin_t, <span class="number">3</span>), <span class="string">'s'</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'current best parameters of xgboost: '</span>,clf.best_params_</div><div class="line">    <span class="keyword">return</span> clf.best_estimator_</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bst_xgb = choose_xgb_model(train_full, ytrain)</div></pre></td></tr></table></figure>
<pre><code>train time:  86.216 s
current best parameters of xgboost:  {&apos;n_estimators&apos;: 150, &apos;objective&apos;: &apos;binary:logistic&apos;, &apos;learning_rate&apos;: 0.05, &apos;max_depth&apos;: 4}
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">choose_lgb_model</span><span class="params">(X_train, y_train)</span>:</span> </div><div class="line">    tuned_params = [&#123;<span class="string">'objective'</span>: [<span class="string">'binary'</span>], <span class="string">'learning_rate'</span>: [<span class="number">0.01</span>, <span class="number">0.03</span>, <span class="number">0.05</span>], </div><div class="line">                     <span class="string">'n_estimators'</span>: [<span class="number">100</span>, <span class="number">150</span>, <span class="number">200</span>], <span class="string">'max_depth'</span>:[<span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>]&#125;]</div><div class="line">    begin_t = time.time()</div><div class="line">    clf = GridSearchCV(lgb.LGBMClassifier(seed=<span class="number">7</span>), tuned_params, scoring=<span class="string">'roc_auc'</span>)</div><div class="line">    clf.fit(X_train, y_train)</div><div class="line">    end_t = time.time()</div><div class="line">    <span class="keyword">print</span> <span class="string">'train time: '</span>,round(end_t-begin_t, <span class="number">3</span>), <span class="string">'s'</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'current best parameters of lgb: '</span>,clf.best_params_</div><div class="line">    <span class="keyword">return</span> clf.best_estimator_</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bst_lgb = choose_lgb_model(train_full, ytrain)</div></pre></td></tr></table></figure>
<pre><code>train time:  16.602 s
current best parameters of lgb:  {&apos;n_estimators&apos;: 150, &apos;objective&apos;: &apos;binary&apos;, &apos;learning_rate&apos;: 0.05, &apos;max_depth&apos;: 4}
</code></pre><p>先使用stacking聚合两个综合表现最佳的模型lgb和xgb</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> mlxtend.classifier <span class="keyword">import</span> StackingClassifier</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">stacking_model</span><span class="params">(X_train, X_test, y_train)</span>:</span>    </div><div class="line">    sclf = StackingClassifier(classifiers=[bst_xgb], use_probas=<span class="keyword">True</span>, average_probas=<span class="keyword">False</span>, meta_classifier=bst_lgb)</div><div class="line">    sclf.fit(X_train, y_train)</div><div class="line">    predictions = sclf.predict_proba(X_test)[:, <span class="number">1</span>]</div><div class="line">    <span class="keyword">return</span> predictions</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kfold_plot(train_full, ytrain, stacking_model)</div></pre></td></tr></table></figure>
<p><img src="/materials/img/HumenOrRobot2/roc_stacking.png" alt="stack_2"></p>
<pre><code>mean scores:  0.880479989868
mean model process time:  0.8142 s
</code></pre><p>然而两个单独表现最佳的模型经过stacking的聚合模型表现反而不如之前的任何一个单一模型，考虑对四个模型进行stacking聚和操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">choose_forest_model</span><span class="params">(X_train, y_train)</span>:</span>    </div><div class="line">    tuned_params = [&#123;<span class="string">'n_estimators'</span>: [<span class="number">100</span>, <span class="number">150</span>, <span class="number">200</span>], <span class="string">'max_features'</span>: [<span class="number">8</span>, <span class="number">15</span>, <span class="number">30</span>], <span class="string">'max_depth'</span>:[<span class="number">4</span>, <span class="number">8</span>, <span class="number">10</span>]&#125;]</div><div class="line">    begin_t = time.time()</div><div class="line">    clf = GridSearchCV(RandomForestClassifier(random_state=<span class="number">7</span>), tuned_params, scoring=<span class="string">'roc_auc'</span>)</div><div class="line">    clf.fit(X_train, y_train)</div><div class="line">    end_t = time.time()</div><div class="line">    <span class="keyword">print</span> <span class="string">'train time: '</span>,round(end_t-begin_t, <span class="number">3</span>), <span class="string">'s'</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'current best parameters: '</span>,clf.best_params_</div><div class="line">    <span class="keyword">return</span> clf.best_estimator_</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bst_forest = choose_forest_model(train_full, ytrain)</div></pre></td></tr></table></figure>
<pre><code>train time:  42.852 s
current best parameters:  {&apos;max_features&apos;: 15, &apos;n_estimators&apos;: 150, &apos;max_depth&apos;: 8}
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">choose_gradient_model</span><span class="params">(X_train, y_train)</span>:</span>    </div><div class="line">    tuned_params = [&#123;<span class="string">'n_estimators'</span>: [<span class="number">100</span>, <span class="number">150</span>, <span class="number">200</span>], <span class="string">'learning_rate'</span>: [<span class="number">0.03</span>, <span class="number">0.05</span>, <span class="number">0.07</span>], </div><div class="line">                     <span class="string">'min_samples_leaf'</span>: [<span class="number">8</span>, <span class="number">15</span>, <span class="number">30</span>], <span class="string">'max_depth'</span>:[<span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>]&#125;]</div><div class="line">    begin_t = time.time()</div><div class="line">    clf = GridSearchCV(GradientBoostingClassifier(random_state=<span class="number">7</span>), tuned_params, scoring=<span class="string">'roc_auc'</span>)</div><div class="line">    clf.fit(X_train, y_train)</div><div class="line">    end_t = time.time()</div><div class="line">    <span class="keyword">print</span> <span class="string">'train time: '</span>,round(end_t-begin_t, <span class="number">3</span>), <span class="string">'s'</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'current best parameters: '</span>,clf.best_params_</div><div class="line">    <span class="keyword">return</span> clf.best_estimator_</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bst_gradient = choose_gradient_model(train_full, ytrain)</div></pre></td></tr></table></figure>
<pre><code>train time:  632.815 s
current best parameters:  {&apos;n_estimators&apos;: 100, &apos;learning_rate&apos;: 0.03, &apos;max_depth&apos;: 8, &apos;min_samples_leaf&apos;: 30}
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">stacking_model2</span><span class="params">(X_train, X_test, y_train)</span>:</span>    </div><div class="line">    sclf = StackingClassifier(classifiers=[bst_xgb, bst_forest, bst_gradient], use_probas=<span class="keyword">True</span>, average_probas=<span class="keyword">False</span>, </div><div class="line">                              meta_classifier=bst_lgb)</div><div class="line">    sclf.fit(X_train, y_train)</div><div class="line">    predictions = sclf.predict_proba(X_test)[:, <span class="number">1</span>]</div><div class="line">    <span class="keyword">return</span> predictions</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kfold_plot(train_full, ytrain, stacking_model2)</div></pre></td></tr></table></figure>
<p><img src="/materials/img/HumenOrRobot2/roc_stacking2.png" alt="stack_4"></p>
<pre><code>mean scores:  0.899170466059
mean model process time:  4.1236 s
</code></pre><p>可以看到四个模型的聚合效果比用两个模型的stacking聚合效果要好一点，但是相比较单一模型仍然效果不好，接下来考虑使用voting对四个模型进行聚合</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> VotingClassifier</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">voting_model</span><span class="params">(X_train, X_test, y_train)</span>:</span>    </div><div class="line">    vclf = VotingClassifier(estimators=[(<span class="string">'xgb'</span>, bst_xgb), (<span class="string">'rf'</span>, bst_forest), (<span class="string">'gbm'</span>,bst_gradient),</div><div class="line">                                       (<span class="string">'lgb'</span>, bst_lgb)], voting=<span class="string">'soft'</span>, weights=[<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>])</div><div class="line">    vclf.fit(X_train, y_train)</div><div class="line">    predictions = vclf.predict_proba(X_test)[:, <span class="number">1</span>]</div><div class="line">    <span class="keyword">return</span> predictions</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">kfold_plot(train_full, ytrain, voting_model)</div></pre></td></tr></table></figure>
<p><img src="/materials/img/HumenOrRobot2/roc_voting.png" alt="voting_4"></p>
<pre><code>mean scores:  0.926889564336
mean model process time:  4.2736 s
</code></pre><p>由上可以看到最终通过voting将四个模型进行聚合可以得到得分最高的模型，确定为最终模型</p>
<h3 id="综合模型，对测试文件进行最终预测"><a href="#综合模型，对测试文件进行最终预测" class="headerlink" title="综合模型，对测试文件进行最终预测"></a>综合模型，对测试文件进行最终预测</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># predict(train_full, test_full, y_train)</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">submit</span><span class="params">(X_train, X_test, y_train, test_ids)</span>:</span></div><div class="line">    predictions = voting_model(X_train, X_test, y_train)</div><div class="line"></div><div class="line">    sub = pd.read_csv(<span class="string">'sampleSubmission.csv'</span>)</div><div class="line">    result = pd.DataFrame()</div><div class="line">    result[<span class="string">'bidder_id'</span>] = test_ids</div><div class="line">    result[<span class="string">'outcome'</span>] = predictions</div><div class="line">    sub = sub.merge(result, on=<span class="string">'bidder_id'</span>, how=<span class="string">'left'</span>)</div><div class="line"></div><div class="line">    <span class="comment"># Fill missing values with mean</span></div><div class="line">    mean_pred = np.mean(predictions)</div><div class="line">    sub.fillna(mean_pred, inplace=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">    sub.drop(<span class="string">'prediction'</span>, <span class="number">1</span>, inplace=<span class="keyword">True</span>)</div><div class="line">    sub.to_csv(<span class="string">'result.csv'</span>, index=<span class="keyword">False</span>, header=[<span class="string">'bidder_id'</span>, <span class="string">'prediction'</span>])</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">submit(train_full, test_full, ytrain, test_ids)</div></pre></td></tr></table></figure>
<p>最终结果提交到kaggle上进行评分，得分如下<br><img src="/materials/img/HumenOrRobot2/point.png" alt="point"></p>
<p>以上就是整个完整的流程，当然还有很多模型可以尝试，很多聚合方法也可以使用，此外，特征工程部分还有很多空间可以挖掘，就留给大家去探索啦~</p>
<p>参考资料<br><a href="/materials/img/HumenOrRobot2/roc_forest.png">1</a> Chen, K. T., Pao, H. K. K., &amp; Chang, H. C. (2008, October). Game bot identification based on manifold learning. In Proceedings of the 7th ACM SIGCOMM Workshop on Network and System Support for Games (pp. 21-26). ACM.<br><a href="/materials/img/HumenOrRobot2/roc_gbm.png">2</a> Alayed, H., Frangoudes, F., &amp; Neuman, C. (2013, August). Behavioral-based cheating detection in online first person shooters using machine learning techniques. In Computational Intelligence in Games (CIG), 2013 IEEE Conference on (pp. 1-8). IEEE.<br><a href="/materials/img/HumenOrRobot2/roc_xgb.png">3</a> <a href="https://www.kaggle.com/c/facebook-recruiting-iv-human-or-bot/data" target="_blank" rel="external">https://www.kaggle.com/c/facebook-recruiting-iv-human-or-bot/data</a><br><a href="/materials/img/HumenOrRobot2/roc_lgbm.png">4</a> <a href="http://stats.stackexchange.com/a/132832/152084" target="_blank" rel="external">http://stats.stackexchange.com/a/132832/152084</a><br><a href="/materials/img/HumenOrRobot2/model_performance.png">5</a> <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" target="_blank" rel="external">https://en.wikipedia.org/wiki/Receiver_operating_characteristic</a><br><a href="/materials/img/HumenOrRobot2/time.png">6</a> <a href="https://en.wikipedia.org/wiki/Random_forest" target="_blank" rel="external">https://en.wikipedia.org/wiki/Random_forest</a><br><a href="/materials/img/HumenOrRobot2/roc_epoch.png">7</a> <a href="https://en.wikipedia.org/wiki/Gradient_boosting" target="_blank" rel="external">https://en.wikipedia.org/wiki/Gradient_boosting</a><br><a href="/materials/img/HumenOrRobot2/roc_stacking.png">8</a> <a href="https://xgboost.readthedocs.io/en/latest//parameter.html#parameters-for-tree-booster" target="_blank" rel="external">https://xgboost.readthedocs.io/en/latest//parameter.html#parameters-for-tree-booster</a><br><a href="/materials/img/HumenOrRobot2/roc_stacking2.png">9</a> <a href="https://github.com/Microsoft/LightGBM" target="_blank" rel="external">https://github.com/Microsoft/LightGBM</a><br><a href="/materials/img/HumenOrRobot2/roc_voting.png">10</a> <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" target="_blank" rel="external">https://en.wikipedia.org/wiki/Receiver_operating_characteristic</a><br><a href="/materials/img/HumenOrRobot2/point.png">11</a> <a href="http://stackoverflow.com/questions/29530232/python-pandas-check-if-any-value-is-nan-in-dataframe" target="_blank" rel="external">http://stackoverflow.com/questions/29530232/python-pandas-check-if-any-value-is-nan-in-dataframe</a><br>[12] <a href="http://pandas.pydata.org/pandas-docs/stable/missing_data.html" target="_blank" rel="external">http://pandas.pydata.org/pandas-docs/stable/missing_data.html</a><br>[13] <a href="http://stackoverflow.com/a/18272653/6653189" target="_blank" rel="external">http://stackoverflow.com/a/18272653/6653189</a><br>[14] <a href="http://www.cnblogs.com/jasonfreak/p/5720137.html" target="_blank" rel="external">http://www.cnblogs.com/jasonfreak/p/5720137.html</a> </p>
]]></content>
    
    <summary type="html">
    
      &lt;!-- 本文承接上一篇文章:[使用机器学习识别出拍卖场中作弊的机器人用户](../HumenOrRobot) --&gt;
&lt;p&gt;本文承接上一篇文章:&lt;a href=&quot;/2017/05/29/HumenOrRobot/&quot; title=&quot;使用机器学习识别出拍卖场中作弊的机器人用户&quot;&gt;使用机器学习识别出拍卖场中作弊的机器人用户&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本项目为kaggle上Facebook举行的一次比赛，地址见数据来源，完整代码见我的&lt;a href=&quot;https://github.com/LancelotHolmes/HumanOrRobot&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;github&lt;/a&gt;,欢迎来玩~&lt;/p&gt;
&lt;h2 id=&quot;代码&quot;&gt;&lt;a href=&quot;#代码&quot; class=&quot;headerlink&quot; title=&quot;代码&quot;&gt;&lt;/a&gt;代码&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;数据探索——Data_Exploration.ipynb&lt;/li&gt;
&lt;li&gt;数据预处理&amp;amp;特征工程——Feature_Engineering.ipynb &amp;amp; Feature_Engineering2.ipynb&lt;/li&gt;
&lt;li&gt;模型设计及评测——Model_Design.ipynb&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="ML" scheme="http://yoursite.com/tags/ML/"/>
    
      <category term="Kaggle" scheme="http://yoursite.com/tags/Kaggle/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>使用机器学习识别出拍卖场中作弊的机器人用户</title>
    <link href="http://yoursite.com/2017/05/29/HumenOrRobot/"/>
    <id>http://yoursite.com/2017/05/29/HumenOrRobot/</id>
    <published>2017-05-29T11:27:51.000Z</published>
    <updated>2017-05-30T06:50:50.126Z</updated>
    
    <content type="html"><![CDATA[<p>本项目为kaggle上Facebook举行的一次比赛，地址见数据来源，完整代码见我的<a href="https://github.com/LancelotHolmes/HumanOrRobot" target="_blank" rel="external">github</a>,欢迎来玩~</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><ul>
<li>数据探索——Data_Exploration.ipynb</li>
<li>数据预处理&amp;特征工程——Feature_Engineering.ipynb &amp; Feature_Engineering2.ipynb</li>
<li>模型设计及评测——Model_Design.ipynb</li>
</ul>
<a id="more"></a>
<h2 id="项目数据来源"><a href="#项目数据来源" class="headerlink" title="项目数据来源"></a>项目数据来源</h2><ul>
<li><a href="https://www.kaggle.com/c/facebook-recruiting-iv-human-or-bot/data" target="_blank" rel="external">kaggle</a><h2 id="项目所需额外工具包"><a href="#项目所需额外工具包" class="headerlink" title="项目所需额外工具包"></a>项目所需额外工具包</h2></li>
<li><a href="http://www.numpy.org/" target="_blank" rel="external">numpy</a></li>
<li><a href="http://pandas.pydata.org/" target="_blank" rel="external">pandas</a></li>
<li><a href="https://matplotlib.org/index.html" target="_blank" rel="external">matplotlib</a></li>
<li><a href="http://scikit-learn.org/stable/" target="_blank" rel="external">sklearn</a></li>
<li><a href="https://xgboost.readthedocs.io/en/latest//parameter.html#parameters-for-tree-booster" target="_blank" rel="external">xgboost</a></li>
<li><a href="https://github.com/Microsoft/LightGBM" target="_blank" rel="external">lightgbm</a></li>
<li><a href="https://github.com/rasbt/mlxtend" target="_blank" rel="external">mlxtend</a>: 含有聚和算法Stacking<br>项目整体运行时间预估为60min左右，在Ubuntu系统，8G内存，运行结果见所提交的jupyter notebook文件</li>
</ul>
<hr>
<p>由于文章内容过长，所以分为两篇文章，总共包含四个部分</p>
<ul>
<li>数据探索</li>
<li>数据预处理及特征工程</li>
<li>模型设计</li>
<li>评估及总结</li>
</ul>
<h2 id="数据探索"><a href="#数据探索" class="headerlink" title="数据探索"></a>数据探索</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line">%matplotlib inline</div><div class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">df_bids = pd.read_csv(<span class="string">'bids.csv'</span>, low_memory=<span class="keyword">False</span>)</div><div class="line">df_train = pd.read_csv(<span class="string">'train.csv'</span>)</div><div class="line">df_test = pd.read_csv(<span class="string">'test.csv'</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">df_bids.head(<span class="number">3</span>)</div></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>bid_id</th>
<th>bidder_id</th>
<th>auction</th>
<th>merchandise</th>
<th>device</th>
<th>time</th>
<th>country</th>
<th>ip</th>
<th>url</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>8dac2b259fd1c6d1120e519fb1ac14fbqvax8</td>
<td>ewmzr</td>
<td>jewelry</td>
<td>phone0</td>
<td>9759243157894736</td>
<td>us</td>
<td>69.166.231.58</td>
<td>vasstdc27m7nks3</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>668d393e858e8126275433046bbd35c6tywop</td>
<td>aeqok</td>
<td>furniture</td>
<td>phone1</td>
<td>9759243157894736</td>
<td>in</td>
<td>50.201.125.84</td>
<td>jmqlhflrzwuay9c</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>aa5f360084278b35d746fa6af3a7a1a5ra3xe</td>
<td>wa00e</td>
<td>home goods</td>
<td>phone2</td>
<td>9759243157894736</td>
<td>py</td>
<td>112.54.208.157</td>
<td>vasstdc27m7nks3</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">df_train.head(<span class="number">3</span>)</div><div class="line"><span class="comment"># df_train.dtypes</span></div></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>bidder_id</th>
<th>payment_account</th>
<th>address</th>
<th>outcome</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>91a3c57b13234af24875c56fb7e2b2f4rb56a</td>
<td>a3d2de7675556553a5f08e4c88d2c228754av</td>
<td>a3d2de7675556553a5f08e4c88d2c228vt0u4</td>
<td>0.0</td>
</tr>
<tr>
<td>1</td>
<td>624f258b49e77713fc34034560f93fb3hu3jo</td>
<td>a3d2de7675556553a5f08e4c88d2c228v1sga</td>
<td>ae87054e5a97a8f840a3991d12611fdcrfbq3</td>
<td>0.0</td>
</tr>
<tr>
<td>2</td>
<td>1c5f4fc669099bfbfac515cd26997bd12ruaj</td>
<td>a3d2de7675556553a5f08e4c88d2c2280cybl</td>
<td>92520288b50f03907041887884ba49c0cl0pd</td>
<td>0.0</td>
</tr>
</tbody>
</table>
<h3 id="异常数据检测"><a href="#异常数据检测" class="headerlink" title="异常数据检测"></a>异常数据检测</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 查看各表格中是否存在空值</span></div><div class="line"><span class="keyword">print</span> <span class="string">'Is there any missing value in bids?'</span>,df_bids.isnull().any().any()</div><div class="line"><span class="keyword">print</span> <span class="string">'Is there any missing value in train?'</span>,df_train.isnull().any().any()</div><div class="line"><span class="keyword">print</span> <span class="string">'Is there any missing value in test?'</span>,df_test.isnull().any().any()</div></pre></td></tr></table></figure>
<pre><code>Is there any missing value in bids? True
Is there any missing value in train? False
Is there any missing value in test? False
</code></pre><p>整个对三个数据集进行空值判断，发现用户数据训练集和测试集均无缺失数据，而在竞标行为数据集中存在缺失值的情况，下面便针对bids数据进一步寻找缺失值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># nan_rows = df_bids[df_bids.isnull().T.any().T]</span></div><div class="line"><span class="comment"># print nan_rows</span></div><div class="line">pd.isnull(df_bids).any()</div></pre></td></tr></table></figure>
<pre><code>bid_id         False
bidder_id      False
auction        False
merchandise    False
device         False
time           False
country         True
ip             False
url            False
dtype: bool
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">missing_country = df_bids[<span class="string">'country'</span>].isnull().sum().sum()</div><div class="line"><span class="keyword">print</span> <span class="string">'No. of missing country: '</span>, missing_country</div><div class="line">normal_country = df_bids[<span class="string">'country'</span>].notnull().sum().sum()</div><div class="line"><span class="keyword">print</span> <span class="string">'No. of normal country: '</span>, normal_country</div></pre></td></tr></table></figure>
<pre><code>No. of missing country:  8859
No. of normal country:  7647475
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line">labels = [<span class="string">'unknown'</span>, <span class="string">'normal'</span>]</div><div class="line">sizes = [missing_country, normal_country]</div><div class="line">explode = (<span class="number">0.1</span>, <span class="number">0</span>)</div><div class="line">fig1, ax1 = plt.subplots()</div><div class="line">ax1.pie(sizes, explode=explode, labels=labels, autopct=<span class="string">'%1.1f%%'</span>, shadow=<span class="keyword">True</span>, startangle=<span class="number">90</span>)</div><div class="line">ax1.axis(<span class="string">'equal'</span>)</div><div class="line">plt.title(<span class="string">'Distribution of missing countries vs. normal countries'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p><img src="/materials/img/HumenOrRobot/null.png" alt="empty value"></p>
<p>综合上述的分析可以发现，在竞标行为用户的<code>country</code>一栏属性中存在很少一部分用户行为是没有<code>country</code>记录的，在预处理部分可以针对这部分缺失数据进行填充操作，有两种思路：</p>
<ul>
<li>针对原始行为数据按照用户分组后，看看每个对应的用户竞标时经常所位于的国家信息，对缺失值填充常驻国家</li>
<li>针对原始行为数据按照用户分组后，按时间顺序对每组用户中的缺失值前向或后向填充相邻的国家信息</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 查看各个数据的记录数</span></div><div class="line"><span class="comment"># 看看数据的id是否是唯一标识</span></div><div class="line"><span class="keyword">print</span> df_bids.shape[<span class="number">0</span>]</div><div class="line"><span class="keyword">print</span> len(df_bids[<span class="string">'bid_id'</span>].unique())</div><div class="line"><span class="keyword">print</span> df_train.shape[<span class="number">0</span>]</div><div class="line"><span class="keyword">print</span> len(df_train[<span class="string">'bidder_id'</span>].unique())</div><div class="line"><span class="keyword">print</span> df_test.shape[<span class="number">0</span>]</div><div class="line"><span class="keyword">print</span> len(df_test[<span class="string">'bidder_id'</span>].unique())</div></pre></td></tr></table></figure>
<pre><code>7656334
7656334
2013
2013
4700
4700
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 简单统计各项基本特征（类别特征）的数目（除去时间）</span></div><div class="line"><span class="keyword">print</span> <span class="string">'total bidder in bids: '</span>, len(df_bids[<span class="string">'bidder_id'</span>].unique())</div><div class="line"><span class="keyword">print</span> <span class="string">'total auction in bids: '</span>, len(df_bids[<span class="string">'auction'</span>].unique())</div><div class="line"><span class="keyword">print</span> <span class="string">'total merchandise in bids: '</span>, len(df_bids[<span class="string">'merchandise'</span>].unique())</div><div class="line"><span class="keyword">print</span> <span class="string">'total device in bids: '</span>, len(df_bids[<span class="string">'device'</span>].unique())</div><div class="line"><span class="keyword">print</span> <span class="string">'total country in bids: '</span>, len(df_bids[<span class="string">'country'</span>].unique())</div><div class="line"><span class="keyword">print</span> <span class="string">'total ip in bids: '</span>, len(df_bids[<span class="string">'ip'</span>].unique())</div><div class="line"><span class="keyword">print</span> <span class="string">'total url in bids: '</span>, len(df_bids[<span class="string">'url'</span>].unique())</div></pre></td></tr></table></figure>
<pre><code>total bidder in bids:  6614
total auction in bids:  15051
total merchandise in bids:  10
total device in bids:  7351
total country in bids:  200
total ip in bids:  2303991
total url in bids:  1786351
</code></pre><p>由上述基本特征可以看到：</p>
<ul>
<li>竞标行为中的用户总数少于训练集+测试集的用户数，也就是说并不是一一对应的，接下来验证下竞标行为数据中的用户是否完全来自训练集和测试集</li>
<li>商品类别和国家的种类相对其他特征较少，可以作为天然的类别特征提取出来进行处理，而其余的特征可能更多的进行计数统计</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">lst_all_users = (df_train[<span class="string">'bidder_id'</span>].unique()).tolist() + (df_test[<span class="string">'bidder_id'</span>].unique()).tolist()</div><div class="line"><span class="keyword">print</span> <span class="string">'total bidders of train and test set'</span>,len(lst_all_users)</div><div class="line">lst_bidder = (df_bids[<span class="string">'bidder_id'</span>].unique()).tolist()</div><div class="line"><span class="keyword">print</span> <span class="string">'total bidders in bids set'</span>,len(lst_bidder)</div><div class="line"><span class="keyword">print</span> <span class="string">'Is bidders in bids are all from train+test set? '</span>,set(lst_bidder).issubset(set(lst_all_users))</div></pre></td></tr></table></figure>
<pre><code>total bidders of train and test set 6713
total bidders in bids set 6614
Is bidders in bids are all from train+test set?  True
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">lst_nobids = [i <span class="keyword">for</span> i <span class="keyword">in</span> lst_all_users <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> lst_bidder]</div><div class="line"><span class="keyword">print</span> <span class="string">'No. of bidders never bid: '</span>,len(lst_nobids)</div><div class="line">lst_nobids_train = [i <span class="keyword">for</span> i <span class="keyword">in</span> lst_nobids <span class="keyword">if</span> i <span class="keyword">in</span> (df_train[<span class="string">'bidder_id'</span>].unique()).tolist()]</div><div class="line">lst_nobids_test = [i <span class="keyword">for</span> i <span class="keyword">in</span> lst_nobids <span class="keyword">if</span> i <span class="keyword">in</span> (df_test[<span class="string">'bidder_id'</span>].unique()).tolist()]</div><div class="line"><span class="keyword">print</span> <span class="string">'No. of bidders never bid in train set: '</span>,len(lst_nobids_train)</div><div class="line"><span class="keyword">print</span> <span class="string">'No. of bidders never bid in test set: '</span>,len(lst_nobids_test)</div></pre></td></tr></table></figure>
<pre><code>No. of bidders never bid:  99
No. of bidders never bid in train set:  29
No. of bidders never bid in test set:  70
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">data_source = [<span class="string">'train'</span>, <span class="string">'test'</span>]</div><div class="line">y_pos = np.arange(len(data_source))</div><div class="line">num_never_bids = [len(lst_nobids_train), len(lst_nobids_test)]</div><div class="line">plt.bar(y_pos, num_never_bids, align=<span class="string">'center'</span>, alpha=<span class="number">0.5</span>)</div><div class="line">plt.xticks(y_pos, data_source)</div><div class="line">plt.ylabel(<span class="string">'bidders no bids'</span>)</div><div class="line">plt.title(<span class="string">'Source of no bids bidders'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p><img src="/materials/img/HumenOrRobot/no_bidders.png" alt="source of no bid bidders"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> df_train[(df_train[<span class="string">'bidder_id'</span>].isin(lst_nobids_train)) &amp; (df_train[<span class="string">'outcome'</span>]==<span class="number">1.0</span>)]</div></pre></td></tr></table></figure>
<pre><code>Empty DataFrame
Columns: [bidder_id, payment_account, address, outcome]
Index: []
</code></pre><p>由上述计算可知存在99个竞标者无竞标记录，其中29位来自训练集，70位来自测试集，而且这29位来自训练集的竞标者未被标记为机器人用户，所以可以针对测试集中的这70位用户后续标记为人类或者取平均值处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># check the partition of bots in train</span></div><div class="line"><span class="keyword">print</span> (df_train[df_train[<span class="string">'outcome'</span>] == <span class="number">1</span>].shape[<span class="number">0</span>]*<span class="number">1.0</span>) / df_train.shape[<span class="number">0</span>] * <span class="number">100</span>,<span class="string">'%'</span></div></pre></td></tr></table></figure>
<pre><code>5.11674118231 %
</code></pre><p>训练集中的标记为机器人的用户占所有用户数目约5%</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">df_train.groupby(<span class="string">'outcome'</span>).size().plot(labels=[<span class="string">'Human'</span>, <span class="string">'Robot'</span>], kind=<span class="string">'pie'</span>, autopct=<span class="string">'%.2f'</span>, figsize=(<span class="number">4</span>, <span class="number">4</span>), </div><div class="line">                                        title=<span class="string">'Distribution of Human vs. Robots'</span>, legend=<span class="keyword">True</span>)</div></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f477135c5d0&gt;
</code></pre><p><img src="/materials/img/HumenOrRobot/pos_neg.png" alt="正负例比较"></p>
<p>由上述训练集中的正负例分布可以看到本数据集正负例比例失衡，所以后续考虑使用AUC（不受正负例比例影响）作为评价指标，此外尽量采用Gradient Boosting族模型来进行训练</p>
<h2 id="数据预处理与特征工程"><a href="#数据预处理与特征工程" class="headerlink" title="数据预处理与特征工程"></a>数据预处理与特征工程</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> pickle</div><div class="line">%matplotlib inline</div><div class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">bids = pd.read_csv(<span class="string">'bids.csv'</span>)</div><div class="line">train = pd.read_csv(<span class="string">'train.csv'</span>)</div><div class="line">test = pd.read_csv(<span class="string">'test.csv'</span>)</div></pre></td></tr></table></figure>
<h3 id="处理缺失数据"><a href="#处理缺失数据" class="headerlink" title="处理缺失数据"></a>处理缺失数据</h3><p>针对前面数据探索部分所发现的竞标行为数据中存在的国家属性缺失问题，考虑使用针对原始行为数据按照用户分组后，按时间顺序对每组用户中的缺失值前向或后向填充相邻的国家信息的方法来进行缺失值的填充处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">display(bids.head(<span class="number">3</span>))</div></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>bid_id</th>
<th>bidder_id</th>
<th>auction</th>
<th>merchandise</th>
<th>device</th>
<th>time</th>
<th>country</th>
<th>ip</th>
<th>url</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>8dac2b259fd1c6d1120e519fb1ac14fbqvax8</td>
<td>ewmzr</td>
<td>jewelry</td>
<td>phone0</td>
<td>9759243157894736</td>
<td>us</td>
<td>69.166.231.58</td>
<td>vasstdc27m7nks3</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>668d393e858e8126275433046bbd35c6tywop</td>
<td>aeqok</td>
<td>furniture</td>
<td>phone1</td>
<td>9759243157894736</td>
<td>in</td>
<td>50.201.125.84</td>
<td>jmqlhflrzwuay9c</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>aa5f360084278b35d746fa6af3a7a1a5ra3xe</td>
<td>wa00e</td>
<td>home goods</td>
<td>phone2</td>
<td>9759243157894736</td>
<td>py</td>
<td>112.54.208.157</td>
<td>vasstdc27m7nks3</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># pd.algos.is_monotonic_int64(bids.time.values, True)[0]</span></div><div class="line"><span class="keyword">print</span> <span class="string">'Is the time monotonically non-decreasing? '</span>, pd.Index(bids[<span class="string">'time'</span>]).is_monotonic</div></pre></td></tr></table></figure>
<pre><code>Is the time monotonically non-decreasing?  False
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># bidder_group = bids.sort_values(['bidder_id', 'time']).groupby('bidder_id')</span></div><div class="line">bids[<span class="string">'country'</span>] = bids.sort_values([<span class="string">'bidder_id'</span>, <span class="string">'time'</span>]).groupby(<span class="string">'bidder_id'</span>)[<span class="string">'country'</span>].ffill()</div><div class="line">bids[<span class="string">'country'</span>] = bids.sort_values([<span class="string">'bidder_id'</span>, <span class="string">'time'</span>]).groupby(<span class="string">'bidder_id'</span>)[<span class="string">'country'</span>].bfill()</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">display(bids.head(<span class="number">3</span>))</div></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>bid_id</th>
<th>bidder_id</th>
<th>auction</th>
<th>merchandise</th>
<th>device</th>
<th>time</th>
<th>country</th>
<th>ip</th>
<th>url</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>8dac2b259fd1c6d1120e519fb1ac14fbqvax8</td>
<td>ewmzr</td>
<td>jewelry</td>
<td>phone0</td>
<td>9759243157894736</td>
<td>us</td>
<td>69.166.231.58</td>
<td>vasstdc27m7nks3</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>668d393e858e8126275433046bbd35c6tywop</td>
<td>aeqok</td>
<td>furniture</td>
<td>phone1</td>
<td>9759243157894736</td>
<td>in</td>
<td>50.201.125.84</td>
<td>jmqlhflrzwuay9c</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>aa5f360084278b35d746fa6af3a7a1a5ra3xe</td>
<td>wa00e</td>
<td>home goods</td>
<td>phone2</td>
<td>9759243157894736</td>
<td>py</td>
<td>112.54.208.157</td>
<td>vasstdc27m7nks3</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> <span class="string">'Is there any missing value in bids?'</span>,bids.isnull().any().any()</div><div class="line"><span class="comment"># pickle.dump(bids, open('bids.pkl', 'w'))</span></div></pre></td></tr></table></figure>
<pre><code>Is there any missing value in bids? True
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">missing_country = bids[<span class="string">'country'</span>].isnull().sum().sum()</div><div class="line"><span class="keyword">print</span> <span class="string">'No. of missing country: '</span>, missing_country</div><div class="line">normal_country = bids[<span class="string">'country'</span>].notnull().sum().sum()</div><div class="line"><span class="keyword">print</span> <span class="string">'No. of normal country: '</span>, normal_country</div></pre></td></tr></table></figure>
<pre><code>No. of missing country:  5
No. of normal country:  7656329
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">nan_rows = bids[bids.isnull().T.any().T]</div><div class="line"><span class="keyword">print</span> nan_rows</div></pre></td></tr></table></figure>
<pre><code>          bid_id                              bidder_id auction  \
1351177  1351177  f3ab8c9ecc0d021ebc81e89f20c8267bn812w   jefix   
2754184  2754184  88ef9cfdbec4c9e33f6c2e0b512e7a01dp2p2   cc5fs   
2836631  2836631  29b8af2fea3881ef61911612372dac41vczqv   jqx39   
3125892  3125892  df20f216cbb0b0df5a7b2e94b16a7853iyw9g   jqx39   
5153748  5153748  5e05ec450e2dd64d7996a08bbbca4f126nzzk   jqx39   

              merchandise    device              time country  \
1351177  office equipment   phone84  9767200789473684     NaN   
2754184            mobile  phone150  9633363947368421     NaN   
2836631           jewelry   phone72  9634034894736842     NaN   
3125892   books and music  phone106  9635755105263157     NaN   
5153748            mobile  phone267  9645270210526315     NaN   

                      ip              url  
1351177   80.211.119.111  g9pgdfci3yseml5  
2754184     20.67.240.88  ctivbfq55rktail  
2836631  149.210.107.205  vasstdc27m7nks3  
3125892      26.23.62.59  ac9xlqtfg0cx5c5  
5153748     145.7.194.40  0em0vg1f0zuxonw  
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># print bids[bids['bid_id']==1351177]</span></div><div class="line">nan_bidder = nan_rows[<span class="string">'bidder_id'</span>].values.tolist()</div><div class="line"><span class="comment"># print nan_bidder</span></div><div class="line"><span class="keyword">print</span> bids[bids[<span class="string">'bidder_id'</span>].isin(nan_bidder)]</div></pre></td></tr></table></figure>
<pre><code>          bid_id                              bidder_id auction  \
1351177  1351177  f3ab8c9ecc0d021ebc81e89f20c8267bn812w   jefix   
2754184  2754184  88ef9cfdbec4c9e33f6c2e0b512e7a01dp2p2   cc5fs   
2836631  2836631  29b8af2fea3881ef61911612372dac41vczqv   jqx39   
3125892  3125892  df20f216cbb0b0df5a7b2e94b16a7853iyw9g   jqx39   
5153748  5153748  5e05ec450e2dd64d7996a08bbbca4f126nzzk   jqx39   

              merchandise    device              time country  \
1351177  office equipment   phone84  9767200789473684     NaN   
2754184            mobile  phone150  9633363947368421     NaN   
2836631           jewelry   phone72  9634034894736842     NaN   
3125892   books and music  phone106  9635755105263157     NaN   
5153748            mobile  phone267  9645270210526315     NaN   

                      ip              url  
1351177   80.211.119.111  g9pgdfci3yseml5  
2754184     20.67.240.88  ctivbfq55rktail  
2836631  149.210.107.205  vasstdc27m7nks3  
3125892      26.23.62.59  ac9xlqtfg0cx5c5  
5153748     145.7.194.40  0em0vg1f0zuxonw  
</code></pre><p>在对整体数据的部分用户缺失国家的按照各个用户分组后在时间上前向和后向填充后，仍然存在5个用户缺失了国家信息，结果发现这5个用户是仅有一次竞标行为，下面看看这5个用户还有什么特征</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">lst_nan_train = [i <span class="keyword">for</span> i <span class="keyword">in</span> nan_bidder <span class="keyword">if</span> i <span class="keyword">in</span> (train[<span class="string">'bidder_id'</span>].unique()).tolist()]</div><div class="line">lst_nan_test = [i <span class="keyword">for</span> i <span class="keyword">in</span> nan_bidder <span class="keyword">if</span> i <span class="keyword">in</span> (test[<span class="string">'bidder_id'</span>].unique()).tolist()]</div><div class="line"><span class="keyword">print</span> <span class="string">'No. of bidders 1 bid in train set: '</span>,len(lst_nan_train)</div><div class="line"><span class="keyword">print</span> <span class="string">'No. of bidders 1 bid in test set: '</span>,len(lst_nan_test)</div></pre></td></tr></table></figure>
<pre><code>No. of bidders 1 bid in train set:  1
No. of bidders 1 bid in test set:  4
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> train[train[<span class="string">'bidder_id'</span>]==lst_nan_train[<span class="number">0</span>]][<span class="string">'outcome'</span>]</div></pre></td></tr></table></figure>
<pre><code>546    0.0
Name: outcome, dtype: float64
</code></pre><p>由于这5个用户仅有一次竞标行为，而且其中1个用户来自训练集，4个来自测试集，由训练集用户的标记为人类，加上行为数太少，所以考虑对这5个用户的竞标行为数据予以舍弃，特别对测试集的4个用户后续操作类似之前对无竞标行为的用户，预测值填充最终模型的平均预测值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">bid_to_drop = nan_rows.index.values.tolist()</div><div class="line"><span class="comment"># print bid_to_drop</span></div><div class="line">bids.drop(bids.index[bid_to_drop], inplace=<span class="keyword">True</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> <span class="string">'Is there any missing value in bids?'</span>,bids.isnull().any().any()</div><div class="line">pickle.dump(bids, open(<span class="string">'bids.pkl'</span>, <span class="string">'w'</span>))</div></pre></td></tr></table></figure>
<pre><code>Is there any missing value in bids? False
</code></pre><h3 id="统计基本的计数特征"><a href="#统计基本的计数特征" class="headerlink" title="统计基本的计数特征"></a>统计基本的计数特征</h3><p>根据前面的数据探索，由于数据集大部分由类别数据或者离散型数据构成，所以首先针对竞标行为数据按照竞标者分组统计其各项属性的数目，比如使用设备种类，参与竞标涉及国家，ip种类等等</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># group by bidder to do some statistics</span></div><div class="line">bidders = bids.groupby(<span class="string">'bidder_id'</span>)</div><div class="line"><span class="comment"># pickle.dump(bids, open('bidders.pkl', 'w'))</span></div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># print bidders['device'].count()</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">feature_count</span><span class="params">(group)</span>:</span></div><div class="line">    dct_cnt = &#123;&#125;</div><div class="line">    dct_cnt[<span class="string">'devices_c'</span>] = group[<span class="string">'device'</span>].unique().shape[<span class="number">0</span>]</div><div class="line">    dct_cnt[<span class="string">'countries_c'</span>] = group[<span class="string">'country'</span>].unique().shape[<span class="number">0</span>]</div><div class="line">    dct_cnt[<span class="string">'ip_c'</span>] = group[<span class="string">'ip'</span>].unique().shape[<span class="number">0</span>]</div><div class="line">    dct_cnt[<span class="string">'url_c'</span>] = group[<span class="string">'url'</span>].unique().shape[<span class="number">0</span>]    </div><div class="line">    dct_cnt[<span class="string">'auction_c'</span>] = group[<span class="string">'auction'</span>].unique().shape[<span class="number">0</span>]</div><div class="line">    dct_cnt[<span class="string">'auc_mean'</span>] = np.mean(group[<span class="string">'auction'</span>].value_counts())    <span class="comment"># bids_c/auction_c</span></div><div class="line"><span class="comment">#     dct_cnt['dev_mean'] = np.mean(group['device'].value_counts())    # bids_c/devices_c</span></div><div class="line">    dct_cnt[<span class="string">'merch_c'</span>] = group[<span class="string">'merchandise'</span>].unique().shape[<span class="number">0</span>]</div><div class="line">    dct_cnt[<span class="string">'bids_c'</span>] = group.shape[<span class="number">0</span>]</div><div class="line">    dct_cnt = pd.Series(dct_cnt)</div><div class="line">    <span class="keyword">return</span> dct_cnt</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cnt_bidder = bidders.apply(feature_count)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">display(cnt_bidder.describe())</div><div class="line"><span class="comment"># cnt_bidder.to_csv('cnt_bidder.csv')</span></div><div class="line"><span class="comment"># print cnt_bidder[cnt_bidder['merch_c']==2]</span></div></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>-</th>
<th>auc_mean</th>
<th>auction_c</th>
<th>bids_c</th>
<th>countries_c</th>
<th>devices_c</th>
<th>ip_c</th>
<th>merch_c</th>
<th>url_c</th>
</tr>
</thead>
<tbody>
<tr>
<td>count</td>
<td>6609.000000</td>
<td>6609.000000</td>
<td>6609.000000</td>
<td>6609.000000</td>
<td>6609.000000</td>
<td>6609.000000</td>
<td>6609.000000</td>
<td>6609.000000</td>
</tr>
<tr>
<td>mean</td>
<td>6.593493</td>
<td>57.850810</td>
<td>1158.470117</td>
<td>12.733848</td>
<td>73.492359</td>
<td>544.507187</td>
<td>1.000151</td>
<td>290.964140</td>
</tr>
<tr>
<td>std</td>
<td>30.009242</td>
<td>131.814053</td>
<td>9596.595169</td>
<td>22.556570</td>
<td>172.171106</td>
<td>3370.730666</td>
<td>0.012301</td>
<td>2225.912425</td>
</tr>
<tr>
<td>min</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
</tr>
<tr>
<td>25%</td>
<td>1.000000</td>
<td>2.000000</td>
<td>3.000000</td>
<td>1.000000</td>
<td>2.000000</td>
<td>2.000000</td>
<td>1.000000</td>
<td>1.000000</td>
</tr>
<tr>
<td>50%</td>
<td>1.677419</td>
<td>10.000000</td>
<td>18.000000</td>
<td>3.000000</td>
<td>8.000000</td>
<td>12.000000</td>
<td>1.000000</td>
<td>5.000000</td>
</tr>
<tr>
<td>75%</td>
<td>4.142857</td>
<td>47.000000</td>
<td>187.000000</td>
<td>12.000000</td>
<td>57.000000</td>
<td>111.000000</td>
<td>1.000000</td>
<td>36.000000</td>
</tr>
<tr>
<td>max</td>
<td>1327.366667</td>
<td>1726.000000</td>
<td>515033.000000</td>
<td>178.000000</td>
<td>2618.000000</td>
<td>111918.000000</td>
<td>2.000000</td>
<td>81376.000000</td>
</tr>
</tbody>
</table>
<h3 id="特征相关性"><a href="#特征相关性" class="headerlink" title="特征相关性"></a>特征相关性</h3><p>在对竞标行为数据按照用户分组后，对数据集中的每一个产品特征构建一个散布矩阵（scatter matrix），来看看各特征之间的相关性</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 对于数据中的每一对特征构造一个散布矩阵</span></div><div class="line">pd.scatter_matrix(cnt_bidder, alpha = <span class="number">0.3</span>, figsize = (<span class="number">16</span>,<span class="number">10</span>), diagonal = <span class="string">'kde'</span>);</div></pre></td></tr></table></figure>
<p><img src="/materials/img/HumenOrRobot/scatter_origin.png" alt="scatter matrix"></p>
<p>在针对竞标行为数据按照竞标用户进行分组基本统计后由上表可以看出，此时并未考虑时间戳的情形下，有以下基本结论：</p>
<ul>
<li>由各项统计的最大值与中位值，75%值的比较可以看到除了商品类别一项，其他的几项多少都存在一些异常数值，或许可以作为异常行为进行观察</li>
<li>各特征的倾斜度很大，考虑对特征进行取对数的操作，并再次输出散布矩阵看看相关性。</li>
<li>商品类别计数这一特征的方差很小，而且从中位数乃至75%的统计来看，大多数用户仅对同一类别商品进行拍卖，而且因为前面数据探索部分发现商品类别本身适合作为类别数据，所以考虑分多个类别进行单独统计，而在计数特征中舍弃该特征。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cnt_bidder.drop(<span class="string">'merch_c'</span>, axis=<span class="number">1</span>, inplace=<span class="keyword">True</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cnt_bidder = np.log(cnt_bidder)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pd.scatter_matrix(cnt_bidder, alpha = <span class="number">0.3</span>, figsize = (<span class="number">16</span>,<span class="number">10</span>), diagonal = <span class="string">'kde'</span>);</div></pre></td></tr></table></figure>
<p><img src="/materials/img/HumenOrRobot/scatter_new.png" alt="scatter matrix(log)"></p>
<p>由上面的散布矩阵可以看到，个行为特征之间并没有表现出很强的相关性，虽然其中的ip计数和竞标计数，设备计数在进行对数操作处理之后表现出轻微的正相关性，但是由于是在做了对数操作之后才体现，而且从图中可以看到并非很强的相关性，所以保留这三个特征。</p>
<p>针对前述的异常行为，先从原train数据集中的机器人、人类中分别挑选几个样本进行追踪观察他们在按照bidders分组后的统计结果，对比看看</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cnt_bidder.to_csv(<span class="string">'cnt_bidder.csv'</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># trace samples,first 2 bots, last 2 humen</span></div><div class="line">indices = [<span class="string">'9434778d2268f1fa2a8ede48c0cd05c097zey'</span>,<span class="string">'aabc211b4cf4d29e4ac7e7e361371622pockb'</span>,</div><div class="line">           <span class="string">'d878560888b11447e73324a6e263fbd5iydo1'</span>,<span class="string">'91a3c57b13234af24875c56fb7e2b2f4rb56a'</span>]</div><div class="line"></div><div class="line"><span class="comment"># build a DataFrame for the choosed indices</span></div><div class="line">samples = pd.DataFrame(cnt_bidder.loc[indices], columns = cnt_bidder.keys()).reset_index(drop = <span class="keyword">True</span>)</div><div class="line"><span class="keyword">print</span> <span class="string">"Chosen samples of training dataset:(first 2 bots, last 2 humen)"</span></div><div class="line">display(samples)</div></pre></td></tr></table></figure>
<pre><code>Chosen samples of training dataset:(first 2 bots, last 2 humen)
</code></pre><table>
<thead>
<tr>
<th>auc_mean</th>
<th>auction_c</th>
<th>bids_c</th>
<th>countries_c</th>
<th>devices_c</th>
<th>ip_c</th>
<th>url_c</th>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
</tr>
</thead>
<tbody>
<tr>
<td>3.190981</td>
<td>5.594711</td>
<td>8.785692</td>
<td>4.174387</td>
<td>6.011267</td>
<td>8.147578</td>
<td>7.557995</td>
</tr>
<tr>
<td>2.780432</td>
<td>4.844187</td>
<td>7.624619</td>
<td>2.639057</td>
<td>3.178054</td>
<td>5.880533</td>
<td>1.609438</td>
</tr>
<tr>
<td>0.287682</td>
<td>1.098612</td>
<td>1.386294</td>
<td>1.098612</td>
<td>1.386294</td>
<td>1.386294</td>
<td>0.000000</td>
</tr>
<tr>
<td>0.287682</td>
<td>2.890372</td>
<td>3.178054</td>
<td>1.791759</td>
<td>2.639057</td>
<td>2.995732</td>
<td>0.000000</td>
</tr>
</tbody>
</table>
<p>使用seaborn来对上面四个例子的热力图进行可视化，看看percentile的情况</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</div><div class="line"></div><div class="line"><span class="comment"># look at percentile ranks</span></div><div class="line">pcts = <span class="number">100.</span> * cnt_bidder.rank(axis=<span class="number">0</span>, pct=<span class="keyword">True</span>).loc[indices].round(decimals=<span class="number">3</span>)</div><div class="line"><span class="keyword">print</span> pcts</div><div class="line"></div><div class="line"><span class="comment"># visualize percentiles with heatmap</span></div><div class="line">sns.heatmap(pcts, yticklabels=[<span class="string">'robot 1'</span>, <span class="string">'robot 2'</span>, <span class="string">'human 1'</span>, <span class="string">'human 2'</span>], annot=<span class="keyword">True</span>, linewidth=<span class="number">.1</span>, vmax=<span class="number">99</span>, </div><div class="line">            fmt=<span class="string">'.1f'</span>, cmap=<span class="string">'YlGnBu'</span>)</div><div class="line">plt.title(<span class="string">'Percentile ranks of\nsamples\' feature statistics'</span>)</div><div class="line">plt.xticks(rotation=<span class="number">45</span>, ha=<span class="string">'center'</span>);</div></pre></td></tr></table></figure>
<pre><code>                                       auc_mean  auction_c  bids_c  \
bidder_id                                                            
9434778d2268f1fa2a8ede48c0cd05c097zey      94.9       94.6    97.0   
aabc211b4cf4d29e4ac7e7e361371622pockb      92.4       87.2    92.3   
d878560888b11447e73324a6e263fbd5iydo1      39.8       30.4    30.2   
91a3c57b13234af24875c56fb7e2b2f4rb56a      39.8       60.2    53.0   

                                       countries_c  devices_c  ip_c  url_c  
bidder_id                                                                   
9434778d2268f1fa2a8ede48c0cd05c097zey         95.4       95.6  96.7   97.4  
aabc211b4cf4d29e4ac7e7e361371622pockb         77.3       63.8  84.8   50.3  
d878560888b11447e73324a6e263fbd5iydo1         48.8       38.7  34.2   13.4  
91a3c57b13234af24875c56fb7e2b2f4rb56a         63.7       56.8  56.2   13.4  
</code></pre><p><img src="/materials/img/HumenOrRobot/hot_map.png" alt="hot map"></p>
<p>由上面的热力图对比可以看到，机器人的各项统计指标除去商品类别上的统计以外，均比人类用户要高，所以考虑据此设计基于基本统计指标规则的基准模型，其中最显著的特征差异应该是在<code>auc_mean</code>一项即用户在各个拍卖场的平均竞标次数，不妨先按照异常值处理的方法来找出上述基础统计中的异常情况</p>
<h3 id="设计朴素分类器"><a href="#设计朴素分类器" class="headerlink" title="设计朴素分类器"></a>设计朴素分类器</h3><p>由于最终目的是从竞标者中寻找到机器人用户，而根据常识，机器人用户的各项竞标行为的操作应该比人类要频繁许多，所以可以从异常值检验的角度来设计朴素分类器，根据之前针对不同用户统计的基本特征计数情况，可以先针对每一个特征找出其中的疑似异常用户列表，最后整合各个特征生成的用户列表，认为超过多个特征异常的用户为机器人用户。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># find the outliers for each feature</span></div><div class="line">lst_outlier = []</div><div class="line"><span class="keyword">for</span> feature <span class="keyword">in</span> cnt_bidder.keys():</div><div class="line">    <span class="comment"># percentile  25th</span></div><div class="line">    Q1 = np.percentile(cnt_bidder[feature], <span class="number">25</span>)</div><div class="line">    <span class="comment"># percentile  75th</span></div><div class="line">    Q3 = np.percentile(cnt_bidder[feature], <span class="number">75</span>)</div><div class="line">    step = <span class="number">1.5</span> * (Q3 - Q1)    </div><div class="line">    <span class="comment"># show outliers</span></div><div class="line">    <span class="comment"># print "Data points considered outliers for the feature '&#123;&#125;':".format(feature)</span></div><div class="line">    display(cnt_bidder[~((cnt_bidder[feature] &gt;= Q1 - step) &amp; (cnt_bidder[feature] &lt;= Q3 + step))])</div><div class="line">    lst_outlier += cnt_bidder[~((cnt_bidder[feature] &gt;= Q1 - step) &amp; (cnt_bidder[feature] &lt;= Q3 + step))].index.values.tolist()</div></pre></td></tr></table></figure>
<p>再找到各种特征的所有可能作为‘异常值’的用户id之后，可以对其做一个基本统计，进一步找出其中超过某几个特征值均异常的用户，经过测试，考虑到原始train集合里bots用户不到5%，所以最终确定以不低于1个特征值均异常的用户作为异常用户的一个假设，由此与train集合里的用户进行交叉，可以得到一个用户子集，可以作为朴素分类器的一个操作方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># print len(lst_outlier)</span></div><div class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</div><div class="line">freq_outlier = dict(Counter(lst_outlier))</div><div class="line">perhaps_outlier = [i <span class="keyword">for</span> i <span class="keyword">in</span> freq_outlier <span class="keyword">if</span> freq_outlier[i] &gt;= <span class="number">1</span>]</div><div class="line"><span class="keyword">print</span> len(perhaps_outlier)</div></pre></td></tr></table></figure>
<pre><code>214
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># basic_pred = test[test['bidder_id'].isin(perhaps_outlier)]['bidder_id'].tolist()</span></div><div class="line">train_pred = train[train[<span class="string">'bidder_id'</span>].isin(perhaps_outlier)][<span class="string">'bidder_id'</span>].tolist()</div><div class="line"><span class="keyword">print</span> len(train_pred)</div></pre></td></tr></table></figure>
<pre><code>76
</code></pre><h3 id="设计评价指标"><a href="#设计评价指标" class="headerlink" title="设计评价指标"></a>设计评价指标</h3><p>根据前面数据探索知本实验中的数据集的正负例比例约为19:1，有些失衡，所以考虑使用auc这种不受正负例比例影响的评价指标作为衡量标准，现针对所涉及的朴素分类器在原始训练集上的表现得到一个基准得分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</div><div class="line">y_true = train[<span class="string">'outcome'</span>]</div><div class="line">naive_pred = pd.DataFrame(columns=[<span class="string">'bidder_id'</span>, <span class="string">'prediction'</span>])</div><div class="line">naive_pred[<span class="string">'bidder_id'</span>] = train[<span class="string">'bidder_id'</span>]</div><div class="line">naive_pred[<span class="string">'prediction'</span>] = np.where(naive_pred[<span class="string">'bidder_id'</span>].isin(train_pred), <span class="number">1.0</span>, <span class="number">0.0</span>)</div><div class="line">basic_pred = naive_pred[<span class="string">'prediction'</span>]</div><div class="line"><span class="keyword">print</span> roc_auc_score(y_true, basic_pred)</div></pre></td></tr></table></figure>
<pre><code>0.54661464952
</code></pre><p>在经过上述对基本计数特征的统计之后，目前尚未针对非类别特征：时间戳进行处理，而在之前的数据探索过程中，针对商品类别和国家这两个类别属性，可以将原始的单一特征转换为多个特征分别统计，此外，在上述分析过程中，我们发现针对用户分组可以进一步对于拍卖场进行分组统计。</p>
<ul>
<li>对时间戳进行处理</li>
<li>针对商品类别、国家转换为多个类别分别进行统计</li>
<li>按照用户-拍卖场进行分组进一步统计</li>
</ul>
<h3 id="对时间戳进行处理"><a href="#对时间戳进行处理" class="headerlink" title="对时间戳进行处理"></a>对时间戳进行处理</h3><p>主要是分析各个竞标行为的时间间隔，即统计竞标行为表中在同一拍卖场的各个用户之间的竞标行为间隔</p>
<p>然后针对每个用户对其他用户的时间间隔计算</p>
<ul>
<li>时间间隔均值</li>
<li>时间间隔最大值</li>
<li>时间间隔最小值</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_timediff</span><span class="params">()</span>:</span>    </div><div class="line">    bids_grouped = bids.groupby(<span class="string">'auction'</span>)</div><div class="line">    bds = defaultdict(list)</div><div class="line">    last_row = <span class="keyword">None</span></div><div class="line"></div><div class="line">    <span class="keyword">for</span> bids_auc <span class="keyword">in</span> bids_grouped:</div><div class="line">        <span class="keyword">for</span> i, row <span class="keyword">in</span> bids_auc[<span class="number">1</span>].iterrows():</div><div class="line">            <span class="keyword">if</span> last_row <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">                last_row = row</div><div class="line">                <span class="keyword">continue</span></div><div class="line"></div><div class="line">            time_difference = row[<span class="string">'time'</span>] - last_row[<span class="string">'time'</span>]</div><div class="line">            bds[row[<span class="string">'bidder_id'</span>]].append(time_difference)</div><div class="line">            last_row = row</div><div class="line"></div><div class="line">    df = []</div><div class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> bds.keys():</div><div class="line">        df.append(&#123;<span class="string">'bidder_id'</span>: key, <span class="string">'mean'</span>: np.mean(bds[key]),</div><div class="line">                   <span class="string">'min'</span>: np.min(bds[key]), <span class="string">'max'</span>: np.max(bds[key])&#125;)</div><div class="line"></div><div class="line">    pd.DataFrame(df).to_csv(<span class="string">'tdiff.csv'</span>, index=<span class="keyword">False</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">generate_timediff()</div></pre></td></tr></table></figure>
<!-- 由于内容长度超过限制，后续内容请移步[使用机器学习识别出拍卖场中作弊的机器人用户(二)](../HumenOrRobot2) -->
<p>后续内容请移步<a href="/2017/05/29/HumenOrRobot2/" title="使用机器学习识别出拍卖场中作弊的机器人用户(二)">使用机器学习识别出拍卖场中作弊的机器人用户(二)</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本项目为kaggle上Facebook举行的一次比赛，地址见数据来源，完整代码见我的&lt;a href=&quot;https://github.com/LancelotHolmes/HumanOrRobot&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;github&lt;/a&gt;,欢迎来玩~&lt;/p&gt;
&lt;h2 id=&quot;代码&quot;&gt;&lt;a href=&quot;#代码&quot; class=&quot;headerlink&quot; title=&quot;代码&quot;&gt;&lt;/a&gt;代码&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;数据探索——Data_Exploration.ipynb&lt;/li&gt;
&lt;li&gt;数据预处理&amp;amp;特征工程——Feature_Engineering.ipynb &amp;amp; Feature_Engineering2.ipynb&lt;/li&gt;
&lt;li&gt;模型设计及评测——Model_Design.ipynb&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="ML" scheme="http://yoursite.com/tags/ML/"/>
    
      <category term="Kaggle" scheme="http://yoursite.com/tags/Kaggle/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>平坦世界</title>
    <link href="http://yoursite.com/2017/05/29/%E4%B8%96%E7%95%8C%E6%98%AF%E5%B9%B3%E7%9A%84/"/>
    <id>http://yoursite.com/2017/05/29/世界是平的/</id>
    <published>2017-05-29T08:30:23.000Z</published>
    <updated>2017-05-29T12:30:46.284Z</updated>
    
    <content type="html"><![CDATA[<p>这次给大家推荐一本书——“The world is flat”（《世界是平的》），刚刚看完了一遍，感觉这本书的视角很广阔，让我看到自己受限于地理或者意识因素所看不到的一些其实就实实在在发生在身边的变化，私以为，作为即将毕业的大学生而言，是很有必要一读的。</p>
<p>【这本书面世其实快10年了，但是书中所述的一些变化我们或经历过，或忽略掉了，所以即使放在现在读，也是很有前瞻性的。特别由于作者本身是记者，写作风格还是颇为轻松地，所以，读起来感觉像是跟着作者开着上帝视角实现了所谓“世界那么大，我想去看看”的成就一般。】</p>
<p>此书整体大概是由世界变平坦的种种例证、现象到作者所认为使世界变平坦的一些因素再到各个“成员”大至国家公司、小至每一个个体在这平坦世界里的角色和相互影响，最后是平坦世界所带来的或即将造成的可能负面影响和威胁来逐层叙述的。我想先就宏观角度简单记叙下书中的一些观点，然后谈一下书中所说而我也感觉到的身边的一些变化，最后就自己而言随意谈一下想法。</p>
<a id="more"></a>
<p>就宏观而言，书中让我印象最深的是全球化的重中体现，首先是全球合作的一些案例，这个曾经在《互联网时代》里也看到过，比如现在的波音飞机的组装以及各零件的制造是分散到世界各个国家各个地区去做的，然后又井然有序的由各个地方汇聚到一个点组装成型，书中还举得一个例子是沃尔玛的生产线，和前者类似，也是一种像分布式的结构，这种做法极大地提高了效率并降低了成本，而其中最让我目眩神迷的是这么个巨大的整体居然能够这么一致的展开协同工作；另外一点是关于离岸外包，这里就不得不提到一个国家是印度，或者说印度的城市班加罗尔，看了这本书我感觉像亲身去看一下，所谓外包，就是将本国家的一些相对而言中低端而要耗费大量人力的基础工作交给其他国家去做，这里你也许会想到所谓的”Made in China”，诚然，中国也是外包的一个很好的例子，换做以前我会觉得嗤之以鼻，感觉我们国家就老是像给美国之类的国家打工一样，其实，分析一下，就目前而言，这个是双赢的，美国那边自不用说，花一分美国工人的钱在中国或者印度雇佣到6~8个同样水平的技术工人，极大地降低了成本，而且这里面不得不说有个很有意思的东西是——时差，因为有些工作在美国的白天又美国人做，晚上就交给印度人（印度正在白天）做，极大地提升了效率，这个我在电影《贫民窟的百万富翁》里看到过的一个场景就是印度人通过远程监控摄像头替美国人监控停车场让我印象深刻，那么对于印度和中国这些国家呢，好处在哪？其一就是增多了工作岗位，就印度而言的话，由于现在印度培养了大量的理工学生，而毕业后以前只能去国外谋出路，否则在国内一般只能成为出租车司机，而经过外包，他们可以在本土就进行软件开发的工作，虽然工资不如美国人，但是相对于自己本身而言，他们的生活已经得到不小的提升了，另外，通过这种形式，印度和中国还可以学习一些国外的技术，甚至是抢占国外的市场，书中后面有个例子是中国生产的埃及传统的灯几乎快要垄断埃及的市场，因为在技术上有所突破，而且价格也低廉。</p>
<p>当然，以上只是从书中看到的知识，也许我以后还需要实地考察一番看看实际情况是否真如作者所述，不过，对于我们国家，我还是希望抱有乐观的态度去看他的发展，相信他会越变越好。</p>
<p>就身边的所见所闻而言，我印象比较深的是一个 距离 的问题，和书中作者一次下飞机乘出租车的经历一般，在乘车那段时间里，司机一直在通过蓝牙耳机聊天，车上开着导航，播放着电影，而作者在自己的笔记本上整理文章以及收发e-mail，用作者的话说，在那一个小时里他们同时做了很多事，却几乎没有交流，作者甚至猜想，也许司机正和远在另一个国度的父母通话呢。这大概就是目前发生在我们身边的一个尴尬境地了，一方面，技术的发展拉近了我们的距离，而另一面却又使我们的距离变得遥远，它拉近了我们和处在不同空间的亲人之间的距离，却又在此时此地的就在你眼前的我面前树起了一道屏障。我想起了高中语文老师发的一篇文章里对动车、高铁上的年轻人乘客们的描述，确确实实的感受到这一真切的现象，大家一上车就戴上耳机，或插入ipad，或插入iphone，而彼此之间却没有交流，这和绿皮火车上的情景完全不同，也是值得我们反思的一件事。</p>
<p>最后我想简单谈一下自己的一些想法。首先关于教育和竞争方面，这里还得扯下印度，书中说道，班加罗尔的接线员晚上为美国（白天）的乘客们进行咨询和失物找回工作，晚上还会自己学习一些知识，攻读一些学位什么的，顿时感到一种压迫感。从前经常听到政治老师说美国家长告诫自己的孩子说快吃饭，不然中国和印度的孩子就把你的饭给吃了或者快努力学习，中国或印度的孩子快把你的饭碗抢走了之类的。而现在是大家都站在几乎同一个平台上竞争，前面我们需要追赶美国，而同时，印度的青年们却也在旁虎视眈眈。而身处计算机专业这一日新月异，竞争更加残酷的环境下，我一面感到威胁，一面感到兴奋，兴奋的是，试想一下你即将站在一个大舞台上，和来自不同城市乃至不同国家的人角逐，而威胁在于，你们本身的水平是不一样的，就我而言，在我将要踏上这个舞台的那一天，我不仅会和同班同学竞争，稍远一点还有来自全国各大高校的强者，再远一点还有世界其他角落的高手出没，而要想不被碾成炮灰，或者说不被这一变平的趋势所冲倒的话，我就得不断地去吸收和学习新的技术、新的知识，还要进一步强化自己的全局意识，做到让自己所做的事无可替代，也就不会被”外包”掉。另外一点就是之前实习时听到负责人说现在的联系方式太多了，又是电话、又是微信、QQ的，反而造成了联系上的障碍，以前我们只有电话时一般就通过电话联系，而现在常常是不同人有不同的习惯，你得把这些一股脑全开着，否则搞不好会错过重要讯息，我常常在想，世界是多元化的，但本意是方便我们交流的工具最后却慢慢成了束缚我们的枷锁，从这个角度来看，人类到底是进步了，还是退化了？</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这次给大家推荐一本书——“The world is flat”（《世界是平的》），刚刚看完了一遍，感觉这本书的视角很广阔，让我看到自己受限于地理或者意识因素所看不到的一些其实就实实在在发生在身边的变化，私以为，作为即将毕业的大学生而言，是很有必要一读的。&lt;/p&gt;
&lt;p&gt;【这本书面世其实快10年了，但是书中所述的一些变化我们或经历过，或忽略掉了，所以即使放在现在读，也是很有前瞻性的。特别由于作者本身是记者，写作风格还是颇为轻松地，所以，读起来感觉像是跟着作者开着上帝视角实现了所谓“世界那么大，我想去看看”的成就一般。】&lt;/p&gt;
&lt;p&gt;此书整体大概是由世界变平坦的种种例证、现象到作者所认为使世界变平坦的一些因素再到各个“成员”大至国家公司、小至每一个个体在这平坦世界里的角色和相互影响，最后是平坦世界所带来的或即将造成的可能负面影响和威胁来逐层叙述的。我想先就宏观角度简单记叙下书中的一些观点，然后谈一下书中所说而我也感觉到的身边的一些变化，最后就自己而言随意谈一下想法。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Reading" scheme="http://yoursite.com/tags/Reading/"/>
    
      <category term="Economy" scheme="http://yoursite.com/tags/Economy/"/>
    
  </entry>
  
  <entry>
    <title>面壁者，我是你的破壁人</title>
    <link href="http://yoursite.com/2017/05/29/%E4%B8%89%E4%BD%93/"/>
    <id>http://yoursite.com/2017/05/29/三体/</id>
    <published>2017-05-29T08:28:53.000Z</published>
    <updated>2017-05-29T12:30:03.383Z</updated>
    
    <content type="html"><![CDATA[<p>对一个人的评判若不结合他所处的时代都是不公允的。</p>
<p>终于看完了《三体》全集，这部科幻小说给人的感觉真像作者自己命名的“地球往事”，像一本历史书，以宇宙为坐标，以光年为刻度，读罢，借用一句话“科幻小说虽然尽是对于未来的想象，但我们探索的一直是人的内心”。</p>
<p>情节上我就不剧透太多了，我想谈谈《三体》里的几个角色。</p>
<a id="more"></a>
<p>首先是罗辑，面壁者、执剑人、守墓人是他不同时期的身份，他是一个充满传奇色彩的人，用他自己的话是一个及时行乐的人，对其他的人、其他的事都不怎么上心的人。但是我看到的是他受人胁迫而终于接受面壁者身份时的无奈和挣扎；在冬眠复苏时被人当做笑话时的淡然、洒脱，再一次被推上历史转折点时的坚韧以及作为执剑人半个多世纪面壁时的狠厉。我得承认全书给我印象最深的是《黑暗森林》最高潮的部分，当罗辑站在自己挖掘的坟墓边对着虚空中的智子亮出最后底牌的那一刻；我真的有一种作为人类终于得救了、终于又有了希望的感觉。命运喜欢捉弄罗辑，在他吊儿郎当、无所事事时对他施以面壁者的诅咒，在他拯救了全人类时却让人类对他报以敌视；但罗辑不在乎这些，他只在乎自己所爱的那个女孩的幸福。</p>
<p>然后是《死神永生》里的女主角程心。之前有看一个《x分钟读完三体》的短片，当时发现弹幕上对于程心大多数是一片骂声，随处可见诸如“程圣母毁灭世界”的字眼。不得不说在看《死神永生》的中后段我也一直对于程心是恨得咬牙切齿的，实话说，我讨厌她的不作为和自以为是爱与善的化身所做的所有决定，讨厌她毁灭了地球、害人类灭亡，但后来一想，我其实是开了上帝视角在看这个角色，其实回过头来看，程心是当前普通人类的典型，甚至，是大众中向善的群体的典型，她一直秉持着自己的责任，逆来顺受；她是勇敢的，敢于牺牲自己，但是，她的能力是不够的。整部小说看下来程心大部分时间处于冬眠状态，而经常是其他人帮她做足了准备，然后突然一下把她推到全人类命运决策的位置，可是却没有想过她准备好了没有，结果她只能依据自己当前的认识做出最佳选择，然后成了公众的替罪羊，其实换位思考，我们估计在那个节点做的更差；不信你把程心放到不同的时间段看公众对于她作为执剑人的那几分钟的态度的不停反复就可以看出来了，大众只是需要一个为自己顶包的人，然后好像自己就可以置身事外了。</p>
<p>如果说程心更多的依靠感性来做判断，那么就不得不提到维德了，这个极端理性到冷酷的男人。最开始他对于程心的捉弄确实让我很不爽，从发射云天明的大脑一直到后面他不择手段的想要暗杀程心竞争执剑人。但读到后面你会发现维德其实是个表里如一的人，对于自己认定的事他能坚持到底，不择手段的坚持到底。</p>
<p>所以不存在这么一个人，把他放到任何一个时空他的判断都是对的，或者说大众对于个体的判断其实也不能代表什么，一个人只需坚持自己所相信的，在乎自己所爱的，到最后一刻，就够了。</p>
<p>各位面壁者们，准备好做自己的破壁人了么？</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对一个人的评判若不结合他所处的时代都是不公允的。&lt;/p&gt;
&lt;p&gt;终于看完了《三体》全集，这部科幻小说给人的感觉真像作者自己命名的“地球往事”，像一本历史书，以宇宙为坐标，以光年为刻度，读罢，借用一句话“科幻小说虽然尽是对于未来的想象，但我们探索的一直是人的内心”。&lt;/p&gt;
&lt;p&gt;情节上我就不剧透太多了，我想谈谈《三体》里的几个角色。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Reading" scheme="http://yoursite.com/tags/Reading/"/>
    
      <category term="Novel" scheme="http://yoursite.com/tags/Novel/"/>
    
  </entry>
  
  <entry>
    <title>平凡的世界，不平凡的凡人</title>
    <link href="http://yoursite.com/2017/05/29/%E5%B9%B3%E5%87%A1%E7%9A%84%E4%B8%96%E7%95%8C/"/>
    <id>http://yoursite.com/2017/05/29/平凡的世界/</id>
    <published>2017-05-29T08:27:42.000Z</published>
    <updated>2017-05-29T12:29:57.341Z</updated>
    
    <content type="html"><![CDATA[<p>一直想读这套书，在临近毕业时还专门从朋友那收藏了一套，借着在MEB的机会终于是忙里偷闲的看完了，虽意犹未尽，却也感到一种平和和满足。</p>
<p><strong>如果要用一句话概括，《平凡的世界》写的是爱情和面包。</strong></p>
<a id="more"></a>
<p>书中描述的爱情种类比较多，我就简单挑给我印象最深的三个来说说吧。首先是润叶和少安的爱情，那句诗里写的“郎骑竹马来，绕床弄青梅”大抵描述的就是这么一种爱情。少安和润叶是两小无猜的一对童年玩伴，随着两家各自发展出的家庭背景的差异却也慢慢在双方之间产生了巨大的鸿沟，一个留校任教成了城里人，另一个却回家务农，给家里分担压力。诚然，你可以说是少安主观上的懦弱导致了最终两人的分离和三个家庭的阴影和痛苦，但是个人认为，在那么一种背景下，就一个男人而言是不得不考虑这些东西的。书中虽说如果两人身份对调也许就没什么问题，但我觉得即使两人身份对调而彼此相爱也还是要考虑双方的家庭背景，这里我倒不是在推崇门当户对的老观念，只是客观的分析一下，毕竟，我一直认为，爱情是建立在一定的物质基础之上，不是简单的彼此相爱，毕竟，爱情可能产生在一瞬间，但是维系这份感情却需要长期的努力，也就需要一定的物质作为基础，而若双方各自条件不对等，时间长了或多或少会产生并积累一些问题。由此看来，古人所推崇的门当户对确有一定道理。</p>
<p>当然，我不否认灰姑娘和王子的童话故事，但是即使在灰姑娘的故事里，灰姑娘也是有仙子为她做后盾的而且她本身有相对应的素质作为支撑。</p>
<p>扯远了，其实书中倒也有这么一对，就是少平和晓霞。我对这一对的定义是充满理想和浪漫主义色彩的情侣，两人由最初的共同爱好或说理想发展出深厚的友谊，继而在不同的人生道路上产生的共鸣引导出爱情，说实话，看到这里我已经觉得有点过于理想化了，到后来晓霞拒绝高富帅依然坚定地爱着少平时，我也深深被打动，从心理上我是希望看到这一对能有美好的结局的，我原希望会是少平从煤炭场最后走出来完成逆袭然后迎娶白富美的励志故事（原谅程序员的屌丝气息），不过感觉依作者的套路势必会再给这对有情人制作一些波折，可是，万万没想到，情节发展居然是晓霞的牺牲，当时感觉很难接受这一事实，毕竟这朴实的书中的一朵充满浪漫主义色彩的绚丽花朵竟以这种方式枯萎。</p>
<p>最后一对就是润叶和向前，很难用爱情定义这一对，因为故事前段一直是向前的单恋，即使两人的结合也是润叶的自我牺牲和自我放逐，结果是长期的互相折磨到最后，然后转折点在向前的事故所带来的残疾，润叶因为内疚而突然回头，两人复合（个人觉得此处作者不够深入），然后两人开始真正的婚姻生活，不过也很难说是爱情，连文中也提及此时的润叶更像是一个虔诚的修女，给予向前的除了妻子的责任另外确是一种变相的母性关怀，姑且称之为——怜悯或者同情吧，其实我是很喜欢润叶这么个姑娘的，敢爱敢恨，在和少安的爱情中表现出勇敢，却又太懂事，这样矛盾的性格造成她最终的屈服，与其说她是嫁给了一个自己不爱的男人，倒不如说她是嫁给了生活。但我又不能怪罪向前，爱情这东西说不清道不明的，很多时候其实就是，我喜欢你然而我并不能理解你为何不喜欢我，其结果至少有一人受伤。</p>
<p>以上是对书中描述的几种爱情的粗浅理解，当然，作为一个纯理论家，请相信，我说的每一句话都是谎话。</p>
<p>还是来谈谈另一条线——面包吧。</p>
<p>全书主要描述了双水村这么个平凡的小天地里一个又一个像你像他像那路边野花的平凡人的平凡而又不平凡的生活。总体来说，大的背景是变化莫测的，从文革末的动乱年代到改革开放的小康生活，立足在这么一个大环境下，每个人的命运都不能孤立的来看，刚开始看这本书的时候我常常随着故事的情节发展给故事中的人下定义是好是坏是对是错，后来随着作者时不时的客观分析才发现自己的浅薄，其实就像我们所生活中的生活，它不像我们做的卷子上的题目，没有什么绝对的对错，每个人只是在给他演出的那么一段镜头里或优雅谢幕或落荒而逃，导演却是生活。也许我仍不能从简单的评判一个人是好人坏人，他做的一件事是对的还是错的这么一种观念里走出来，但是从这本书里我看到了生活这辆无缰马车上的形形色色人物的身不由己，同时，我也看到他们的奋斗，一次一次被生活喊cut却又一次一次带着微笑或者含着泪水伤痕累累的跑龙套，在这场戏里，没有主角，或者说每个人都是主角，轮番上场。</p>
<p>每一个人物都有其鲜明特色又有其局限性，之前有一朋友说他觉得书中把任务刻画得太脸谱化了，我觉得是有这么一点，但是大体而言路遥对人物的刻画还是很鲜明，很丰满而有血有肉的。我欣赏少安在物质生活追求上的不屈不挠精神，却又为他有时的偏执扼腕，对于他在爱情上的胆怯以及一意孤行而叹息；我喜欢少平这么一个脚踏实地的为生活战斗，为自己为他人着想的‘精神贵族’。他太可爱了，看这本书真的就是看着这个少年的成长，看着他咀嚼生活，消化生活，不过我希望他能更勇敢，有时能多为自己考虑一点，勇敢的追逐自己的幸福；至于晓霞，自不用说，感觉书中几乎刻画成女神一般的存在了，可惜也由于她的冒险精神和舍己为人的精神而香消玉殒；润叶，真是一个让人忍不住心疼却又忍不住尊敬的女性，她是那么为大家着想，甚至于可以牺牲自己；还有孙玉厚，这个伟大的老父亲，虽然书中没太多专门的笔墨，但是仍可以看见少安、少平甚至兰花从他身上传承的坚韧的基因，也许从早期发狠供玉亭念书也能窥见一二，另外，这位老人在儿子追求自己目标时默默支持，在孩子们遭受不幸时却总是挺身而出，实在令人感动；其他还有用情专一的向前，逛鬼王满银，懂事的兰香等等，像你我身边的每一个人一样在这个平凡的世界里献上了这精彩的演出，然后帷幕缓缓落下，他们又消失在人群中，从此你我看到的身边的每一个人都似曾相识。</p>
<p>以上大概就是这粗略的第一次阅读《平凡的世界》的一点不吐不快的想法，虽然书有一点点小瑕疵比如各个主角的结局实在难以让我这么一个习惯了happy ending的人满意，比如中间外星人的情节有点乱入的感觉，不过还是强力推荐这本书，怎么说呢，在看这本书的过程中，我常常有一种踏实感，活着的踏实感，在我合上书页，回想起书中一些情节时情不自禁的感受到生活，从某种程度上，它减轻了我若有若无的虚无感。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一直想读这套书，在临近毕业时还专门从朋友那收藏了一套，借着在MEB的机会终于是忙里偷闲的看完了，虽意犹未尽，却也感到一种平和和满足。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果要用一句话概括，《平凡的世界》写的是爱情和面包。&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Reading" scheme="http://yoursite.com/tags/Reading/"/>
    
      <category term="Novel" scheme="http://yoursite.com/tags/Novel/"/>
    
  </entry>
  
  <entry>
    <title>韶华倾负，难舍皮囊</title>
    <link href="http://yoursite.com/2017/05/29/%E9%9F%B6%E5%8D%8E%E5%80%BE%E8%B4%9F%EF%BC%8C%E9%9A%BE%E8%88%8D%E7%9A%AE%E5%9B%8A/"/>
    <id>http://yoursite.com/2017/05/29/韶华倾负，难舍皮囊/</id>
    <published>2017-05-29T08:22:21.000Z</published>
    <updated>2017-05-29T12:30:14.390Z</updated>
    
    <content type="html"><![CDATA[<p>利用在动车上的四个小时看完了《皮囊》（除去中间15分钟和邻座美女搭讪的时间），感觉是很不错的一本书，不同的章节写的不同的故事，如果你有时间不妨通篇阅读一下，如果没有时间不妨听我说一说。</p>
<p>个人觉得，前五章的主题关于生离，关于死别。</p>
<p>第一章和书同名是为《皮囊》，讲述的是99岁的阿太。</p>
<p><em>我们的生命本来多轻盈，都是被这肉体和各种欲望的污浊给拖住。阿太，我记住了。“肉体是拿来用的，不是拿来伺候的。”</em></p>
<a id="more"></a>
<p>没文化的神婆阿太穷极一生都在利用自己的那副皮囊，甚至要求周围的人也学会去利用好这幅皮囊，所以她把年幼的孩子扔进海里让他学游泳，所以她即使白发人送黑发人也保持一副让人不解的嘲弄表情，或许在她看来，失掉这皮囊，灵魂最终的归宿反而是自由吧。</p>
<p>但这并不意味着阿太是那种不在乎生死的人，相反，我觉得她是站在更高的角度看待生死这个问题的人，而这也许隐隐约约影响着身边的人。所以作者后来写下这么一句话：</p>
<p><em>从小我就喜欢闻泥土的味道，也因此其实从小我不怕死，一直觉得死是回家，是入土。我反而觉得生才是问题，人学会站立，是任性地想脱离这土地，因此不断向上攀爬，不断抓取任何理由——欲望、理想、追求。然而，我们终究需要脚踏着黄土。在我看来，生是更激烈的索取，或许太激烈的生活本身就是一种任性。</em></p>
<p>然后是第二章——《母亲的房子》写的是母亲，房子还有爱情。</p>
<p>每个人都会有自己的执着，而那种执着最后就物化成某种具体的事物，然后进一步，有的化成妥协后的一道疤痕，有的成为穷极一生的执念。而文中的母亲显然是后者，而她所执着的是那所房子，是年轻时的父亲曾允诺的房子，以一种执着的近乎任性的方式。从最开始的一修再修，这所母亲执意要修建的房子联系着一家人的生活和命运，从拮据的生活到后来周围人的不解最后甚至家人的埋怨，母亲一度支撑不下去却又不甘心，最难过的日子里甚至一家人想要一起求死，直到后来身为“不合格的一家之主”的我终于理解了母亲：</p>
<p><em>事实上，知道母亲坚持要建好这房子的那一刻。我才明白过来，前两次建房，为的不是她或者我的脸面，而是父亲的脸面——她想让父亲发起的这个家庭看上去是那么健全和完整。</em></p>
<p><em>这是母亲从老没表达过，也不可能说出口的爱情。</em></p>
<p>另外，关于母亲的故事在《我的神明朋友》里会继续讲述，你会看到更多母亲身上的坚韧。</p>
<p>然后《残疾》讲述的是父亲中风后的家里的种种艰辛和一家人和生活的抗争。</p>
<p>不同于以前语文课本里父亲那种高大、沉默的形象，《皮囊》里的父亲首先是一个中风而偏瘫了的父亲，而后是一个曾经混黑社会呼风唤雨的混混头子，中风前后的心理落差造成了父亲接下来的一系列变化，他从假装坚强，希望靠对时间的严苛要求和每天的活动恢复到以前的健壮身体，于是一家人默契的相互演着戏，却也过了一段幸福的时间，直到被一场意料之中的台风摧毁。</p>
<p><em>虽然知道根本不是台风的错。那结局是注定的，生活中很多事情，该来的会来，不以这个形式，就会以那样的形式。但把事情简单归咎于我们无能为力的某个点，会让我们的内心可以稍微自我安慰一下，所以，我至今仍愿意诅咒那次台风。</em></p>
<p>那场台风刮倒的不仅仅是父亲，更打碎了父亲伪装的坚强和一家人匆忙写就的生活的剧本。自此，父亲进入了第二个状态，先是放弃了坚强，呈现出一副自暴自弃的样子期盼着死亡。而后又进入下一阶段，甚至于舍弃了父亲的身份，像个不懂事的孩子一样撒娇、任性，却不再期盼死亡。</p>
<p>但是父亲的故事并没有完，在《重症病房里的圣诞节》，作者以在重症病房里的看护家属的视角半写实半轻描淡写地描述了退去浮华身份后的种种生离死别。</p>
<p><em>疾病在不同的地方找到了他们，即使他们当时身处不同的生活，但疾病一眼看出他们共同的地方，统一把他们赶到这么一个地方圈养。</em></p>
<p>在这一章里，作者刻画了几个不同的人物，有乐观的病人，有刻意显得刻薄的医护人员，有早熟的同龄孩子。在医院这么一个特殊的小世界里，赤裸的生长着。有几个事件的刻画让我印象深刻，比如‘我’对于医院里电梯的描写，对于走过一间间病房核查之前的病人是否还在；比如和同龄的孩子交流，发现相同点，大家拥有相同的眼睛，那是经历过生命消逝后才看得到的眼睛，所以会被一眼看透，而无法交到同龄的朋友，因为他们只有一次也只能有一次痛彻心扉的谈话；比如乐观的病友最后还是被夺走生命后‘我’心态上的变化，印象最深的是那个为父亲在圣诞节违禁燃放烟花的年轻人，只因他父亲要进行手术了，然后他被三个保安团团围住……</p>
<p><em>比如，在帮父亲换输液瓶时，会发觉他手上密密麻麻的针孔，找不到哪一寸可以用来插针；比如医生会时常拿着两种药让我选择，这个是进口的贵点的，这个是国产的便宜的，你要哪种？我问了问进口的价钱，想了很久。“国产的会有副作用吗？”“会，吃完后会有疼痛，进口的就不会。”我算了算剩下的钱和可能要住院的时间，“还是国产的吧。” 然后看着父亲疼痛了一个晚上，怎么都睡不着。</em></p>
<p><em>在这里，你一不小心留出空当，就会被悲伤占领——这是疾病最廉价、最恼人的雇佣兵。</em></p>
<p>这种笔触没在重症病房待过的人是写不出来的，那种切实的压抑感和空闲下来被对未来的恐惧和迷茫逼到绝路的走投无路感。</p>
<p>接下来的几章个人觉得是关于青春和梦想的。</p>
<p>首先《张美丽》这一章从这么一个略显俗气的名字开始，从迷信的桃色传说开始记叙了传说中自杀的殉情张美丽，而后记叙了现实中被夹在理想和世俗之间压垮的张美丽，同样是一副让荷尔蒙萌动的青春期少年燥起来的皮囊，演绎了不同的故事。这故事一面让我想起了《搜索》这部电影里舆论的可怕，人们对于未知的事物的不理解演化成的嫉妒和驱逐和以讹传讹造成的悲剧上演。另一面看到的是被遗忘的先驱们，为了自己的理想而头破血流，然后若干年后在残次不齐的字里行间被遗忘或变成谈资。只是人们一同忘掉的，是现在所呈现在眼前的似曾相识。</p>
<p>接下来《阿小和阿小》、《天才文展》记叙的算是童年和成长吧。</p>
<p>关于城市，那是不在城市长大的孩子们小时候的天堂，是他们在电视屏幕上看到的模样，而两个阿小，一个土生土长在小城镇；另一个为即将开始的大城市生活过度而寄居在小城镇。同样的名字，也沉浸在同样的幻想里，只是他们误读了城市，他们以为的城市就真的是电视屏幕上的那样，数不过来的高楼，四六分的香港发饰，衬衫，洁白的牙齿……于是，他们开始注重外表上的模仿和行为上的接近，在我看来，这正是一种青春期的迷茫，对于寻找自我定位时的种种探索，追求那些很酷很与众不同的感觉。但是结局却不尽如意：</p>
<p><em>大部分人都困倦到睡着了——他们都是一早七点准时在家门口等着这车到市区，他们出发前各自化妆、精心穿着，等着到这城市的各个角落，扮演起维修工、洗碗工、电器行销售、美发店小弟……时间一到，又仓皇地一路小跑赶这趟车，搭一两个小时回所谓的家，准备第二天的演出。</em></p>
<p><em>他们都是这城市的组成部分。而这城市，曾经是我们在小镇以为的，最美的天堂。他们是我们曾经认为的，活在天堂里的人。</em></p>
<p>而《天才文展》里的文展则代表着一种有远大抱负却囿于家庭环境的早熟的年轻人，也许我们都碰到过像这样的人，以一种居高临下的姿态看着你，对于自我有着严苛的要求，希望通过一项项计划通来向别人证明自己，来狠狠地扇曾经看不起自己的人一耳光。</p>
<p><em>我才明白，那封信里，我向文展说的“小时候的玩伴真该一起聚聚了”，真是个天真的提议。每个人都已经过上不同的生活，不同的生活让许多人在这个时空里没法相处在共同的状态中，除非等彼此都老了，年迈再次抹去其他，构成我们每个人最重要的标志，或许那时候的聚会才能成真。</em></p>
<p>然而结局却是悲剧的，‘我’最终过上了文展所希冀的生活而遭到文展的嫉妒和排斥，令人吃惊的是‘我’却也产生了一些负罪感。就像电视剧里经常碰到的桥段，“如果不是因为当初XXX，你现在所有的一切本该是我的。”其实这何尝不是自我欺骗呢，就算自我假设的前提条件不成立，结局却不见得会不一样，失败者把失败原因归结到自己以外的事物上注定还是会重蹈覆辙。</p>
<p>然后是《厚朴》描述的这么一个可爱的男生，英文名又是hope，伴着激情和叛逆的形象出场，不得不说让我想起身边一些充满朝气和正能量的人，平时还是很羡慕他们的，不过厚朴是不同的，开始我也很希望看看他所谓的“务虚”能走出一片天地来，俗话说就是理想主义者，因为我感觉自己更类似于作者。不过可惜的是最后结局让人痛心，像作者所形容的</p>
<p><em>不清楚真实的标准时，越用力就越让人觉得可笑。</em></p>
<p><em>不合时宜的东西，如果自己虚弱，终究会成为人们嘲笑的对象，但有力量了，或坚持久了，或许反而能成为众人追捧的魅力和个性——让我修正自己想法，产生这个判断的，是厚朴。</em></p>
<p><em>他以为自己做着摧毁一切规矩的事情，但其实一直活在规矩里。我以为自己战战兢兢地以活在规矩里为生活方式，但其实却对规矩有着将其彻底摧毁的欲望。</em></p>
<p>所以厚朴所表现出来的其实是一种沉浸在自己构造的幻想世界里而最终难以回到现实，他不愿接受自己失败了的现实，只是表现的叛逆。但话说回来我是希望能看到一种理想主义者最终实现理想的故事，我相信如果有那么一定会是精彩的。</p>
<p>说到这里我甚至有一种奇怪的感觉，是否厚朴其实就是作者的另一面，只是最终发现自己其实是在规则里画着圈而随着屈服而死掉的那部分。</p>
<p>最后几章主要简单谈了些关于城市、理想之类的话题，印象较之之前的几章倒是没那么深了，截取一段如下</p>
<p><em>只是我觉得城市不好。特别是中国的城市不好。厦门和中国大部分城市的建设都有个基础——人家国外的城市是怎么样的，以及人们该怎么被组织的，然后再依据这样的标准建设。中国近代的城市不是长出来的，不是培植出来的，不是催生出来的，而是一种安排。因为初期必然要混乱，所以中国的城市也表现出强大的秩序意识，人要干吗，路要怎么样。生长在这样环境里的人，除了维护秩序或者反抗秩序，似乎也难接受第二层次的思维了。</em></p>
<p>回头来看，几篇文章倒确实很契合《皮囊》这么一个主题，就像开头所述的，灵魂离不开皮囊，无论你如何讨厌自己的这幅皮囊，你的灵魂也得附庸其下。皮囊往小的说就是阿太所谓的驱壳和父亲半瘫的残疾，往大了说是一个人所处的位置，他背后的故事，就像母亲的那所房子，阿小的香港梦，厚朴的架子鼓。过去我常常看不懂电视剧里有些人的无可奈何，一厢情愿的认为这么容易的事换做是我直接三下五除二就解决了，实际情况却是不要以好坏善恶对错来划分人群，你看到的只是他当前展现给你的，你看不到的是他这一举动后面的挣扎，人是不能孤立和剥离来看的，当他站在你面前时，你得看到他的背景。</p>
<p><em>我常对朋友说，理解是对他人最大的善举。当你坐在一个人面前，听他开口说话，看得到各种复杂、精密的境况和命运，如何最终雕刻出这样的性格、思想、做法、长相，这才是理解。而有了这样的眼睛，你才算真正“看见”那个人，也才会发觉，这世界最美的风景，是一个个活出各自模样和体系的人。</em></p>
<p>如果每个人都是一段程序的话，那么我们在和不同的人交往的过程中就有意无意的修改了他们的代码，从此也许他们身上就带着你的痕迹；而身边亲近的人，更像是写进你基因里的代码段，在某个特定的时间里被激活，让你似曾相识，让你视线模糊。</p>
<p>无论如何，请带着这副皮囊好好生活。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;利用在动车上的四个小时看完了《皮囊》（除去中间15分钟和邻座美女搭讪的时间），感觉是很不错的一本书，不同的章节写的不同的故事，如果你有时间不妨通篇阅读一下，如果没有时间不妨听我说一说。&lt;/p&gt;
&lt;p&gt;个人觉得，前五章的主题关于生离，关于死别。&lt;/p&gt;
&lt;p&gt;第一章和书同名是为《皮囊》，讲述的是99岁的阿太。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;我们的生命本来多轻盈，都是被这肉体和各种欲望的污浊给拖住。阿太，我记住了。“肉体是拿来用的，不是拿来伺候的。”&lt;/em&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Reading" scheme="http://yoursite.com/tags/Reading/"/>
    
      <category term="Novel" scheme="http://yoursite.com/tags/Novel/"/>
    
  </entry>
  
</feed>
